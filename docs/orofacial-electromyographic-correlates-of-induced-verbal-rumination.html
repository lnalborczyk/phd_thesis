<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 3 Orofacial electromyographic correlates of induced verbal rumination | Psychophysiological characteristics of verbal rumination</title>
  <meta name="description" content="Chapter 3 Orofacial electromyographic correlates of induced verbal rumination | Psychophysiological characteristics of verbal rumination">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 3 Orofacial electromyographic correlates of induced verbal rumination | Psychophysiological characteristics of verbal rumination" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Orofacial electromyographic correlates of induced verbal rumination | Psychophysiological characteristics of verbal rumination" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="methodological-framework.html">
<link rel="next" href="dissociating-facial-electromyographic-correlates-of-visual-and-verbal-induced-rumination.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Theoretical chapters</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Theoretical framework</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#rumination-as-a-form-of-repetitive-negative-thinking"><i class="fa fa-check"></i><b>1.1</b> Rumination as a form of repetitive negative thinking</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#what-is-motor-imagery"><i class="fa fa-check"></i><b>1.2</b> What is motor imagery ?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#the-motor-simulation-theory"><i class="fa fa-check"></i><b>1.2.1</b> The motor simulation theory</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#emulation-and-internal-models"><i class="fa fa-check"></i><b>1.2.2</b> Emulation and internal models</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#emg"><i class="fa fa-check"></i><b>1.3</b> Electromyography of covert actions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="intro.html"><a href="intro.html#explanations-for-the-presence-of-muscular-activity-during-motor-imagery"><i class="fa fa-check"></i><b>1.3.1</b> Explanations for the presence of muscular activity during motor imagery</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#controversial-findings"><i class="fa fa-check"></i><b>1.3.2</b> Controversial findings</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#what-is-that-little-voice-inside-my-head"><i class="fa fa-check"></i><b>1.4</b> What is that little voice inside my head ?</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#inner-speech-as-multimodal-verbal-imagery"><i class="fa fa-check"></i><b>1.4.1</b> Inner speech as multimodal verbal imagery</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#overt-and-imagined-actions"><i class="fa fa-check"></i><b>1.5</b> Overt and imagined actions</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#motor-imagery"><i class="fa fa-check"></i><b>1.5.1</b> Motor imagery</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#inner-speech---what-is-this-little-voice-in-my-head"><i class="fa fa-check"></i><b>1.5.2</b> Inner speech - what is this little voice in my head ?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="methodological-framework.html"><a href="methodological-framework.html"><i class="fa fa-check"></i><b>2</b> Methodological framework</a><ul>
<li class="chapter" data-level="2.1" data-path="methodological-framework.html"><a href="methodological-framework.html#electromyographic-correlates-of-speech-production"><i class="fa fa-check"></i><b>2.1</b> Electromyographic correlates of speech production</a><ul>
<li class="chapter" data-level="2.1.1" data-path="methodological-framework.html"><a href="methodological-framework.html#speech-production-mechanisms"><i class="fa fa-check"></i><b>2.1.1</b> Speech production mechanisms</a></li>
<li class="chapter" data-level="2.1.2" data-path="methodological-framework.html"><a href="methodological-framework.html#speech-production-muscles"><i class="fa fa-check"></i><b>2.1.2</b> Speech production muscles</a></li>
<li class="chapter" data-level="2.1.3" data-path="methodological-framework.html"><a href="methodological-framework.html#muscular-physiology"><i class="fa fa-check"></i><b>2.1.3</b> Muscular physiology</a></li>
<li class="chapter" data-level="2.1.4" data-path="methodological-framework.html"><a href="methodological-framework.html#emg-signal"><i class="fa fa-check"></i><b>2.1.4</b> EMG signal</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="methodological-framework.html"><a href="methodological-framework.html#emg-signal-measures"><i class="fa fa-check"></i><b>2.2</b> EMG signal measures</a><ul>
<li class="chapter" data-level="2.2.1" data-path="methodological-framework.html"><a href="methodological-framework.html#motor-unit-action-potential"><i class="fa fa-check"></i><b>2.2.1</b> Motor unit action potential</a></li>
<li class="chapter" data-level="2.2.2" data-path="methodological-framework.html"><a href="methodological-framework.html#surface-emg"><i class="fa fa-check"></i><b>2.2.2</b> Surface EMG</a></li>
<li class="chapter" data-level="2.2.3" data-path="methodological-framework.html"><a href="methodological-framework.html#basic-signal-processing"><i class="fa fa-check"></i><b>2.2.3</b> Basic signal processing</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="methodological-framework.html"><a href="methodological-framework.html#statistical-modelling-approach"><i class="fa fa-check"></i><b>2.3</b> Statistical modelling approach</a></li>
<li class="chapter" data-level="2.4" data-path="methodological-framework.html"><a href="methodological-framework.html#overview-of-the-experimental-chapters"><i class="fa fa-check"></i><b>2.4</b> Overview of the experimental chapters</a></li>
</ul></li>
<li class="part"><span><b>II Experimental chapters</b></span></li>
<li class="chapter" data-level="3" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><i class="fa fa-check"></i><b>3</b> Orofacial electromyographic correlates of induced verbal rumination</a><ul>
<li class="chapter" data-level="3.1" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#abstract"><i class="fa fa-check"></i><b>3.1</b> Abstract</a></li>
<li class="chapter" data-level="3.2" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#introduction"><i class="fa fa-check"></i><b>3.2</b> Introduction</a></li>
<li class="chapter" data-level="3.3" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#methods"><i class="fa fa-check"></i><b>3.3</b> Methods</a><ul>
<li class="chapter" data-level="3.3.1" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#participants"><i class="fa fa-check"></i><b>3.3.1</b> Participants</a></li>
<li class="chapter" data-level="3.3.2" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#material"><i class="fa fa-check"></i><b>3.3.2</b> Material</a></li>
<li class="chapter" data-level="3.3.3" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#procedure"><i class="fa fa-check"></i><b>3.3.3</b> Procedure</a></li>
<li class="chapter" data-level="3.3.4" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#data-processing-and-analysis"><i class="fa fa-check"></i><b>3.3.4</b> Data processing and analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#results"><i class="fa fa-check"></i><b>3.4</b> Results</a><ul>
<li class="chapter" data-level="3.4.1" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#experiment-1-rumination-induction-1"><i class="fa fa-check"></i><b>3.4.1</b> Experiment 1: rumination induction</a></li>
<li class="chapter" data-level="3.4.2" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#experiment-2-rumination-reduction-by-relaxation-1"><i class="fa fa-check"></i><b>3.4.2</b> Experiment 2: rumination reduction by relaxation</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#discussion"><i class="fa fa-check"></i><b>3.5</b> Discussion</a><ul>
<li class="chapter" data-level="3.5.1" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#experiment-1"><i class="fa fa-check"></i><b>3.5.1</b> Experiment 1</a></li>
<li class="chapter" data-level="3.5.2" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#experiment-2"><i class="fa fa-check"></i><b>3.5.2</b> Experiment 2</a></li>
<li class="chapter" data-level="3.5.3" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#general-discussion"><i class="fa fa-check"></i><b>3.5.3</b> General discussion</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#acknowledgements"><i class="fa fa-check"></i><b>3.6</b> Acknowledgements</a></li>
<li class="chapter" data-level="3.7" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#suppCH3"><i class="fa fa-check"></i><b>3.7</b> Supplementary data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dissociating-facial-electromyographic-correlates-of-visual-and-verbal-induced-rumination.html"><a href="dissociating-facial-electromyographic-correlates-of-visual-and-verbal-induced-rumination.html"><i class="fa fa-check"></i><b>4</b> Dissociating facial electromyographic correlates of visual and verbal induced rumination</a></li>
<li class="chapter" data-level="5" data-path="muscle-specific-electromyographic-correlates-of-inner-speech-production.html"><a href="muscle-specific-electromyographic-correlates-of-inner-speech-production.html"><i class="fa fa-check"></i><b>5</b> Muscle-specific electromyographic correlates of inner speech production</a></li>
<li class="chapter" data-level="6" data-path="articulatory-suppression-effects-on-induced-rumination.html"><a href="articulatory-suppression-effects-on-induced-rumination.html"><i class="fa fa-check"></i><b>6</b> Articulatory suppression effects on induced rumination</a></li>
<li class="chapter" data-level="7" data-path="refining-the-involvement-of-the-speech-motor-system-during-rumination-a-dual-task-investigation.html"><a href="refining-the-involvement-of-the-speech-motor-system-during-rumination-a-dual-task-investigation.html"><i class="fa fa-check"></i><b>7</b> Refining the involvement of the speech motor system during rumination: a dual-task investigation</a></li>
<li class="part"><span><b>III Discussion and conclusions</b></span></li>
<li class="chapter" data-level="8" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html"><i class="fa fa-check"></i><b>8</b> Discussion and perspectives</a><ul>
<li class="chapter" data-level="8.1" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html#summary-of-the-results"><i class="fa fa-check"></i><b>8.1</b> Summary of the results</a></li>
<li class="chapter" data-level="8.2" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html#benchmarks-for-theories-of-inner-speech"><i class="fa fa-check"></i><b>8.2</b> Benchmarks for theories of inner speech</a></li>
<li class="chapter" data-level="8.3" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html#limitations-and-ways-forward"><i class="fa fa-check"></i><b>8.3</b> Limitations and ways forward</a></li>
<li class="chapter" data-level="8.4" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html#conclusions"><i class="fa fa-check"></i><b>8.4</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank"> Powered by bookdown </a></li>
<li><a href="http://www.barelysignificant.com" target="blank"> Ladislas Nalborczyk </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Psychophysiological characteristics of verbal rumination</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="orofacial-electromyographic-correlates-of-induced-verbal-rumination" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Orofacial electromyographic correlates of induced verbal rumination</h1>
<p>Add a summary of the research and brief introduction to this first empirical chapter here…<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<div id="abstract" class="section level2">
<h2><span class="header-section-number">3.1</span> Abstract</h2>
<p>Rumination is predominantly experienced in the form of repetitive verbal thoughts. Verbal rumination is a particular case of inner speech. According to the <em>Motor Simulation view</em>, inner speech is a kind of motor action, recruiting the speech motor system. In this framework, we predicted an increase in speech muscle activity during rumination as compared to rest. We also predicted increased forehead activity, associated with anxiety during rumination. We measured electromyographic activity over the <em>orbicularis oris superior and inferior</em>, <em>frontalis</em> and <em>flexor carpi radialis</em> muscles. Results showed increased lip and forehead activity after rumination induction compared to an initial relaxed state, together with increased self-reported levels of rumination. Moreover, our data suggest that orofacial relaxation is more effective in reducing rumination than non-orofacial relaxation. Altogether, these results support the hypothesis that verbal rumination involves the speech motor system, and provide a promising psychophysiological index to assess the presence of verbal rumination.</p>
</div>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">3.2</span> Introduction</h2>
<p>As humans, we spend a considerable amount of time reflecting upon ourselves, thinking about our own feelings, thoughts and behaviors. Self-reflection enables us to create and clarify the meaning of past and present experiences <span class="citation">(Boyd &amp; Fales, <a href="#ref-boyd_reflective_1983">1983</a>; Nolen-Hoeksema, Wisco, &amp; Lyubomirsky, <a href="#ref-Nolen-Hoeksema2008">2008</a>)</span>. However, this process can lead to unconstructive consequences when self-referent thoughts become repetitive, abstract, evaluative, and self-critical <span class="citation">(Watkins, <a href="#ref-Watkins2008">2008</a>)</span>.</p>
<p>Indeed, rumination is most often defined as a repetitive and recursive mode of responding to negative affect <span class="citation">(Rippere, <a href="#ref-Rippere1977">1977</a>)</span> or life situations <span class="citation">(M. S. Robinson &amp; Alloy, <a href="#ref-Robinson2003">2003</a>)</span>. Although rumination is a common process that can be observed in the general population <span class="citation">(Watkins, <a href="#ref-Watkins2008">2008</a>)</span>, it has been most extensively studied in depression and anxiety. Depressive rumination has been thoroughly studied by Susan Nolen-Hoeksema, who developed the Response Style Theory <span class="citation">(RST, Nolen-Hoeksema, <a href="#ref-nolen-hoeksema_responses_1991">1991</a>)</span>. According to the RST, depressive rumination is characterized by an evaluative style of processing that involves recurrent thinking about the causes, meanings, and implications of depressive symptoms. Even though rumination can involve several modalities (i.e., visual, sensory), it is a predominantly verbal process <span class="citation">(Goldwin &amp; Behar, <a href="#ref-goldwin_concreteness_2012">2012</a>; McLaughlin, Borkovec, &amp; Sibrava, <a href="#ref-mclaughlin_effects_2007">2007</a>)</span>. In this study, we focus on verbal rumination, which can be conceived of as a particularly significant form of inner speech.</p>
<p>Inner speech or covert speech can be defined as silent verbal production in one’s mind or the activity of silently talking to oneself <span class="citation">(Zivin, <a href="#ref-zivin_development_1979">1979</a>)</span>. The nature of inner speech is still a matter of theoretical debate <span class="citation">(for a review, see Perrone-Bertolotti, Rapin, Lachaux, Baciu, &amp; Lœvenbruck, <a href="#ref-Perrone-Bertolotti2014">2014</a>)</span>. Two opposing views have been proposed in the literature: the <em>Abstraction view</em> and the <em>Motor Simulation view</em>. The <em>Abstraction view</em> describes inner speech as unconcerned with articulatory or auditory simulations and as operating on an amodal level. It has been described as “condensed, abbreviated, disconnected, fragmented, and incomprehensible to others” <span class="citation">(Vygotsky, <a href="#ref-vygotsky_collected_1987">1987</a>)</span>. It has been argued that important words or grammatical affixes may be dropped in inner speech <span class="citation">(Vygotsky, <a href="#ref-vygotsky_collected_1987">1987</a>)</span> or even that the phonological form or representation of inner words may be incomplete <span class="citation">(G. S. Dell &amp; Repka, <a href="#ref-dell_errors_1992">1992</a>; Sokolov, <a href="#ref-sokolov_inner_1972">1972</a>)</span>. <span class="citation">MacKay (<a href="#ref-mackay_constraints_1992">1992</a>)</span> stated that inner speech is nonarticulatory and nonauditory and that “Even the lowest level units for inner speech are highly abstract” (p.122).</p>
<p>In contrast with this <em>Abstraction view</em>, the physicalist or embodied view considers inner speech production as mental simulation of overt speech production. As such, it can be viewed as similar to overt speech production, except that the motor execution process is blocked and no sound is produced <span class="citation">(Gr�zes &amp; Decety, <a href="#ref-grzes_functional_2001">2001</a>; Postma &amp; Noordanus, <a href="#ref-postma_production_1996">1996</a>)</span>. Under this <em>Motor Simulation view</em>, a continuum exists between overt and covert speech, in line with the continuum drawn by <span class="citation">Decety &amp; Jeannerod (<a href="#ref-decety_mentally_1996">1996</a>)</span> between imagined and actual actions. This hypothesis has led certain authors to claim that inner speech by essence should share features with speech motor actions <span class="citation">(Feinberg, <a href="#ref-feinberg_efference_1978">1978</a>; Jones &amp; Fernyhough, <a href="#ref-Jones2007">2007</a>)</span>. The <em>Motor Simulation view</em> is supported by several findings. First, covert and overt speech have comparable physiological correlates: for instance, measurements of speaking rate(Landauer, 1962) and respiratory rate <span class="citation">(B. Conrad &amp; Schönle, <a href="#ref-conrad_speech_1979">1979</a>)</span> are similar in both. A prediction of the <em>Motor Simulation view</em> is that the speech motor system should be recruited during inner speech. Subtle muscle activity has been detected in the speech musculature using electromyography (EMG) during verbal mental imagery, silent reading, silent recitation <span class="citation">(Jacobson, <a href="#ref-jacobson_electrical_1931">1931</a>; Livesay, Liebke, Samaras, &amp; Stanley, <a href="#ref-livesay_covert_1996">1996</a>; McGuigan &amp; Dollins, <a href="#ref-mcguigan_patterns_1989">1989</a>; Sokolov, <a href="#ref-sokolov_inner_1972">1972</a>)</span>, and during auditory verbal hallucination in patients with schizophrenia <span class="citation">(Rapin, Dohen, Polosan, Perrier, &amp; Lœvenbruck, <a href="#ref-Rapin2013">2013</a>)</span>. Second, it has been shown that covert speech production involves a similar cerebral network as that of overt speech production. Covert and overt speech both recruit essential language areas in the left hemisphere <span class="citation">(for a review, see Perrone-Bertolotti et al., <a href="#ref-Perrone-Bertolotti2014">2014</a>)</span>. However, there are differences. Consistent with the <em>Motor Simulation view</em> and the notion of a continuum between covert and overt speech, overt speech is associated with more activity in motor and premotor areas than inner speech <span class="citation">(e.g., Palmer et al., <a href="#ref-palmer_event-related_2001">2001</a>)</span>. This can be related to the absence of articulatory movements during inner verbal production. In a reciprocal way, inner speech involves cerebral areas that are not activated during overt speech <span class="citation">(Basho, Palmer, Rubio, Wulfeck, &amp; Müller, <a href="#ref-basho_effects_2007">2007</a>)</span>. Some of these activations (cingulate gyrus and superior rostral frontal cortex) can be attributed to the inhibition of overt responses.</p>
<p>These findings suggest that the processes involved in overt speech include those required for inner speech (except for inhibition). Several studies in patients with aphasia support this view: overt speech loss can either be associated with an impairment in inner speech <span class="citation">(e.g., Levine, Calvanio, &amp; Popovics, <a href="#ref-levine_language_1982">1982</a>; Martin &amp; Caramazza, <a href="#ref-martin_short-term_1982">1982</a>)</span> or with intact inner speech: only the later phases of speech production (execution) being affected by the lesion <span class="citation">(Baddeley &amp; Wilson, <a href="#ref-baddeley_phonological_1985">1985</a>; Marshall, Rappaport, &amp; Garcia-Bunuel, <a href="#ref-marshall_self-monitoring_1985">1985</a>; Vallar &amp; Cappa, <a href="#ref-vallar_articulation_1987">1987</a>)</span>. <span class="citation">Geva, Bennett, Warburton, &amp; Patterson (<a href="#ref-geva_discrepancy_2011">2011</a>)</span> have reported a dissociation that goes against this view, however. In three patients with chronic post-stroke aphasia (out of 27 patients), poorer homophone and rhyme judgement performance was in fact observed in covert mode compared with overt mode. A limitation of this study, though, was that the task was to detect rhymes in written words, which could have been too difficult for the patients. To overcome this limitation, <span class="citation">Langland-Hassan, Faries, Richardson, &amp; Dietz (<a href="#ref-langland-hassan_inner_2015">2015</a>)</span> have tested aphasia patients with a similar task, using images rather than written words. They also found that most patients performed better in the overt than in the covert mode. They inferred from these results that inner speech might be more demanding in terms of cognitive and linguistic load, and that inner speech may be a distinct ability, with its own neural substrates. We suggest an alternative interpretation to this dissociation. According to our view, rhyme and homophone judgements rely on auditory representations of the stimuli <span class="citation">(e.g., Paulesu, Frith, &amp; Frackowiak, <a href="#ref-paulesu_neural_1993">1993</a>)</span>. Overt speech provides a strong acoustic output that is fed back to the auditory cortex and can create an auditory trace, which can be used to monitor speech. In the covert mode, the auditory output is only mentally simulated, and its saliency in the auditory system is lesser than in the overt mode. This is in accordance with the finding that inner speech is associated with reduced sensory cortex activation compared with overt speech <span class="citation">(Shuster &amp; Lemieux, <a href="#ref-shuster_fmri_2005">2005</a>)</span>. In patients with aphasia, the weakened saliency of covert auditory signals may be accentuated for two reasons: first, because of impairment in the motor-to-auditory transformation that produces the auditory simulation, and second, because of associated auditory deficits. Therefore, according to our view, the reduced performance observed in rhyme and homophone judgement tasks in the covert compared with the overt mode in brain-injured patients, simply indicates a lower saliency of the auditory sensations evoked during inner speech compared with the actual auditory sensations fed back during overt speech production. In summary, these findings suggest that overt and covert speech share common subjective, physiological and neural correlates, supporting the claim that inner speech is a motor simulation of overt speech.</p>
<p>However, the <em>Motor Simulation view</em> has been challenged by several experimental results. Examining the properties of errors during the production of tongue twisters, <span class="citation">Oppenheim &amp; Dell (<a href="#ref-oppenheim_motor_2010">2010</a>)</span> showed that speech errors display a lexical bias in both overt and inner speech. According to these researchers, errors also display a phonemic similarity effect (or articulatory bias), a tendency to exchange phonemes with common articulatory features, but this second effect is only observed with overt speech or with inner speech accompanied with mouthing. This has led <span class="citation">Oppenheim &amp; Dell (<a href="#ref-oppenheim_motor_2010">2010</a>)</span> to claim that inner speech is fully specified at the lexical level, but that it is impoverished at lower featural (articulatory) levels. This claim, related to the <em>Abstraction view</em>, is still debated however, as a phonemic similarity effect has been found by <span class="citation">Corley, Brocklehurst, &amp; Moat (<a href="#ref-corley_error_2011">2011</a>)</span>. Their findings suggest that inner speech is in fact specified at the articulatory level, even when there is no intention to articulate words overtly. Other findings however, may still challenge the Motor Simulation view. <span class="citation">R. Netsell, Ashley, &amp; Bakker (<a href="#ref-netsell_inner_2010">2010</a>)</span> have examined covert and overt speech in persons who stutter (PWS) and typical speakers. They have found that PWS were faster in covert than in overt speech while typical speakers presented similar overt and covert speech rates. This can be interpreted in favour of the <em>Abstraction view</em>, in which inner representations are not fully specified at the articulatory level, which would explain why they are not disrupted in PWS speech. Altogether, these results suggest that full articulatory specification may not always be necessary for inner speech to be produced.</p>
<p>The aim of this study is to examine the physiological correlates of verbal rumination in an attempt to provide new data in the debate between motor simulation and abstraction. A prediction of the <em>Motor Simulation view</em> is that verbal rumination, as a kind of inner speech, should be accompanied with activity in speech-related facial muscles, as well as in negative emotion or anxiety-related facial muscles, but should not involve non-facial muscles (such as arm muscles). Alternatively, the <em>Abstraction view</em> predicts that verbal rumination should be associated with an increase in emotion-related facial activity, without activity in speech-related muscles and non-facial muscles.</p>
<p>There is strong interest in the examination of physiological correlates of rumination as traditional assessment of rumination essentially consists of self-reported measures. The measurement of rumination as conceptualized by <span class="citation">Nolen-Hoeksema (<a href="#ref-nolen-hoeksema_responses_1991">1991</a>)</span> was operationalized by the development of the Ruminative Response Scale (RRS), which is a subscale of the response style questionnaire <span class="citation">(Nolen-Hoeksema &amp; Morrow, <a href="#ref-nolen-hoeksema_prospective_1991">1991</a>)</span>. The RRS consists of 22 items that describe responses to dysphoric mood that are self-focused, symptom-focused, and focused on the causes and consequences of one’s mood. Based on this scale, <span class="citation">Treynor, Gonzalez, &amp; Nolen-Hoeksema (<a href="#ref-treynor_rumination_2003">2003</a>)</span> have offered a detailed description of rumination styles and more recently, <span class="citation">Watkins (<a href="#ref-Watkins2008">2008</a>)</span> has further characterized different modes of rumination. The validity of these descriptions is nevertheless based on the hypothesis that individuals have direct and reliable access to their internal states. However, self-reports increase reconstruction biases <span class="citation">(e.g., Brewer, <a href="#ref-rubin_what_1986">1986</a>; Conway, <a href="#ref-conway_autobiographical_1990">1990</a>)</span> and it is well known that participants have a very low level of awareness of the cognitive processes that underlie and modulate complex behaviors <span class="citation">(Nisbett &amp; Wilson, <a href="#ref-nisbett_telling_1977">1977</a>)</span>.</p>
<p>In order to overcome these difficulties, some authors have attempted to quantify state rumination and trait rumination more objectively, by recording physiological or neuroanatomical correlates of rumination <span class="citation">(for a review, see Siegle &amp; Thayer, <a href="#ref-papageorgiou_physiological_2003">2003</a>)</span>. Peripheral physiological manifestations (e.g., pupil dilation, blood pressure, cardiac rhythm, cardiac variability) have been examined during induced or chronic rumination. <span class="citation">Vickers &amp; Vogeltanz-Holm (<a href="#ref-vickers_effects_2003">2003</a>)</span> have observed an increase in systolic blood pressure after rumination induction, suggesting the involvement of the autonomic nervous system in rumination. Moreover, galvanic skin response has shown to be increased after a rumination induction, in highly anxious women <span class="citation">(Sigmon, Dorhofer, Rohan, &amp; Boulard, <a href="#ref-sigmon_impact_2000">2000</a>)</span>. According to <span class="citation">Siegle &amp; Thayer (<a href="#ref-papageorgiou_physiological_2003">2003</a>)</span>, disrupted autonomic activity could provide a reliable physiological correlate of rumination. In this line, <span class="citation">Key, Campbell, Bacon, &amp; Gerin (<a href="#ref-Key2008">2008</a>)</span> have observed a diminution of the high-frequency component of heart rate variability (HF-HRV) after rumination induction in people with a low tendency to ruminate <span class="citation">(see also Woody, McGeary, &amp; Gibb, <a href="#ref-woody_brooding_2014">2014</a>)</span>. A consistent link between perseverative cognition and decreased HRV was also found in a meta-analysis conducted by <span class="citation">Ottaviani et al. (<a href="#ref-Ottaviani2015">2015</a>)</span>. Based on these positive results and on suggestions that labial EMG activity may accompany inner speech and therefore rumination, our aim was to examine facial EMG as a potential correlate of rumination and HRV as an index to examine concurrent validity.</p>
<p>In addition to labial muscular activity, we also recorded forehead muscular activity (i.e., <em>frontalis</em> muscle) because of its implication in prototypical expression of sadness <span class="citation">(e.g., Ekman &amp; Friesen, <a href="#ref-ekman_facial_1978">1978</a>; Kohler et al., <a href="#ref-kohler_differences_2004">2004</a>)</span>, reactions to unpleasant stimuli <span class="citation">(Jäncke, Vogt, Musial, Lutz, &amp; Kalveram, <a href="#ref-Jancke1996">1996</a>)</span>, and anxiety or negative emotional state <span class="citation">(A. Conrad &amp; Roth, <a href="#ref-conrad_muscle_2007">2007</a>)</span><a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a>. Our hypothesis was that <em>frontalis</em> activity could be an accurate electromyographic correlate of induced rumination, as a negatively valenced mental process.</p>
<p>In this study, we were also interested in the effects of relaxation on induced rumination. Using a relaxation procedure targeted on muscles involved in speech production is a further way to test the reciprocity of the link between inner speech (verbal rumination) and orofacial muscle activity. If verbal rumination is a kind of action, then its production should be modulated in return by the effects of relaxation on speech effectors. This idea is supported by the results of (among others) <span class="citation">Cefidekhanie, Savariaux, Sato, &amp; Schwartz (<a href="#ref-cefidekhanie_interaction_2014">2014</a>)</span>, who have observed substantial perturbations of inner speech production while participants had to realize forced movements of the articulators.</p>
<p>In summary, the current study aimed at evaluating the <em>Motor Simulation view</em> and the <em>Abstraction view</em> by using objective and subjective measures of verbal rumination. To test the involvement of the orofacial motor system in verbal rumination, we used two basic approaches. In the first approach, we induced verbal rumination and examined concurrent changes in facial muscle activity (Experiment 1). In the second approach, we examined whether orofacial relaxation would reduce verbal rumination levels (Experiment 2). More specifically, in Experiment 1, we aimed to provide an objective assessment of verbal rumination using quantitative physiological measures. Thus, we used EMG recordings of muscle activity during rumination, focusing on the comparison of speech-related (i.e., two lip muscles − <em>orbicularis oris superior</em> and <em>orbicularis oris inferior</em>) and speech-unrelated (i.e., forehead −<em>frontalis</em>- and forearm − <em>flexor carpi radialis</em>) muscles. Under the <em>Motor Simulation view</em>, an increase in lip and forehead EMG activity should be observed after rumination induction, with no change in forearm EMG activity, associated with an increase in self-reported rumination. Alternatively, under the <em>Abstraction view</em>, an increase in forehead activity should be observed, associated with an increase in self-reported rumination, and no changes in either lip or forearm activity should be noted.</p>
<p>In Experiment 2, in order to assess the reciprocity of the rumination and orofacial motor activity relationship, we evaluated the effects of orofacial relaxation on rumination. More specifically, we compared three kinds of relaxation: i) Orofacial Relaxation (i.e., lip muscles), ii) Arm Relaxation (i.e., to differentiate effects specific to speech-related muscle relaxation) and iii) Story Relaxation (i.e., to differentiate effects specific to attentional distraction). If the <em>Motor simulation view</em> is correct, we predicted a larger decrease of lip and forehead muscle activity after an Orofacial Relaxation than after an Arm Relaxation (associated with a larger decrease in self-reported rumination), which should also be larger than after listening to a story. We also predicted that forearm activity should remain stable across the three conditions (i.e., should not decrease after relaxation). Alternatively, if the <em>Abstraction view</em> is correct, we predicted that none of the relaxation conditions should have an effect on lip or arm activity, because none of these should have increased after induction. However, we expected to observe a decrease in forehead activity and self-reported rumination after Orofacial or Arm relaxation, this decrease being larger than after listening to a Story. Importantly, we predicted that, under the <em>Abstraction View</em> no superiority of the Orofacial relaxation should be observed over the Arm relaxation.</p>
</div>
<div id="methods" class="section level2">
<h2><span class="header-section-number">3.3</span> Methods</h2>
<div id="participants" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Participants</h3>
<p>Because of the higher prevalence of rumination in women than in men <span class="citation">(see Johnson &amp; Whisman, <a href="#ref-Johnson2013">2013</a>, for a recent meta-analysis)</span>, we chose to include female participants only. Seventy-two female undergraduate students from Univ. Grenoble Alpes, native French speaking, participated in our study. One participant presenting aberrant data (probably due to inadequate sensor sticking) was removed from analyses. Final sample consisted of seventy-one undergraduate female students (M<sub>age</sub> = 20.58, SD<sub>age</sub> = 4.99). They were recruited by e-mail diffusion lists and participated in the experiment for course credits. They did not know the goals of the study. The cover story presented the research as aiming at validating a new I.Q. test, more sensitive to personality profiles. Participants reported having no neurologic or psychiatric medical history, no language disorder, no hearing deficit, and taking no medication. Each participant gave written consent and this study has been approved by the local ethical committee (CERNI, N° 2015-03-03-61).</p>
</div>
<div id="material" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Material</h3>
<p>EMG signals were detected with Trigno<sup>TM</sup> Mini sensors (Delsys Inc.) at a sampling rate of 1926 samples/s with a band pass of 20 Hz (12 dB/ oct) to 450 Hz (24 dB/oct) and were amplified by a Trigno<sup>TM</sup> 16-channel wireless EMG system (Delsys Inc.). The sensors consisted of two 5 mm long, 1 mm wide parallel bars, spaced by 10 mm, which were attached to the skin using double-sided adhesive interfaces. The skin was cleaned by gently scrubbing it with 70% isopropynol alcohol. EMG signals were then synchronized using the PowerLab 16/35 (ADInstrument, PL3516). Raw data from the EMG sensors were then resampled at a rate of 1 kHz and stored in digital format using Labchart 8 software (ADInstrument, MLU60/8). As shown in Figure <a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#fig:emgface">3.1</a>, bipolar surface EMG recordings were obtained from two speech-related labial muscles: <em>orbicularis oris superior</em> (OOS) and <em>orbicularis oris inferior</em> (OOI), as well as from one non speech-related but negative-affect-related facial muscle: <em>frontalis</em> (FRO) and from one non-facial and non speech-related muscle: <em>flexor carpi radialis</em> (FCR) on the non-dominant forearm. The latter pair of electrodes was used to check whether the rumination induction would cause any muscle contraction, outside of the facial muscles. The same sensor layout was used for all participants. Asymmetrical movements of the face have been shown in speech and emotional expression. As reviewed in <span class="citation">Everdell, Marsh, Yurick, Munhall, &amp; Paré (<a href="#ref-everdell_gaze_2007">2007</a>)</span>, the dominant side of the face displays larger movements than the left during speech production, whereas the non-dominant side is more emotionally expressive. To optimise the capture of speech-related activity, the OOS and OOI sensors were therefore positioned on the dominant side of the body (i.e. the right side for right-handed participants). To optimise the capture of emotion-related activity, the FRO sensor was positioned on the non-dominant side. To minimise the presence of involuntary manual gestures during the recording, the FCR sensor was positioned on the non-dominant side. Each pair of electrodes was placed parallel with the direction of the muscle fibers, at a position distant from the innervation zones and the muscle tendon interface, following the recommendations of <span class="citation">De Luca (<a href="#ref-de_luca_use_1997">1997</a>)</span>. The experiment was video-monitored using a Sony HDR-CX240E video camera to track any visible facial movements. A microphone was placed 20–30 cm away from the participant’s lips to record any faint vocal production during rumination. Stimuli were displayed with E-prime 2.0 (<a href="http://www.pstnet.com" class="uri">http://www.pstnet.com</a>) on a 19-inch color monitor.</p>
<div class="figure" style="text-align: center"><span id="fig:emgface"></span>
<img src="assets/face_emg.jpg" alt="Facial muscles of interest. Two speech-related labial muscles: \textit{orbicularis oris superior} (OOS) and \textit{orbicularis oris inferior} (OOI); as well as one non speech-related but sadness-related facial muscle: \textit{frontalis} (FRO)." width="75%" />
<p class="caption">
Figure 3.1: Facial muscles of interest. Two speech-related labial muscles:  (OOS) and  (OOI); as well as one non speech-related but sadness-related facial muscle:  (FRO).
</p>
</div>
</div>
<div id="procedure" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Procedure</h3>
<p>This study consisted of two parts. The first part was carried out a week before the EMG experiment and consisted in checking the inclusion criteria. We checked that participants did not exceed a threshold on a depressive symptoms scale. This was assessed using the French version of the <em>Center for Epidemiologic Studies Depression</em> scale <span class="citation">(CES-D, Fuhrer &amp; Rouillon, <a href="#ref-fuhrer_version_1989">1989</a>)</span>, which evaluates the level of depressive symptom in subclinical population. We also collected information about any potential speech, neurologic, neuromuscular or cardiac disorders and about academic curriculum. Finally, the tendency to ruminate (i.e., trait rumination) in daily life was evaluated using the French version of the Mini-CERTS <span class="citation">(Cambridge-Exeter Repetitive Thought Scale, Douilliez, Philippot, Heeren, Watkins, &amp; Barnard, <a href="#ref-Douilliez2012">2012</a>)</span>. The second part included two EMG interdependent experiments related to <em>Rumination Induction</em> and <em>Rumination Reduction by Muscle Relaxation</em>. Specifically, Experiment 1 consisted of acquiring physiological EMG data during rest and induced rumination and Experiment 2 consisted of acquiring physiological EMG data after different kinds of relaxation (see below).</p>
<p>During both Experiment 1 and Experiment 2, momentary rumination was assessed using four different Visual Analogue Scales <span class="citation">(VAS, the first two being adapted and translated to French from Huffziger, Ebner-Priemer, Koudela, Reinhard, &amp; Kuehner, <a href="#ref-Huffziger2012">2012</a>)</span> rated from 0 to 100: i) “At this moment, I am thinking about my feelings” (referred to as VAS “<em>Feelings</em>”), ii) “At this moment, I am thinking about my problems” (referred to as VAS “<em>Problems</em>”), iii) “At this moment, I am brooding about negative things” (referred to as VAS “<em>Brooding</em>”) and iv) “At this moment, I am focused on myself” (referred to as VAS “<em>Focused</em>”).</p>
<div id="experiment-1-rumination-induction" class="section level4">
<h4><span class="header-section-number">3.3.3.1</span> Experiment 1: rumination induction</h4>
<p>Participants were seated in front of a computer screen in a comfortable and quiet room. EMG sensors were positioned as explained above (see Figure <a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#fig:emgface">3.1</a>). Before the rumination induction, each participant underwent a non-specific relaxation session (i.e., without targeting specific muscles) in order to minimize inter-individual initial thymic variability (approximate duration ∼330 s). Immediately after, participants were instructed to remain silent and not to move for one minute to carry out EMG “baseline” measurements. Then, participants’ initial level of rumination was assessed using the four VASs.</p>
<p>Subsequently, participants were invited to perform a 15-min I.Q. test, which was presented on the computer screen facing them. They were instructed to correctly respond to three types of I.Q. questions (logical, mathematical and spatial-reasoning questions) in a very short time (30 s). Most of the questions were very difficult, if not impossible, to correctly answer in 30 s. We included ten different questions for each of the three types of I.Q. question: ten logical questions (e.g., finding the next number of a Fibonacci sequence), ten mathematical questions (e.g., “What is the result of the following calculus: (30/165) − (70/ 66)”) and ten spatial-reasoning questions (e.g., finding the next figure of a series). Forced-failure tasks have extensively been employed in the literature to induce a slightly negative mood, ideal for subsequent rumination induction <span class="citation">(e.g., Lemoult &amp; Joormann, <a href="#ref-Lemoult2014">2014</a>; Randenborgh, Hüffmeier, LeMoult, &amp; Joormann, <a href="#ref-VanRandenborgh2010">2010</a>)</span>.</p>
<p>After the I.Q. test, participants were invited to reflect upon the causes and consequences of their feelings, during five minutes (rumina- tion induction). This method is based on the induction paradigm developed by <span class="citation">Nolen-Hoeksema &amp; Morrow (<a href="#ref-nolen-hoeksema_effects_1993">1993</a>)</span>. The classical paradigm uses a series of prompts. In order to avoid the potential confound in muscle activity induced by silent reading, we did not use the full paradigm. We simply summarised the series of prompts by one typical induction sentence. During this period, participants were asked to remain silent and not to move, while EMG recordings were carried out (i.e., EMG Post-induction measures). EMG signals of rumination were collected during the last minute of this period. Finally, participants were instructed to self-report momentary rumination on the four VASs.</p>
</div>
<div id="experiment-2-rumination-reduction-by-relaxation" class="section level4">
<h4><span class="header-section-number">3.3.3.2</span> Experiment 2: rumination reduction by relaxation</h4>
<p>After Experiment 1, participants were randomly allocated to one of three groups. In the first group, participants listened to a pre-recorded relaxation session that was focused on orofacial speech-related muscles (“<em>Orofacial Relaxation</em>” condition). In the second group, relaxation was focused on the arm muscles (“<em>Arm Relaxation</em>” condition). In the third group, participants simply listened to a story, read by the same person, for an equivalent duration (“<em>Story</em>” condition, detailed content of the story can be found in the <a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#suppCH3">supplementary materials</a>, in French). In summary, the first condition allowed us to evaluate the effects of targeted speech muscle relaxation on rumination. The second condition allowed evaluating the effects of a non-orofacial relaxation (i.e., speech-unrelated muscles) while the third condition allowed controlling for effects of attentional distraction during relaxation listening.</p>
<p>The speeches associated with the three conditions, relaxation sessions and story listening session, were delivered to the participants through loudspeakers. They were recorded by a professional sophrology therapist in an anechoic room at GIPSA-lab (Grenoble, France) and were approximately of the same duration (around 330 s).</p>
<p>After the relaxation/distraction session, participants were asked to remain silent and not to move during one minute, during which EMG measurements were collected (EMG Post-relaxation measures). Finally, participants were instructed to self-report rumination on the four VASs.</p>
</div>
</div>
<div id="data-processing-and-analysis" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Data processing and analysis</h3>
<div id="emg-data-processing" class="section level4">
<h4><span class="header-section-number">3.3.4.1</span> EMG data processing</h4>
<p>EMG signal pre-processing was carried out using Labchart 8. The EMG data were high-pass filtered using a Finite Impulse Response (FIR) filter at a cut-off of 20 Hz, using the Kaiser window method with <span class="math inline">\(\beta\)</span> = 6. Then, output of this first filter was to a low-pass filtered at a cut-off of 450 Hz (with the same parameters), in order to focus on the 20–450 Hz frequency band, following current recommendations for facial EMG studies <span class="citation">(A. Boxtel, <a href="#ref-boxtel_optimal_2001">2001</a>; De Luca, <a href="#ref-de_luca_use_1997">1997</a>; De Luca, Donald Gilmore, Kuznetsov, &amp; Roy, <a href="#ref-de_luca_filtering_2010">2010</a>)</span>.</p>
<p>Although we specifically asked participants to remain silent and not to move during EMG data collection, tiny facial movements (such as biting one’s lips) or vocal productions sometimes occurred. Periods with such facial movement or vocal production were excluded from the analysis. To do this, visual inspection of audio, video, and EMG signal was performed. Specifically, for the EMG signals, we compared two methods of signal selection. The first one consisted of setting a threshold on the absolute value of the EMG signal and portions of signals above this threshold were removed. This threshold was empirically chosen using visual inspection of a few samples and set to the mean EMG value plus 6 SDs. The second method consisted of manually removing periods of time that included visually obvious bursts of EMG activity, corresponding to overt contraction <span class="citation">(as in Rapin, Dohen, Polosan, &amp; Perrier, <a href="#ref-rapin_emg_2013">2013</a>)</span>. Based on samples from a few participants, the comparisons between these two methods showed that the automatic threshold method was somewhat less sensitive to overt movements. Therefore, the second method was used, as it was more conservative and less prone to leave data related to irrelevant overt movements.</p>
<p>After pre-processing, EMG data were exported from Labchart software to Matlab r2014a (Version 8.3.0.532, www.mathworks.fr). For each EMG signal, mean values were computed under Matlab, using 200 ms sliding windows. The average of these mean values were calculated for each recording session (baseline, after induction and after relaxation/induction). This provided a score for each muscle of interest (OOS, OOI, FCR, FRO) in each Session (Baseline, Post-Induction, Post-Relaxation) for each participant<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a>.</p>
</div>
<div id="statistical-analyses" class="section level4">
<h4><span class="header-section-number">3.3.4.2</span> Statistical analyses</h4>
<p>Absolute EMG values are not meaningful as muscle activation is never null, even in resting conditions, due in part to physiological noise <span class="citation">(Tassinary, Cacioppo, &amp; Vanman, <a href="#ref-berntson_skeletomotor_2007">2007</a>)</span>. In addition, there are inter-individual variations in the amount of EMG activity in the baseline. To normalise for baseline activity across participants, we used a differential measure and expressed EMG amplitude as a percentage of baseline level (Experiment 1) or of post-induction level (Experiment 2).</p>
<p>To model EMG amplitude variations in response to the rumination induction (Experiment 1) and relaxation (Experiment 2), we used a bayesian multivariate regression model with the natural logarithm of the EMG amplitude (expressed in % of baseline level) as an outcome, in an intercept-only model (in Experiment 1), and using Condition (Orofacial, Arm or Story) as a categorical predictor in Experiment 2. We used the same strategy (two multivariate models) to analyse VAS scores (expressed in relative changes) along the two experiments.</p>
<p>These analyses were conducted using RStudio (RStudio Team, 2018) and the <code>brms</code> package <span class="citation">(Bürkner, <a href="#ref-R-brms">2018</a>)</span>, an <code>R</code> implementation of Bayesian multilevel models that employs the probabilistic programming language <code>Stan</code> <span class="citation">(Carpenter et al., <a href="#ref-carpenter_stan:_2017">2017</a>)</span>. Stan implements gradient-based Markov Chain Monte Carlo (MCMC) algorithms (e.g., Hamiltonian Monte-Carlo), which allow yielding posterior distributions that are straightforward to use for interval estimation around all parameters. Two MCMC simulations (or “chains”) were run for each model, including 100,000 iterations, a warmup of 10,000 iterations, and a thinning interval of 10. Posterior convergence was assessed examining autocorrelation and trace plots, as well as the Gelman-Rubin statistic. Fixed effects were estimated via the posterior mean and 95% highest density intervals (HDIs), where an HDI interval is the Bayesian analogue of a classical confidence interval<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a>.</p>
<p>This strategy allowed us to examine posterior probability distribution on each parameter of interest (i.e., effects of session and condition on each response variable). When applicable, we also report evidence ratios (ERs), computed using the hypothesis function of the <code>brms</code> package <span class="citation">(Bürkner, <a href="#ref-R-brms">2018</a>)</span>. These evidence ratios are simply the posterior probability under a hypothesis against its alternative <span class="citation">(Bürkner, <a href="#ref-R-brms">2018</a>)</span>. We also report summary statistics (mean and HDI) of Cohen’s d effect sizes, computed from the posterior samples.</p>
</div>
</div>
</div>
<div id="results" class="section level2">
<h2><span class="header-section-number">3.4</span> Results</h2>
<div id="experiment-1-rumination-induction-1" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Experiment 1: rumination induction</h3>
<p>The evolution of VAS scores (for the four assessed scales: Feelings, Problems, Brooding, and Focused) and EMG (for the four muscles: OOS, OOI, FCR and FRO) activity from baseline to post-induction were examined.</p>
<div id="self-reported-rumination-measures-vas-scores" class="section level4">
<h4><span class="header-section-number">3.4.1.1</span> Self-reported rumination measures: VAS scores</h4>
<p>Results for VAS relative changes based on the multivariate models described earlier are shown in the right panel of Figure <a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#fig:resultsemgfig1">3.2</a>. Thereafter, <span class="math inline">\(\alpha\)</span> represents the mean of the posterior distribution of the intercept. Raw pre- and post-induction scores are provided in the <a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#suppCH3">supplementary materials</a>.</p>
<p>Mean VAS score on the Feelings scale was slightly lower after induction (<span class="math inline">\(\alpha\)</span> = −5.55, 95% HDI [-10.89, −0.24], d = −0.23, 95% HDI [-0.46, −0.01]), while Problems score was slightly higher (<span class="math inline">\(\alpha\)</span> = 3.99, 95% HDI [-2.04, 9.83], d = 0.15, 95% HDI [-0.08, 0.37]). We observed a strong increase of the score on the Brooding scale (<span class="math inline">\(\alpha\)</span> = 14.45, 95% HDI [8.07, 20.72], d = 0.50, 95% HDI [0.26, 0.74]), and a strong decrease on the Focused scale (<span class="math inline">\(\alpha\)</span> = −11.63, 95% HDI [-17, −6.07], d = −0.48, 95% HDI [-0.72, −0.24]). As we examined the fit of the intercept-only model, these estimates represent the posterior mean for each muscle.</p>
<p>In the following, we report the mean (indicated by the Greek symbol <span class="math inline">\(\rho\)</span>) and the 95% HDI of the posterior distribution on the correlation coefficient (<span class="math inline">\(\rho\)</span>). Examination of the correlation matrix estimated by the multivariate model revealed no apparent correlation neither between Feelings and Problems scales (<span class="math inline">\(\rho\)</span> = −0.01, 95% HDI [-0.23, 0.22]), nor between Feelings and Brooding (<span class="math inline">\(\rho\)</span> = 0.08, 95% HDI [-0.15, 0.30]). However, we observed a strong positive correlation between Problems and Brooding VASs (<span class="math inline">\(\rho\)</span> = 0.64, 95% HDI [.49, 0.76]), a positive correlation between Feelings and Focused (<span class="math inline">\(\rho\)</span> = 0.30, 95% HDI [.08, 0.50]), and a negative correlation between Problems and Focused (<span class="math inline">\(\rho\)</span> = −0.30, 95% HDI [-0.49, −0.08]), as well as between Brooding and Focused (<span class="math inline">\(\rho\)</span> = −0.18, 95% HDI [-0.39, 0.05]).</p>
<div class="figure" style="text-align: center"><span id="fig:resultsemgfig1"></span>
<img src="assets/emg_fig1.pdf" alt="Posterior mean (white dots) and 95\% credible intervals for the EMG amplitude (expressed in percentage of baseline level, left panel), and the VAS score (expressed in relative change from baseline, right panel). N = 71 (for each muscle and each VAS). Dashed line represents the null value (i.e., 100\% for the EMG amplitude and 0 for the VAS scores)." width="100%" />
<p class="caption">
Figure 3.2: Posterior mean (white dots) and 95% credible intervals for the EMG amplitude (expressed in percentage of baseline level, left panel), and the VAS score (expressed in relative change from baseline, right panel). N = 71 (for each muscle and each VAS). Dashed line represents the null value (i.e., 100% for the EMG amplitude and 0 for the VAS scores).
</p>
</div>
</div>
<div id="emg" class="section level4">
<h4><span class="header-section-number">3.4.1.2</span> EMG</h4>
<p>Results for EMG data based on the multivariate model described earlier are shown in the left panel of Figure <a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#fig:resultsemgfig1">3.2</a>. Summary statistics were computed on posterior samples transformed back from log scale.</p>
<p>Mean EMG amplitude for OOS was higher after induction (<span class="math inline">\(\alpha\)</span> = 138.57, 95% HDI [124.43, 151.71], d = 0.66, 95% HDI [0.49, 0.84]) as well as for OOI (<span class="math inline">\(\alpha\)</span> = 163.89, 95% HDI [145.24, 184.14], d = 0.77, 95% HDI [0.61, 0.94]), and FRO (<span class="math inline">\(\alpha\)</span> = 197.55, 95% HDI [166.59, 228.42], d = 0.74, 95% HDI [0.59, 0.89]). Effects on the FCR were approximately null (<span class="math inline">\(\alpha\)</span> = 100.10, 95% HDI [97.48, 102.76], d = 0.01, 95% HDI [-0.24, 0.23]).</p>
<p>Examination of the correlation matrix estimated by the bayesian multivariate model revealed a positive correlation between OOS and OOI EMG amplitudes (<span class="math inline">\(\rho\)</span> = 0.44, 95% HDI [.24, 0.61]), while no apparent correlations neither between OOS and FCR (<span class="math inline">\(\rho\)</span> = 0.09, 95% HDI [-0.14, 0.31]), OOS and FRO (<span class="math inline">\(\rho\)</span> = 0.12, 95% HDI [-0.11, 0.35]), OOI and FCR (<span class="math inline">\(\rho\)</span> = 0.02, 95% HDI [-0.21, 0.25]), FRO and FCR (<span class="math inline">\(\rho\)</span> = −0.06, 95% HDI [-0.28, 0.17]), nor OOI and FRO (<span class="math inline">\(\rho\)</span> = 0.07, 95% HDI [-0.16, 0.29]). Scatterplots, marginal posterior distributions and posterior distributions on correlation coefficients are available in <a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#suppCH3">supplementary materials</a>.</p>
<p>In order to check whether the propensity to ruminate could predict the effects of the rumination induction on EMG amplitude, we compared the multivariate model described above, with a similar model but with the score on the abstract dimension of the Mini-CERTS as an additional predictor. We compared these models using the widely applicable information criterion (WAIC; Watanabe, 2010), via the WAIC function of the <code>brms</code> package <span class="citation">(Bürkner, <a href="#ref-R-brms">2018</a>)</span>. Results showed that the intercept-only model had a lower WAIC (WAIC = 177.39) than the more complex model (WAIC = 182.01), indicating that there is no predictive benefit in adding the Mini-CERTS score as a predictor.</p>
</div>
<div id="correlations-between-emg-amplitudes-and-vas-scores" class="section level4">
<h4><span class="header-section-number">3.4.1.3</span> Correlations between EMG amplitudes and VAS scores</h4>
<p>Correlations between EMG amplitudes and VAS scores were examined using the <code>BayesianFirstAid</code> package <span class="citation">(Bååth, <a href="#ref-R-BayesianFirstAid">2018</a>)</span>, using 15,000 iterations for each correlation coefficient. Both estimated correlation coefficients (<span class="math inline">\(\rho\)</span>s) and 95% HDIs are reported in Table XX.</p>
<!-- insert table 1 here -->
</div>
</div>
<div id="experiment-2-rumination-reduction-by-relaxation-1" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Experiment 2: rumination reduction by relaxation</h3>
<p>In the second experiment, we aimed at comparing the evolution in EMG activity and VAS scores from post-induction to post-relaxation in three different conditions: Orofacial relaxation, Arm relaxation, and listening to a Story.</p>
<div id="self-reported-rumination-measures-vas-scores-1" class="section level4">
<h4><span class="header-section-number">3.4.2.1</span> Self-reported rumination measures: VAS scores</h4>
<p>Posterior means and 95% HDIs of the VAS scores in each condition of experiment 2 are represented in Figure XX and Table XX.</p>
<p>In order to compare the effects of the two kind of relaxation on the VAS scores, we then used the <code>hypothesis()</code> function of the <code>brms</code> package that allows deriving evidence ratios (ER). These evidence ratios are simply the posterior probability under a hypothesis (e.g., the hypothesis that the Orofacial relaxation session would be more effective in reducing self-reported rumination than the Arm relaxation session) against its alternative <span class="citation">(Bürkner, <a href="#ref-R-brms">2018</a>)</span>.</p>
<p>Since the Problems and the Brooding scales seemed to be sensitive markers of rumination (as their scores increased after induction in Experiment 1), our analyses were focused on these two scales.</p>
<p>Concerning the Problems VAS, the decrease observed in the Orofacial condition was more pronounced than in the Arm condition (Est = −11.06, SE = 6.35, ER10 = 22.65), and slightly more pro- nounced compared to the Story condition (Est = −6.05, SE = 6.31, ER10 = 4.98). The observed on the Brooding VAS score in the Orofacial condition was larger than in the Arm condition (Est = −9.98, SE = 6.07, ER10 = 18.85), and slightly more important compared to the Story condition (Est = −5.23, SE = 6.01, ER10 = 4.27).</p>
<div class="figure" style="text-align: center"><span id="fig:resultsemgfig2"></span>
<img src="assets/emg_fig2.pdf" alt="Posterior mean and 95\% credible intervals for the VAS score (expressed in relative change from post-induction level)." width="75%" />
<p class="caption">
Figure 3.3: Posterior mean and 95% credible intervals for the VAS score (expressed in relative change from post-induction level).
</p>
</div>
<!-- insert table 2 here -->
</div>
<div id="emg-1" class="section level4">
<h4><span class="header-section-number">3.4.2.2</span> EMG</h4>
<p>Posterior means and 95% HDIs of the EMG amplitude in each condition of experiment 2 are represented in Figure XX and reported in Table XX. We used the same strategy as before to compare the effects of the two kinds of relaxation on the EMG amplitudes.</p>
<p>Concerning the OOS, the observed decrease in the Orofacial condition was more pronounced than in the Arm condition (Est = −0.34, SE = 0.14, ER10 = 140.73), as well as concerning the OOI (Est = −0.35, SE = 0.19, ER10 = 29.46), while we observed no noticeable differences between the two kinds of relaxation concerning the EMG amplitude of the FRO (Est = -0.04, SE = 0.14, ER10 = 1.53).</p>
<div class="figure" style="text-align: center"><span id="fig:resultsemgfig3"></span>
<img src="assets/emg_fig3.pdf" alt="Posterior mean and 95\% credible intervals for the VAS score (expressed in relative change from post-induction level)." width="75%" />
<p class="caption">
Figure 3.4: Posterior mean and 95% credible intervals for the VAS score (expressed in relative change from post-induction level).
</p>
</div>
<!-- insert table 2 here -->
</div>
</div>
</div>
<div id="discussion" class="section level2">
<h2><span class="header-section-number">3.5</span> Discussion</h2>
<div id="experiment-1" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Experiment 1</h3>
<p>In the first experiment, we examined electromyographic correlates of induced rumination in healthy individuals. According to the <em>Motor Simulation view</em>, we predicted an increase in the activity of all facial muscles after the rumination induction, associated with an increase in self-reported rumination. Alternatively, the <em>Abstraction view</em> predicted an increase in self-reported rumination associated with an increase in forehead activity with no changes in either lip or forearm activity.</p>
<p>To test the predictions of these two theoretical views, we compared EMG measures and VAS scores after induction to their values before induction. EMG activity was examined in four muscles: OOS and OOI, two muscles involved in speech production, FRO, a facial negative- affect-related but not speech-related muscle, and FCR, a non-facial control muscle on the non-dominant forearm.</p>
<p>As predicted by the <em>Motor Simulation view</em>, we observed an increase in the activity of the two speech-related muscles (OOS &amp; OOI) as well as in the negative-affect-related muscle (FRO) and no change in FCR activity. The increase in facial EMG together with the increase in the subjective reports of rumination suggests that facial EMG increase is a correlate of verbal rumination. As supported by several studies results, the forehead muscle activity has been associated with unpleasant emotions <span class="citation">(Jäncke et al., <a href="#ref-Jancke1996">1996</a>)</span> or anxiety <span class="citation">(A. Conrad &amp; Roth, <a href="#ref-conrad_muscle_2007">2007</a>)</span>. The increase in FRO activity observed here is consistent with the increase in negative emotions induced by our negatively valenced induction procedure. <em>Orbicularis oris</em> lip muscles are associated with speech production. The increase in lip activity observed here suggests that the speech motor system was involved during the ruminative phase. The fact that the FCR remained stable after rumination induction suggests that the observed facial activity increase was not due to general body tension induced by a negative mental state. These facial EMG results therefore support the hypothesis that rumination is an instance of articulatory-specified inner speech.</p>
<p>After the rumination induction, a larger increase in OOI activity was observed compared to the increase in OOS activity. This finding is consistent with previous findings of higher EMG amplitude in the lower lip during speech and inner speech <span class="citation">(e.g., S. M. Barlow &amp; Netsell, <a href="#ref-barlow_differential_1986">1986</a>; Regalo et al., <a href="#ref-regalo_electromyographic_2005">2005</a>; Sokolov, <a href="#ref-sokolov_inner_1972">1972</a>)</span> or auditory verbal hallucinations <span class="citation">(Rapin et al., <a href="#ref-rapin_emg_2013">2013</a>)</span>. <span class="citation">Rapin et al. (<a href="#ref-rapin_emg_2013">2013</a>)</span> have explained the difference between the activities of the two lip muscles by muscle anatomy. The proximity of the OOI muscle with other speech muscles (such as the depressor angular muscle or the mentalis) could increase the surface EMG signal captured on the lower lip (OOI), as compared to the upper lip (OOS) during speech. An even larger increase in FRO activity was observed compared to the increase in lip muscle activity. As EMG amplitude is known to vary with muscle length <span class="citation">(Babault, Pousson, Michaut, &amp; Van Hoecke, <a href="#ref-babault_effect_2003">2003</a>)</span>, the greater increase in frontalis activity could be explained by its anatomical properties.</p>
<p>However, although a functional distinction can be drawn between the forehead and the lip muscles, one should acknowledge the fact that these two sets of muscles can be commonly activated during some behaviours. For instance, <span class="citation">A. van Boxtel &amp; Jessurun (<a href="#ref-van_boxtel_amplitude_1993">1993</a>)</span> have shown that orbicularis oris inferior and frontalis were both activated during a two-choice serial reaction task in which nonverbal auditory or visual signals were presented. Moreover, there was a gradual increase in EMG activity in these muscles during the task, either when the task was prolonged or when the task was made more difficult. They interpreted this increase in EMG activity as associated with a growing compensatory effort to keep performance at an adequate level. An alternative interpretation is that the increase in task difficulty was dealt with by inner verbalization. Covertly rehearsing the instructions or covertly qualifying the stimuli might have helped the participants to perform adequately. Therefore, the increase in orbicularis oris activity might have been related to an increase in covert verbalization, whereas the increase in frontalis activity might have been related to increased anxiety or tension. The fact that the EMG increase was muscle specific, and that some facial muscles (<em>orbicularis oculi</em>, <em>zygomaticus major</em>, <em>temporalis</em>) did not show an increase in activity unless the task became too difficult, supports this interpretation. It cannot be ruled out, however, that orbicularis oris activity may in some cases be related to mental effort without mental verbalisation. Nevertheless, although the I.Q. test itself was designed to induce mental effort, no cognitively demanding task was asked to the participant during the period of EMG recording (i.e., approximately four minutes after the end of the test). Although we cannot absolutely exclude that rumination in itself could require cognitive effort, it seems unlikely that mental effort was the main factor of variation.</p>
<p>Scores on the VAS need to be discussed in further detail. We examined which VAS scales were most suitable to capture changes in state rumination to allow focused analyses. Due to the “pre-baseline” relaxation session, during which participants were asked to concentrate on their body and breathing cycles, participants reported a high level of attentional self-focus at baseline (“Feelings” and “Focused” VAS). Because of the high level of self-focused attention at baseline, it is likely that the scores on the “Feelings” and “Focused” VAS did not show the expected increase after rumination induction (ceiling effect). The scores on the scales “Problems” and “Brooding”, which are more representative of maladaptive rumination, did increase after our rumination induction paradigm, however. Interestingly, the “Brooding” VAS corresponded to a larger increase and seemed to be more sensitive to rumination induction than the “Problems” VAS. Given this greater sensibility and the strong positive correlation between the “Brooding” and the “Problems” VAS, it thus make sense to consider the “Brooding” VAS as a better estimate of ruminative state, at least within our paradigm. We will therefore only use this scale to assess rumination in the following.</p>
<p>The fact that we did not observe any association between the propensity to ruminate (as measured by the Mini-CERTS questionnaire) and the effects of the induction is consistent with the results of <span class="citation">Rood, Roelofs, Bögels, &amp; Arntz (<a href="#ref-Rood2012">2012</a>)</span> who found that the level of trait rumination did not moderate the effects of a rumination induction.</p>
</div>
<div id="experiment-2" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Experiment 2</h3>
<p>In the second experiment, we studied the effects of two muscle-specific relaxation sessions: Orofacial relaxation and Arm relaxation. We compared their effects to a third control condition (Story), which did not involve the deliberate relaxation of any specific muscle. Our predictions were that a decrease in facial EMG activity should be observed in each condition. If the <em>Motor Simulation view</em> is correct, we expected a larger decrease in the activity of all facial muscles in the “Orofacial relaxation” condition than in the “Arm relaxation” condition, associated with a larger decrease in self-reported rumination. Additionally, we expected a more pronounced decrease in the two relaxation conditions (orofacial and arm relaxation conditions) than in the control (“Story”) condition. We also expected no difference between relaxation conditions regarding the change in the forearm muscle activity.</p>
<p>The data indicated a decrease in self-reported rumination (“Brooding” VAS) in each condition. The “Orofacial” relaxation condi- tion elicited a slightly larger decrease than the “Arm relaxation” or the “Story” condition. However, there was extensive individual variation in response to these conditions. As concerns EMG results, we observed a decrease in OOS and OOI activities in all three conditions but this decrease was more pronounced in the orofacial condition than in the other two conditions. The frontalis activity did not show the same pattern. A similar FRO activity decrease was observed in both the orofacial and the non-orofacial relaxation conditions. Therefore, in Experiment 2, the lip muscles and the forehead muscle follow differential evolutions. A dissociation was observed: whereas both orofacial and arm relaxations resulted in a decrease in forehead activity, only orofacial relaxation was successful at reducing lip activity.</p>
<p>Considering both VAS results and the dissociation in EMG patterns, several interpretations are possible. The first interpretation is that verbal production associated with rumination was more reduced by orofacial muscular relaxation than by non-orofacial relaxation. This interpretation is consistent with the fact that the “Brooding” VAS was slightly more decreased in this condition compared to the other two. The larger decrease in OOS and OOI amplitude after orofacial relaxa- tion would thus reflect this reduction in verbal production, as hypothesised by the <em>Motor Simulation view</em>. The fact that FRO activity displayed a similar decrease in both orofacial and non-orofacial relaxation conditions could suggest that any means of body relaxation (be it orofacial or not) is appropriate to reduce negative affect and can therefore reduce forehead contraction. This suggests that the FRO activity increase presumably reflected negative affect and tension <span class="citation">(such as observed in EMG studies on generalised anxiety disorder patients, see A. Conrad &amp; Roth, <a href="#ref-conrad_muscle_2007">2007</a>, for a review)</span>.</p>
<p>Alternatively, one could also argue that the larger decrease in lip muscle activity after orofacial relaxation finds a more trivial explana- tion in that it seems obvious to expect that orofacial relaxation will be more efficient to reduce lip muscle contraction than non-orofacial relaxation. Thus, the different impacts of the two relaxation sessions on the lip muscles would not be related to reduced rumination per se but simply to a more anatomically targeted relaxation. However, several observations argue against such an interpretation. The larger decrease in the “Brooding” VAS in the orofacial relaxation condition compared with the other conditions suggests that the reduction in lip muscle activity is indeed related to the reduction in rumination. Moreover, an interpretation solely based on anatomical links does not explain why FRO activity displayed the same amount of reduction in both relaxation sessions. If reduction in muscle activity was merely related to the effect of facial muscle relaxation, then the decrease in FRO activity should have also been higher in the orofacial relaxation condition than in the other relaxation condition, which was not the case. Therefore the dissociation between forehead and lip patterns of activity, together with the differential effects of the two types of relaxation on subjective rumination reports strongly suggest that different processes underlie the activity of these two sets of muscles. We therefore consider that the first interpretation is more plausible: frontalis activity seems related to overall facial tension due to negative affect whereas lip activity seems to be related to the specific involvement of the speech musculature in rumination. These results thus seem to confirm the interpretation of decreased OOS and OOI activities in the orofacial relaxation condition as markers of rumination reduction.</p>
<p>Interestingly, we observed no changes of forearm EMG activity in any of the three conditions of Experiment 2. The fact that the relaxation session focused on the forearm was not associated with a decrease in FCR activity has a simple explanation: FCR activity had not increased after rumination induction and had remained at floor level. The forearm was thus already relaxed and the Arm relaxation session did not modify FCR activity. Another interesting conclusion related to this absence of modification of forearm activity is that relaxation does not spuriously decrease muscle activity below its resting level. One possible interpretation of the increase in lip EMG after rumination induction could have been that baseline relaxation artificially decreased baseline activity under its resting level. The facts that forearm activity did not decrease after arm-focused relaxation contradicts this interpretation.</p>
<p>Finally, the “Story” condition was also associated with a decrease in OOI and FRO activities. This could mean that listening to a story reduced rumination to the same extent as relaxation did. However, the discrepancy observed in “Focused” VAS between the two relaxation conditions on the one hand and the control condition on the other hand, suggests that the EMG decrease observed in the “Story” condition might be attributable to a different cause than that observed in the two relaxation conditions. Listening to a story could help reducing rumination by shifting attention away from ruminative thoughts. Relaxation sessions could help reducing rumination by shifting attention to the body in a beneficial way.</p>
</div>
<div id="general-discussion" class="section level3">
<h3><span class="header-section-number">3.5.3</span> General discussion</h3>
<p>We set out two experiments to examine whether rumination involves motor simulation or is better described as linguistically abstract and articulatory impoverished. We used labial, facial, and arm EMG measures to assess potential articulatory correlates of rumination. The patterns of results of our study seem to be in favour of the motor nature of verbal rumination. In Experiment 1, rumination induction was associated with a higher score on the scale “I am brooding about negative things” which is representative of abstract-analytical rumination, considered as verbal rumination. This maladap- tive rumination state was associated with an increase in the activity of two speech-related muscles, without modification of the arm muscle activity, which indicates that rumination involves activity in speech articulatory muscles, specifically. The concurrent increase in forehead muscle activity could be explained by an increase in negative emotions induced by our negatively valenced induction procedure. The results of Experiment 1 therefore show the involvement of the speech muscula- ture during rumination. This is in line with the <em>Motor simulation view</em>, according to which inner speech is fully specified at the articulatory level, not just the lexical level.</p>
<p>In Experiment 2, guided relaxation resulted in a decrease in speech muscle activity. In the lip muscles, the activity decrease was stronger after orofacial relaxation than after arm-focused relaxation. In the forehead muscle, however the effect was the same for both types of relaxation. This decrease in speech muscle activity was associated with a decrease in self-reports of rumination and was most pronounced after orofacial relaxation. These findings suggest that a reduction in speech muscle activity could hinder articulatory simulation and thus limit inner speech production and therefore reduce rumination. This interpretation is consistent with the <em>Motor Simulation view</em> of inner speech. Brooding-type rumination was also diminished after the arm-focused relaxation as well as after listening to a story, although less than in the orofacial relaxation. This suggests that general relaxation or distraction are also likely to reduce negative rumination. To summarize, experiments 1 and 2 are consistent with the <em>Motor Simulation view</em> of inner speech, according to which speech muscle activity is inherent to inner speech production. Experiment 1 shows the involvement of the lip musculature during brooding-type rumination. Experiment 2 suggests that brooding-type rumination could be reduced by blocking or relaxing speech muscles.</p>
<p>These data support the utility of labial EMG as a tool to objectively assess inner speech in a variety of normal and pathological forms. We suggest that this method could be used as a complement to self-report measures, in order to overcome limitation of these measures.</p>
<p>Our results should be interpreted with some limitations in mind. First, our sample consisted exclusively of women. Although this methodological choice makes sense considering the more frequent occurrence of rumination in women, further studies should be conducted to ascertain that our results may generalize to men. Second, in Experiment 1, no between-subject control condition was used to compare with the group of participants who underwent rumination induction. Thus, we cannot rule out that other processes occurred between baseline and rumination induction, influencing responding. Thirdly, substantial inter-individual differences were observed concerning the size of the effect of rumination induction on facial EMG activity. The results of Jäncke <span class="citation">(Jäncke, <a href="#ref-Jancke1996a">1996</a>; Jäncke et al., <a href="#ref-Jancke1996">1996</a>)</span> can shed light on this last result. Jäncke used a similar procedure (i.e., negative mood induction using a false I.Q. test and facial EMG measurements to assess emotions), except that the experimenter was not in the room while participants performed the test and acknowledged their results. The experimenter then came back to the room and analysed participants’ behaviours. Jäncke observed an increase in facial muscular activity (assessed when participants were reading their results) only in partici- pants who were prone to express their distress when the experimenter came back, while more introverted participants did not show any increased facial activity when reading their results. Jäncke interpreted these results in the framework of an ecological theory of facial expression, suggesting that facial expressions would not only be guided by underlying emotions, but also by their communicative properties. Considering these results, it seems likely that the proneness of participants to communicate their emotions could have mediated effects of the induction on their facial EMG activity. This could partially explain the observed inter-individual variability in facial EMG activity associated with rumination. Moreover, even though rumination is a predominantly verbal process, one cannot exclude that some of our participants experienced rumination in another modality (e.g., imagery-based rumination), which would explain their lower than average lip activity.</p>
<p>Thus, a logical next step is to examine qualitative factors that mediate the link between rumination and facial muscular activity. These factors (among others) could be proneness to communicate emotion or proneness to verbalize affects. Additionally, recent studies suggest a link between verbal aptitudes and propensity to ruminate. <span class="citation">Uttl, Morin, &amp; Hamper (<a href="#ref-Uttl2011">2011</a>)</span> have observed a weak but consistent correlation between the tendency to ruminate and scores on a verbal intelligence test. <span class="citation">Penney, Miedema, &amp; Mazmanian (<a href="#ref-Penney2015">2015</a>)</span> have observed that verbal intelligence constitutes a unique predictor of rumination severity in chronic anxious patients. To our knowledge, the link between verbal intelligence and induced rumination has never been studied. It would be interesting to examine whether the effects of a rumination induction could be mediated by verbal intelligence, and to what extent this could influence related facial EMG activity.</p>
<p>In conclusion, this study provides new evidence for the facial embodiment of rumination, considered as a particular instance of inner speech. Even if more data are needed to confirm these preliminary conclusions, our results seem to support the <em>Motor Simulation view</em> of inner speech production, manifested as verbal rumination. In addition, facial EMG activity provides a useful means to objectively quantify the presence of verbal rumination.</p>
</div>
</div>
<div id="acknowledgements" class="section level2">
<h2><span class="header-section-number">3.6</span> Acknowledgements</h2>
<p>This project was funded by the ANR project INNERSPEECH. The first author of the manuscript is funded by a fellowship from Université Grenoble Alpes and a grant from the Pôle Grenoble Cognition. We thank Nathalie Vallet for recording the relaxation and distraction sessions. We thank our colleagues from GIPSA-lab: Marion Dohen for her help in the recording of the audio stimuli in the anechoic room at GIPSA-lab, as well as Christophe Savariaux and Coriandre Vilain for their advice in the audio setup associated with the EMG measures. We are also grateful to Rafael Laboissière and Adeline Leclercq Samson for their advice concerning data analysis. We sincerely thank two anonymous reviewers for their critical reading of our manuscript and their many insightful comments and suggestions. Access to the facility of the MSH-Alpes SCREEN platform for conducting research is gratefully acknowledged.</p>
</div>
<div id="suppCH3" class="section level2">
<h2><span class="header-section-number">3.7</span> Supplementary data</h2>
<p>Supplementary data associated with this article can be found at <a href="https://osf.io/882te/" class="uri">https://osf.io/882te/</a>.</p>
<!-- create a new page for the summary -->

<!-- center the box vertically, with a parameter to specify the ratio of space above to space below -->


</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-boyd_reflective_1983">
<p>Boyd, E. M., &amp; Fales, A. W. (1983). Reflective Learning: Key to Learning from Experience. <em>Journal of Humanistic Psychology</em>, <em>23</em>(2), 99–117. <a href="https://doi.org/10.1177/0022167883232011" class="uri">https://doi.org/10.1177/0022167883232011</a></p>
</div>
<div id="ref-Nolen-Hoeksema2008">
<p>Nolen-Hoeksema, S., Wisco, B. E., &amp; Lyubomirsky, S. (2008). Rethinking Rumination. <em>Perspectives on Psychological Science</em>, <em>3</em>(5), 400–424. <a href="https://doi.org/10.1111/j.1745-6924.2008.00088.x" class="uri">https://doi.org/10.1111/j.1745-6924.2008.00088.x</a></p>
</div>
<div id="ref-Watkins2008">
<p>Watkins, E. R. (2008). Constructive and unconstructive repetitive thought. <em>Psychological Bulletin</em>, <em>134</em>(2), 163–206. <a href="https://doi.org/10.1037/0033-2909.134.2.163" class="uri">https://doi.org/10.1037/0033-2909.134.2.163</a></p>
</div>
<div id="ref-Rippere1977">
<p>Rippere, V. (1977). What’s the thing to do when you’re feeling depressed? A cross-cultural replication. <em>Behaviour Research and Therapy</em>, <em>15</em>, 185–191. <a href="https://doi.org/10.1016/0005-7967(83)90038-4" class="uri">https://doi.org/10.1016/0005-7967(83)90038-4</a></p>
</div>
<div id="ref-Robinson2003">
<p>Robinson, M. S., &amp; Alloy, L. B. (2003). Negative cognitive styles and stress-reactive rumination interact to predict depression: A prospective study. <em>Cognitive Therapy and Research</em>, <em>27</em>(3), 275–292. <a href="https://doi.org/10.1023/A:1023914416469" class="uri">https://doi.org/10.1023/A:1023914416469</a></p>
</div>
<div id="ref-nolen-hoeksema_responses_1991">
<p>Nolen-Hoeksema, S. (1991). Responses to depression and their effects on the duration of depressive episodes. <em>Journal of Abnormal Psychology</em>, <em>100</em>(4), 569–582. <a href="https://doi.org/10.1037//0021-843X.100.4.569" class="uri">https://doi.org/10.1037//0021-843X.100.4.569</a></p>
</div>
<div id="ref-goldwin_concreteness_2012">
<p>Goldwin, M., &amp; Behar, E. (2012). Concreteness of Idiographic Periods of Worry and Depressive Rumination. <em>Cognitive Therapy and Research</em>, <em>36</em>(6), 840–846. <a href="https://doi.org/10.1007/s10608-011-9428-1" class="uri">https://doi.org/10.1007/s10608-011-9428-1</a></p>
</div>
<div id="ref-mclaughlin_effects_2007">
<p>McLaughlin, K. A., Borkovec, T. D., &amp; Sibrava, N. J. (2007). The Effects of Worry and Rumination on Affect States and Cognitive Activity. <em>Behavior Therapy</em>, <em>38</em>(1), 23–38. <a href="https://doi.org/10.1016/j.beth.2006.03.003" class="uri">https://doi.org/10.1016/j.beth.2006.03.003</a></p>
</div>
<div id="ref-zivin_development_1979">
<p>Zivin, G. (1979). <em>The development of self-regulation through private speech</em>. New York: Wiley.</p>
</div>
<div id="ref-Perrone-Bertolotti2014">
<p>Perrone-Bertolotti, M., Rapin, L., Lachaux, J. P., Baciu, M., &amp; Lœvenbruck, H. (2014). What is that little voice inside my head? Inner speech phenomenology, its role in cognitive performance, and its relation to self-monitoring. <em>Behavioural Brain Research</em>, <em>261</em>, 220–239. <a href="https://doi.org/10.1016/j.bbr.2013.12.034" class="uri">https://doi.org/10.1016/j.bbr.2013.12.034</a></p>
</div>
<div id="ref-vygotsky_collected_1987">
<p>Vygotsky, L. S. (1987). <em>The Collected Works of L. S. Vygotsky</em>. (R. W. Rieber &amp; A. S. Carton, Eds.). Springer US.</p>
</div>
<div id="ref-dell_errors_1992">
<p>Dell, G. S., &amp; Repka, R. J. (1992). Errors in Inner Speech. In B. J. Baars (Ed.), <em>Experimental Slips and Human Error: Exploring the Architecture of Volition</em> (pp. 237–262). Boston, MA: Springer US. <a href="https://doi.org/10.1007/978-1-4899-1164-3_10" class="uri">https://doi.org/10.1007/978-1-4899-1164-3_10</a></p>
</div>
<div id="ref-sokolov_inner_1972">
<p>Sokolov, A. (1972). <em>Inner speech and thought.</em> New York: Springer-Verlag.</p>
</div>
<div id="ref-mackay_constraints_1992">
<p>MacKay, D. G. (1992). Constraints on theories of inner speech. In D. Reisberg (Ed.), <em>Auditory imagery</em> (pp. 121–149). Erlbaum; Hillsdale, N. J.</p>
</div>
<div id="ref-grzes_functional_2001">
<p>Gr�zes, J., &amp; Decety, J. (2001). Functional anatomy of execution, mental simulation, observation, and verb generation of actions: A meta-analysis. <em>Human Brain Mapping</em>, <em>12</em>(1), 1–19. <a href="https://doi.org/10.1002/1097-0193(200101)12:1&lt;1::AID-HBM10&gt;3.0.CO;2-V" class="uri">https://doi.org/10.1002/1097-0193(200101)12:1&lt;1::AID-HBM10&gt;3.0.CO;2-V</a></p>
</div>
<div id="ref-postma_production_1996">
<p>Postma, A., &amp; Noordanus, C. (1996). Production and detection of speech errors in silent, mouthed, noise-masked, and normal auditory feedback speech. <em>Language and Speech</em>, <em>39</em>(4), 375–392. <a href="https://doi.org/10.1177/002383099603900403" class="uri">https://doi.org/10.1177/002383099603900403</a></p>
</div>
<div id="ref-decety_mentally_1996">
<p>Decety, J., &amp; Jeannerod, M. (1996). Mentally simulated movements in virtual reality: Does Fitts’s law hold in motor imagery? <em>Behavioural Brain Research</em>, 8.</p>
</div>
<div id="ref-feinberg_efference_1978">
<p>Feinberg, I. (1978). Efference Copy and Corollary Discharge: Implications for Thinking and Its Disorders. <em>Schizophrenia Bulletin</em>, <em>4</em>(4), 636–640. <a href="https://doi.org/10.1093/schbul/4.4.636" class="uri">https://doi.org/10.1093/schbul/4.4.636</a></p>
</div>
<div id="ref-Jones2007">
<p>Jones, S. R., &amp; Fernyhough, C. (2007). Thought as action: Inner speech, self-monitoring, and auditory verbal hallucinations. <em>Consciousness and Cognition</em>, <em>16</em>(2), 391–399. <a href="https://doi.org/10.1016/j.concog.2005.12.003" class="uri">https://doi.org/10.1016/j.concog.2005.12.003</a></p>
</div>
<div id="ref-conrad_speech_1979">
<p>Conrad, B., &amp; Schönle, P. (1979). Speech and respiration. <em>Archiv Für Psychiatrie Und Nervenkrankheiten</em>, <em>226</em>(4), 251–268. <a href="https://doi.org/10.1007/BF00342238" class="uri">https://doi.org/10.1007/BF00342238</a></p>
</div>
<div id="ref-jacobson_electrical_1931">
<p>Jacobson, E. (1931). Electrical measurements of neuromuscular states during mental activities. VII. Imagination, recollection, and abstract thinking involving the speech musculature. <em>American Journal of Physiology</em>, <em>897</em>, 200–209.</p>
</div>
<div id="ref-livesay_covert_1996">
<p>Livesay, J., Liebke, A., Samaras, M., &amp; Stanley, A. (1996). Covert speech behavior during a silent language recitation task. <em>Perceptual and Motor Skills</em>, <em>83</em>, 1355–1362. <a href="https://doi.org/10.2466/pms.1996.83.3f.1355" class="uri">https://doi.org/10.2466/pms.1996.83.3f.1355</a></p>
</div>
<div id="ref-mcguigan_patterns_1989">
<p>McGuigan, F. J., &amp; Dollins, A. D. (1989). Patterns of covert speech behavior and phonetic coding. <em>The Pavlovian Journal of Biological Science</em>, <em>24</em>(1), 19–26.</p>
</div>
<div id="ref-Rapin2013">
<p>Rapin, L., Dohen, M., Polosan, M., Perrier, P., &amp; Lœvenbruck, H. (2013). An EMG study of the lip muscles during covert auditory verbal hallucinations in schizophrenia. <em>Journal of Speech, Language, and Hearing Research : JSLHR</em>, <em>56</em>(6), S1882–93. <a href="https://doi.org/10.1044/1092-4388(2013/12-0210)" class="uri">https://doi.org/10.1044/1092-4388(2013/12-0210)</a></p>
</div>
<div id="ref-palmer_event-related_2001">
<p>Palmer, E. D., Rosen, H. J., Ojemann, J. G., Buckner, R. L., Kelley, W. M., &amp; Petersen, S. E. (2001). An Event-Related fMRI Study of Overt and Covert Word Stem Completion. <em>NeuroImage</em>, <em>14</em>(1), 182–193. <a href="https://doi.org/10.1006/nimg.2001.0779" class="uri">https://doi.org/10.1006/nimg.2001.0779</a></p>
</div>
<div id="ref-basho_effects_2007">
<p>Basho, S., Palmer, E. D., Rubio, M. A., Wulfeck, B., &amp; Müller, R.-A. (2007). Effects of generation mode in fMRI adaptations of semantic fluency: Paced production and overt speech. <em>Neuropsychologia</em>, <em>45</em>(8), 1697–1706. <a href="https://doi.org/10.1016/j.neuropsychologia.2007.01.007" class="uri">https://doi.org/10.1016/j.neuropsychologia.2007.01.007</a></p>
</div>
<div id="ref-levine_language_1982">
<p>Levine, D. N., Calvanio, R., &amp; Popovics, A. (1982). Language in the absence of inner speech. <em>Neuropsychologia</em>, <em>20</em>(4), 391–409. <a href="https://doi.org/10.1016/0028-3932(82)90039-2" class="uri">https://doi.org/10.1016/0028-3932(82)90039-2</a></p>
</div>
<div id="ref-martin_short-term_1982">
<p>Martin, R. C., &amp; Caramazza, A. (1982). Short-term memory performance in the absence of phonological coding. <em>Brain and Cognition</em>, <em>1</em>(1), 50–70. <a href="https://doi.org/10.1016/0278-2626(82)90006-9" class="uri">https://doi.org/10.1016/0278-2626(82)90006-9</a></p>
</div>
<div id="ref-baddeley_phonological_1985">
<p>Baddeley, A. D., &amp; Wilson, B. (1985). Phonological coding and short-term memory in patients without speech. <em>Journal of Memory and Language</em>, <em>24</em>(4), 490–502. <a href="https://doi.org/10.1016/0749-596X(85)90041-5" class="uri">https://doi.org/10.1016/0749-596X(85)90041-5</a></p>
</div>
<div id="ref-marshall_self-monitoring_1985">
<p>Marshall, R. C., Rappaport, B., &amp; Garcia-Bunuel, L. (1985). Self-monitoring behavior in a case of severe auditory agnosia with aphasia. <em>Brain and Language</em>, <em>24</em>(2), 297–313. <a href="https://doi.org/10.1016/0093-934X(85)90137-3" class="uri">https://doi.org/10.1016/0093-934X(85)90137-3</a></p>
</div>
<div id="ref-vallar_articulation_1987">
<p>Vallar, G., &amp; Cappa, S. F. (1987). Articulation and verbal short-term memory: Evidence from anarthria. <em>Cognitive Neuropsychology</em>, <em>4</em>(1), 55–77. <a href="https://doi.org/10.1080/02643298708252035" class="uri">https://doi.org/10.1080/02643298708252035</a></p>
</div>
<div id="ref-geva_discrepancy_2011">
<p>Geva, S., Bennett, S., Warburton, E. A., &amp; Patterson, K. (2011). Discrepancy between inner and overt speech: Implications for post-stroke aphasia and normal language processing. <em>Aphasiology</em>, <em>25</em>(3), 323–343. <a href="https://doi.org/10.1080/02687038.2010.511236" class="uri">https://doi.org/10.1080/02687038.2010.511236</a></p>
</div>
<div id="ref-langland-hassan_inner_2015">
<p>Langland-Hassan, P., Faries, F. R., Richardson, M. J., &amp; Dietz, A. (2015). Inner speech deficits in people with aphasia. <em>Frontiers in Psychology</em>, <em>6</em>. <a href="https://doi.org/10.3389/fpsyg.2015.00528" class="uri">https://doi.org/10.3389/fpsyg.2015.00528</a></p>
</div>
<div id="ref-paulesu_neural_1993">
<p>Paulesu, E., Frith, C. D., &amp; Frackowiak, R. S. J. (1993). The neural correlates of the verbal component of working memory. <em>Nature</em>, <em>362</em>(6418), 342–345. <a href="https://doi.org/10.1038/362342a0" class="uri">https://doi.org/10.1038/362342a0</a></p>
</div>
<div id="ref-shuster_fmri_2005">
<p>Shuster, L., &amp; Lemieux, S. (2005). An fMRI investigation of covertly and overtly produced mono- and multisyllabic words. <em>Brain and Language</em>, <em>93</em>(1), 20–31. <a href="https://doi.org/10.1016/j.bandl.2004.07.007" class="uri">https://doi.org/10.1016/j.bandl.2004.07.007</a></p>
</div>
<div id="ref-oppenheim_motor_2010">
<p>Oppenheim, G. M., &amp; Dell, G. S. (2010). Motor movement matters: The flexible abstractness of inner speech. <em>Memory &amp; Cognition</em>, <em>38</em>(8), 1147–1160. <a href="https://doi.org/10.3758/MC.38.8.1147" class="uri">https://doi.org/10.3758/MC.38.8.1147</a></p>
</div>
<div id="ref-corley_error_2011">
<p>Corley, M., Brocklehurst, P. H., &amp; Moat, H. S. (2011). Error biases in inner and overt speech: Evidence from tongue twisters. <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>, <em>37</em>(1), 162–175. <a href="https://doi.org/10.1037/a0021321" class="uri">https://doi.org/10.1037/a0021321</a></p>
</div>
<div id="ref-netsell_inner_2010">
<p>Netsell, R., Ashley, E., &amp; Bakker, K. (2010). The inner speech of persons who stutter. In <em>Proceedings of the international motor speech conference</em>.</p>
</div>
<div id="ref-nolen-hoeksema_prospective_1991">
<p>Nolen-Hoeksema, S., &amp; Morrow, J. (1991). A Prospective Study of Depression and Posttraumatic Stress Symptoms After a Natural Disaster: The 1989 Loma Prieta Earthquake. <em>Journal of Personality and Social Psychology</em>, <em>61</em>(1), 115–121. <a href="https://doi.org/10.1037//0022-3514.61.1.115" class="uri">https://doi.org/10.1037//0022-3514.61.1.115</a></p>
</div>
<div id="ref-treynor_rumination_2003">
<p>Treynor, W., Gonzalez, R., &amp; Nolen-Hoeksema, S. (2003). Rumination Reconsidered : A Psychometric Analysis, <em>27</em>(3), 247–259. <a href="https://doi.org/10.1023/A:1023910315561" class="uri">https://doi.org/10.1023/A:1023910315561</a></p>
</div>
<div id="ref-rubin_what_1986">
<p>Brewer, W. F. (1986). What is autobiographical memory? In D. C. Rubin (Ed.), <em>Autobiographical Memory</em> (pp. 25–49). Cambridge: Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511558313.006" class="uri">https://doi.org/10.1017/CBO9780511558313.006</a></p>
</div>
<div id="ref-conway_autobiographical_1990">
<p>Conway, M. A. (1990). <em>Autobiographical memory: An introduction.</em> Open University Press.</p>
</div>
<div id="ref-nisbett_telling_1977">
<p>Nisbett, J., &amp; Wilson, T. D. (1977). Telling more than we can know: Verbal reports of mental processes. <em>Psychological Review</em>, <em>84</em>(3), 231–259. <a href="https://doi.org/10.1037// 0033-295x.84.3.231" class="uri">https://doi.org/10.1037// 0033-295x.84.3.231</a></p>
</div>
<div id="ref-papageorgiou_physiological_2003">
<p>Siegle, G. J., &amp; Thayer, J. F. (2003). Physiological Aspects of Depressive Rumination. In C. Papageorgiou &amp; A. Wells (Eds.), <em>Depressive Rumination</em> (pp. 79–104). Chichester, UK: John Wiley &amp; Sons Ltd. <a href="https://doi.org/10.1002/9780470713853.ch5" class="uri">https://doi.org/10.1002/9780470713853.ch5</a></p>
</div>
<div id="ref-vickers_effects_2003">
<p>Vickers, K. S., &amp; Vogeltanz-Holm, N. D. (2003). The Effects of Rumination and Distraction Tasks on Psychophysiological Responses and Mood in Dysphoric and Nondysphoric Individuals. <em>Cognitive Therapy and Research</em>, 19.</p>
</div>
<div id="ref-sigmon_impact_2000">
<p>Sigmon, S. T., Dorhofer, D. M., Rohan, K. J., &amp; Boulard, N. E. (2000). The Impact of Anxiety Sensitivity, Bodily Expectations, and Cultural Beliefs on Menstrual Symptom Reporting: A Test of the Menstrual Reactivity Hypothesis. <em>Journal of Anxiety Disorders</em>, <em>14</em>(6), 615–633. <a href="https://doi.org/10.1016/s0887-6185(00)00054-2" class="uri">https://doi.org/10.1016/s0887-6185(00)00054-2</a></p>
</div>
<div id="ref-Key2008">
<p>Key, B. L., Campbell, T. S., Bacon, S. L., &amp; Gerin, W. (2008). The influence of trait and state rumination on cardiovascular recovery from a negative emotional stressor. <em>Journal of Behavioral Medicine</em>, <em>31</em>, 237–248. <a href="https://doi.org/10.1007/s10865-008-9152-9" class="uri">https://doi.org/10.1007/s10865-008-9152-9</a></p>
</div>
<div id="ref-woody_brooding_2014">
<p>Woody, M. L., McGeary, J. E., &amp; Gibb, B. E. (2014). Brooding rumination and heart rate variability in women at high and low risk for depression: Group differences and moderation by COMT genotype. <em>Journal of Abnormal Psychology</em>, <em>123</em>(1), 61–67. <a href="https://doi.org/10.1037/a0035450" class="uri">https://doi.org/10.1037/a0035450</a></p>
</div>
<div id="ref-Ottaviani2015">
<p>Ottaviani, C., Shahabi, L., Tarvainen, M., Cook, I., Abrams, M., &amp; Shapiro, D. (2015). Cognitive, behavioral, and autonomic correlates of mind wandering and perseverative cognition in major depression. <em>Frontiers in Neuroscience</em>, <em>8</em>(January), 1–9. <a href="https://doi.org/10.3389/fnins.2014.00433" class="uri">https://doi.org/10.3389/fnins.2014.00433</a></p>
</div>
<div id="ref-ekman_facial_1978">
<p>Ekman, P., &amp; Friesen, W. (1978). <em>Facial coding action system (FACS): A technique for the measurement of facial actions</em>. Palo Alto, CA: Consulting Psychologists Press.</p>
</div>
<div id="ref-kohler_differences_2004">
<p>Kohler, C. G., Turner, T., Stolar, N. M., Bilker, W. B., Brensinger, C. M., Gur, R. E., &amp; Gur, R. C. (2004). Differences in facial expressions of four universal emotions. <em>Psychiatry Research</em>, <em>128</em>(3), 235–244. <a href="https://doi.org/10.1016/j.psychres.2004.07.003" class="uri">https://doi.org/10.1016/j.psychres.2004.07.003</a></p>
</div>
<div id="ref-Jancke1996">
<p>Jäncke, L., Vogt, J., Musial, F., Lutz, K., &amp; Kalveram, K. T. (1996). Facial EMG responses to auditory stimuli. <em>International Journal of Psychophysiology</em>, <em>22</em>(1-2), 85–96. <a href="https://doi.org/10.1016/0167-8760(96)00013-X" class="uri">https://doi.org/10.1016/0167-8760(96)00013-X</a></p>
</div>
<div id="ref-conrad_muscle_2007">
<p>Conrad, A., &amp; Roth, W. T. (2007). Muscle relaxation therapy for anxiety disorders: It works but how? <em>Journal of Anxiety Disorders</em>, <em>21</em>(3), 243–264. <a href="https://doi.org/10.1016/j.janxdis.2006.08.001" class="uri">https://doi.org/10.1016/j.janxdis.2006.08.001</a></p>
</div>
<div id="ref-cefidekhanie_interaction_2014">
<p>Cefidekhanie, A. H., Savariaux, C., Sato, M., &amp; Schwartz, J.-l. (2014). Interaction between articulatory gestures and inner speech in a counting task. <em>Journal of the Acoustical Society of America</em>, <em>136</em>(4), 1869–1879. <a href="https://doi.org/10.1121/1.4893910" class="uri">https://doi.org/10.1121/1.4893910</a></p>
</div>
<div id="ref-Johnson2013">
<p>Johnson, D. P., &amp; Whisman, M. a. (2013). Gender differences in rumination: A meta-analysis. <em>Personality and Individual Differences</em>, <em>55</em>(4), 367–374. <a href="https://doi.org/10.1016/j.paid.2013.03.019" class="uri">https://doi.org/10.1016/j.paid.2013.03.019</a></p>
</div>
<div id="ref-everdell_gaze_2007">
<p>Everdell, I. T., Marsh, H., Yurick, M. D., Munhall, K. G., &amp; Paré, M. (2007). Gaze Behaviour in Audiovisual Speech Perception: Asymmetrical Distribution of Face-Directed Fixations. <em>Perception</em>, <em>36</em>(10), 1535–1545. <a href="https://doi.org/10.1068/p5852" class="uri">https://doi.org/10.1068/p5852</a></p>
</div>
<div id="ref-de_luca_use_1997">
<p>De Luca, C. J. (1997). The Use of Surface Electromyography in Biomechanics. <em>Journal of Applied Biomechanics</em>, <em>13</em>(2), 135–163. <a href="https://doi.org/10.1123/jab.13.2.135" class="uri">https://doi.org/10.1123/jab.13.2.135</a></p>
</div>
<div id="ref-fuhrer_version_1989">
<p>Fuhrer, R., &amp; Rouillon, F. (1989). La version française de l’échelle CES-D (Center for Epidemiologic Studies-Depression Scale). Description et traduction de l’échelle d’autoévaluation. <em>Psychiatrie &amp; Psychobiologie</em>, <em>4</em>(3), 163–166.</p>
</div>
<div id="ref-Douilliez2012">
<p>Douilliez, C., Philippot, P., Heeren, A., Watkins, E. R., &amp; Barnard, P. (2012). The Mini-CERTS (Cambridge-Exeter Repetitive Thought Scale): A Short Questionnaire to Assess Constructive and Unconstructive Repetitive Thinking. <em>Revue Canadienne Des Sciences Du Comportement/ Canadian Journal of Behavioural Science.</em>, 1–19.</p>
</div>
<div id="ref-Huffziger2012">
<p>Huffziger, S., Ebner-Priemer, U., Koudela, S., Reinhard, I., &amp; Kuehner, C. (2012). Induced rumination in everyday life: Advancing research approaches to study rumination. <em>Personality and Individual Differences</em>, <em>53</em>(6), 790–795. <a href="https://doi.org/10.1016/j.paid.2012.06.009" class="uri">https://doi.org/10.1016/j.paid.2012.06.009</a></p>
</div>
<div id="ref-Lemoult2014">
<p>Lemoult, J., &amp; Joormann, J. (2014). Depressive rumination alters cortisol decline in Major Depressive Disorder. <em>Biological Psychology</em>, <em>100</em>, 50–55. <a href="https://doi.org/10.1016/j.biopsycho.2014.05.001" class="uri">https://doi.org/10.1016/j.biopsycho.2014.05.001</a></p>
</div>
<div id="ref-VanRandenborgh2010">
<p>Randenborgh, A. van, Hüffmeier, J., LeMoult, J., &amp; Joormann, J. (2010). Letting go of unmet goals: Does self-focused rumination impair goal disengagement? <em>Motivation and Emotion</em>, <em>34</em>, 325–332. <a href="https://doi.org/10.1007/s11031-010-9190-9" class="uri">https://doi.org/10.1007/s11031-010-9190-9</a></p>
</div>
<div id="ref-nolen-hoeksema_effects_1993">
<p>Nolen-Hoeksema, S., &amp; Morrow, J. (1993). Effects of rumination and distraction on naturally occurring depressed mood. <em>Cognition and Emotion</em>, <em>7</em>(6), 561–570. <a href="https://doi.org/10.1080/02699939308409206" class="uri">https://doi.org/10.1080/02699939308409206</a></p>
</div>
<div id="ref-boxtel_optimal_2001">
<p>Boxtel, A. (2001). Optimal signal bandwidth for the recording of surface EMG activity of facial, jaw, oral, and neck muscles. <em>Psychophysiology</em>, <em>38</em>(1), 22–34. <a href="https://doi.org/10.1111/1469-8986.3810022" class="uri">https://doi.org/10.1111/1469-8986.3810022</a></p>
</div>
<div id="ref-de_luca_filtering_2010">
<p>De Luca, C. J., Donald Gilmore, L., Kuznetsov, M., &amp; Roy, S. H. (2010). Filtering the surface EMG signal: Movement artifact and baseline noise contamination. <em>Journal of Biomechanics</em>, <em>43</em>(8), 1573–1579. <a href="https://doi.org/10.1016/j.jbiomech.2010.01.027" class="uri">https://doi.org/10.1016/j.jbiomech.2010.01.027</a></p>
</div>
<div id="ref-rapin_emg_2013">
<p>Rapin, L., Dohen, M., Polosan, M., &amp; Perrier, P. (2013). An EMG Study of the Lip Muscles During Covert Auditory Verbal Hallucinations in Schizophrenia. <em>JSLHR</em>, <em>56</em>, 1882–1893. <a href="https://doi.org/10.1044/1092-4388(2013/12-0210)and" class="uri">https://doi.org/10.1044/1092-4388(2013/12-0210)and</a></p>
</div>
<div id="ref-berntson_skeletomotor_2007">
<p>Tassinary, L. G., Cacioppo, J. T., &amp; Vanman, E. J. (2007). The Skeletomotor System. In G. Berntson, J. T. Cacioppo, &amp; L. G. Tassinary (Eds.), <em>Handbook of Psychophysiology</em> (3rd ed., pp. 267–300). Cambridge: Cambridge University Press. Retrieved from <a href="https://www.cambridge.org/core/books/handbook-of-psychophysiology/skeletomotor-system/CAD1D438D70B4242013F71848E4799D0" class="uri">https://www.cambridge.org/core/books/handbook-of-psychophysiology/skeletomotor-system/CAD1D438D70B4242013F71848E4799D0</a></p>
</div>
<div id="ref-R-brms">
<p>Bürkner, P.-C. (2018). <em>Brms: Bayesian regression models using ’stan’</em>. Retrieved from <a href="https://CRAN.R-project.org/package=brms" class="uri">https://CRAN.R-project.org/package=brms</a></p>
</div>
<div id="ref-carpenter_stan:_2017">
<p>Carpenter, B., Gelman, A., Hoffman, M., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2017). Stan: A Probabilistic Programming Language. <em>Journal of Statistical Software, Articles</em>, <em>76</em>(1), 1–32. <a href="https://doi.org/10.18637/jss.v076.i01" class="uri">https://doi.org/10.18637/jss.v076.i01</a></p>
</div>
<div id="ref-R-BayesianFirstAid">
<p>Bååth, R. (2018). <em>BayesianFirstAid: Bayesian replacements for the most commonly used statistical tests in r.</em> Retrieved from <a href="http://www.sumsar.net" class="uri">http://www.sumsar.net</a></p>
</div>
<div id="ref-barlow_differential_1986">
<p>Barlow, S. M., &amp; Netsell, R. (1986). Differential Fine Force Control of the Upper and Lower Lips. <em>Journal of Speech, Language, and Hearing Research</em>, <em>29</em>(2), 163–169. <a href="https://doi.org/10.1044/jshr.2902.163" class="uri">https://doi.org/10.1044/jshr.2902.163</a></p>
</div>
<div id="ref-regalo_electromyographic_2005">
<p>Regalo, S. C. H., Vitti, M., Moraes, M. T. B., Semprini, M., Felício, C. M. de, Mattos, M. da G. C. de, … Santos, C. M. (2005). Electromyographic analysis of the orbicularis oris muscle in oralized deaf individuals. <em>Brazilian Dental Journal</em>, <em>16</em>(3), 237–242. <a href="https://doi.org/10.1590/S0103-64402005000300012" class="uri">https://doi.org/10.1590/S0103-64402005000300012</a></p>
</div>
<div id="ref-babault_effect_2003">
<p>Babault, N., Pousson, M., Michaut, A., &amp; Van Hoecke, J. (2003). Effect of quadriceps femoris muscle length on neural activation during isometric and concentric contractions. <em>Journal of Applied Physiology</em>, <em>94</em>(3), 983–990. <a href="https://doi.org/10.1152/japplphysiol.00717.2002" class="uri">https://doi.org/10.1152/japplphysiol.00717.2002</a></p>
</div>
<div id="ref-van_boxtel_amplitude_1993">
<p>Boxtel, A. van, &amp; Jessurun, M. (1993). Amplitude and bilateral coherency of facial and jaw-elevator EMG activity as an index of effort during a two-choice serial reaction task. <em>Psychophysiology</em>, <em>30</em>(6), 589–604. <a href="https://doi.org/10.1111/j.1469-8986.1993.tb02085.x" class="uri">https://doi.org/10.1111/j.1469-8986.1993.tb02085.x</a></p>
</div>
<div id="ref-Rood2012">
<p>Rood, L., Roelofs, J., Bögels, S. M., &amp; Arntz, A. (2012). The effects of experimentally induced rumination, positive reappraisal, acceptance, and distancing when thinking about a stressful event on affect states in adolescents. <em>Journal of Abnormal Child Psychology</em>, <em>40</em>(1), 73–84. <a href="https://doi.org/10.1007/s10802-011-9544-0" class="uri">https://doi.org/10.1007/s10802-011-9544-0</a></p>
</div>
<div id="ref-Jancke1996a">
<p>Jäncke, L. (1996). Facial EMG in an anger-provoking situation: Individual differences in directing anger outwards or inwards. <em>International Journal of Psychophysiology</em>, <em>23</em>(3), 207–214. <a href="https://doi.org/10.1016/S0167-8760(96)00062-1" class="uri">https://doi.org/10.1016/S0167-8760(96)00062-1</a></p>
</div>
<div id="ref-Uttl2011">
<p>Uttl, B., Morin, A., &amp; Hamper, B. (2011). Are Inner Speech Self-Report Questionnaires Reliable and Valid? <em>Procedia - Social and Behavioral Sciences</em>, <em>30</em>, 1719–1723. <a href="https://doi.org/10.1016/j.sbspro.2011.10.332" class="uri">https://doi.org/10.1016/j.sbspro.2011.10.332</a></p>
</div>
<div id="ref-Penney2015">
<p>Penney, A. M., Miedema, V. C., &amp; Mazmanian, D. (2015). Intelligence and emotional disorders : Is the worrying and ruminating mind a more intelligent mind ? <em>Personality and Individual Differences</em>, <em>74</em>, 90–93. <a href="https://doi.org/10.1016/j.paid.2014.10.005" class="uri">https://doi.org/10.1016/j.paid.2014.10.005</a></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>This experimental chapter is a published paper reformatted for the need of this thesis. Source: Nalborczyk, L., Perrone-Bertolotti, M., Baeyens, C., Grandchamp, R., Polosan, M., Spinelli, E., … Lvenbruck, H. (2017). Orofacial Electromyographic Correlates of Induced Verbal Rumination. <em>Biological Psychology, 127</em>, 53-63. <a href="https://dx.doi.org/10.1016/j.biopsycho.2017.04.013" class="uri">https://dx.doi.org/10.1016/j.biopsycho.2017.04.013</a>.<a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#fnref8">↩</a></p></li>
<li id="fn9"><p>The <em>corrugator supercilii</em> was another potential site, as it is sensitive to negative emotions. However, it has been claimed to be mostly activated for strong emotions such as fear/terror, anger/rage and sadness/grief <span class="citation">(Ekman &amp; Friesen, <a href="#ref-ekman_facial_1978">1978</a>; Sumitsuji, Matsumoto, Tanaka, Kashiwagi, &amp; Kaneko, <a href="#ref-sumitsuji_electromyographic_1967">1967</a>)</span>. The rumination induction used in this study was designed to have participants self-reflect and brood over their failure at the I.Q. test. It was not meant to induce such strong emotions. Several studies have reported increased activity in the <em>frontalis</em> muscle at rest in anxious or generalized anxiety disorder patients <span class="citation">(for a review, see A. Conrad &amp; Roth, <a href="#ref-conrad_muscle_2007">2007</a>)</span>. We expected the type of emotional state induced by rumination to be closer to anxiety or worry than to strong emotions like fear, anger or grief. It was therefore more appropriate to record non-speech facial activity in the <em>frontalis</em> rather than in the <em>corrugator.</em><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#fnref9">↩</a></p></li>
<li id="fn10"><p>Because of constraints attributable to the design of our experiment, we were not able to perform conventional control measures (e.g., time of the day, food consumption, sport activity, smoking habits, etc.). Moreover, in our study, periods of signal recording had to be shorter than usual HRV analysis time periods (cf. methodology section). Although recent studies suggest that “ultrashort term” HRV analysis seems to correlate quite well with HRV analysis performed on longer periods of time <span class="citation">(Brisinda et al., <a href="#ref-brisinda_comparison_2013">2013</a>; Salahuddin, Cho, Jeong, &amp; Kim, <a href="#ref-Salahuddin2007">2007</a>)</span>, we cannot exclude that our measurements might be unreliable. For these reasons, we chose not to present HRV results in this report and to focus on EMG results as well as subjective reports of rumination.<a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#fnref10">↩</a></p></li>
<li id="fn11"><p>While not suffering from the misunderstandings associated with frequentist confidence intervals <span class="citation">(for more details, see for instance Morey, Hoekstra, Rouder, Lee, &amp; Wagenmakers, <a href="#ref-morey_fallacy_2015">2015</a>)</span>.<a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#fnref11">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="methodological-framework.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dissociating-facial-electromyographic-correlates-of-visual-and-verbal-induced-rumination.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lnalborczyk/phd_thesis/edit/master/03-chap3.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["thesis.pdf"],
"toc": {
"collapse": "none / section / subsection",
"scroll_highlight": true
},
"search": true,
"highlight": "pygments"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
