<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 6 Methods | Understanding rumination as a form of inner speech</title>
  <meta name="description" content="Chapter 6 Methods | Understanding rumination as a form of inner speech">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 6 Methods | Understanding rumination as a form of inner speech" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Methods | Understanding rumination as a form of inner speech" />
  
  
  

<meta name="author" content="">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction-1.html">
<link rel="next" href="results-1.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Theoretical chapters</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Theoretical framework</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#rumination-as-a-form-of-repetitive-negative-thinking"><i class="fa fa-check"></i><b>1.1</b> Rumination as a form of repetitive negative thinking</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#theoretical-perspectives-on-rumination"><i class="fa fa-check"></i><b>1.1.1</b> Theoretical perspectives on rumination</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#measures-of-rumination"><i class="fa fa-check"></i><b>1.1.2</b> Measures of rumination</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#on-the-verbal-and-sensory-properties-of-rumination"><i class="fa fa-check"></i><b>1.1.3</b> On the verbal and sensory properties of rumination</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#what-is-that-little-voice-inside-my-head"><i class="fa fa-check"></i><b>1.2</b> What is that little voice inside my head ?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#brief-historical-overview-of-inner-speech-investigations"><i class="fa fa-check"></i><b>1.2.1</b> Brief historical overview of inner speech investigations</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#theoretical-perspectives-about-inner-speech-production"><i class="fa fa-check"></i><b>1.2.2</b> Theoretical perspectives about inner speech production</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#theoretical-perspective-on-motor-imagery"><i class="fa fa-check"></i><b>1.3</b> Theoretical perspective on motor imagery</a><ul>
<li class="chapter" data-level="1.3.1" data-path="intro.html"><a href="intro.html#overt-and-imagined-actions"><i class="fa fa-check"></i><b>1.3.1</b> Overt and imagined actions</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#the-motor-simulation-theory"><i class="fa fa-check"></i><b>1.3.2</b> The motor simulation theory</a></li>
<li class="chapter" data-level="1.3.3" data-path="intro.html"><a href="intro.html#emulation-and-internal-models"><i class="fa fa-check"></i><b>1.3.3</b> Emulation and internal models</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#electromyography-of-covert-actions"><i class="fa fa-check"></i><b>1.4</b> Electromyography of covert actions</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#explaining-the-muscular-activity-during-motor-imagery"><i class="fa fa-check"></i><b>1.4.1</b> Explaining the muscular activity during motor imagery</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#controversial-findings"><i class="fa fa-check"></i><b>1.4.2</b> Controversial findings</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#electromyographic-correlates-of-inner-speech-production"><i class="fa fa-check"></i><b>1.4.3</b> Electromyographic correlates of inner speech production</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="methodological-framework.html"><a href="methodological-framework.html"><i class="fa fa-check"></i><b>2</b> Methodological framework</a><ul>
<li class="chapter" data-level="2.1" data-path="methodological-framework.html"><a href="methodological-framework.html#speech-production-mechanisms"><i class="fa fa-check"></i><b>2.1</b> Speech production mechanisms</a><ul>
<li class="chapter" data-level="2.1.1" data-path="methodological-framework.html"><a href="methodological-framework.html#psychological-aspects-of-speech-production"><i class="fa fa-check"></i><b>2.1.1</b> Psychological aspects of speech production</a></li>
<li class="chapter" data-level="2.1.2" data-path="methodological-framework.html"><a href="methodological-framework.html#biomechanical-aspects-of-speech-production"><i class="fa fa-check"></i><b>2.1.2</b> Biomechanical aspects of speech production</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="methodological-framework.html"><a href="methodological-framework.html#a-brief-introduction-to-electromyography"><i class="fa fa-check"></i><b>2.2</b> A brief introduction to electromyography</a><ul>
<li class="chapter" data-level="2.2.1" data-path="methodological-framework.html"><a href="methodological-framework.html#nature-of-the-emg-signal"><i class="fa fa-check"></i><b>2.2.1</b> Nature of the EMG signal</a></li>
<li class="chapter" data-level="2.2.2" data-path="methodological-framework.html"><a href="methodological-framework.html#emg-instrumentation-and-recording"><i class="fa fa-check"></i><b>2.2.2</b> EMG instrumentation and recording</a></li>
<li class="chapter" data-level="2.2.3" data-path="methodological-framework.html"><a href="methodological-framework.html#emg-signal-processing"><i class="fa fa-check"></i><b>2.2.3</b> EMG signal processing</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="methodological-framework.html"><a href="methodological-framework.html#statistical-modelling-and-statistical-inference"><i class="fa fa-check"></i><b>2.3</b> Statistical modelling and statistical inference</a><ul>
<li class="chapter" data-level="2.3.1" data-path="methodological-framework.html"><a href="methodological-framework.html#limitations-of-the-standard-statistical-approach-in-psychology"><i class="fa fa-check"></i><b>2.3.1</b> Limitations of the standard statistical approach in Psychology</a></li>
<li class="chapter" data-level="2.3.2" data-path="methodological-framework.html"><a href="methodological-framework.html#our-statistical-approach"><i class="fa fa-check"></i><b>2.3.2</b> Our statistical approach</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="methodological-framework.html"><a href="methodological-framework.html#overview-of-the-following-chapters"><i class="fa fa-check"></i><b>2.4</b> Overview of the following chapters</a></li>
</ul></li>
<li class="part"><span><b>II Experimental chapters</b></span></li>
<li class="chapter" data-level="3" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><i class="fa fa-check"></i><b>3</b> Orofacial electromyographic correlates of induced verbal rumination</a><ul>
<li class="chapter" data-level="3.1" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#abstract"><i class="fa fa-check"></i><b>3.1</b> Abstract</a></li>
<li class="chapter" data-level="3.2" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#introduction"><i class="fa fa-check"></i><b>3.2</b> Introduction</a></li>
<li class="chapter" data-level="3.3" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#methods"><i class="fa fa-check"></i><b>3.3</b> Methods</a><ul>
<li class="chapter" data-level="3.3.1" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#participants"><i class="fa fa-check"></i><b>3.3.1</b> Participants</a></li>
<li class="chapter" data-level="3.3.2" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#material"><i class="fa fa-check"></i><b>3.3.2</b> Material</a></li>
<li class="chapter" data-level="3.3.3" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#procedure"><i class="fa fa-check"></i><b>3.3.3</b> Procedure</a></li>
<li class="chapter" data-level="3.3.4" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#data-processing-and-analysis"><i class="fa fa-check"></i><b>3.3.4</b> Data processing and analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#results"><i class="fa fa-check"></i><b>3.4</b> Results</a><ul>
<li class="chapter" data-level="3.4.1" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#experiment-1-rumination-induction-1"><i class="fa fa-check"></i><b>3.4.1</b> Experiment 1: rumination induction</a></li>
<li class="chapter" data-level="3.4.2" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#experiment-2-rumination-reduction-by-relaxation-1"><i class="fa fa-check"></i><b>3.4.2</b> Experiment 2: rumination reduction by relaxation</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#discussion"><i class="fa fa-check"></i><b>3.5</b> Discussion</a><ul>
<li class="chapter" data-level="3.5.1" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#experiment-1"><i class="fa fa-check"></i><b>3.5.1</b> Experiment 1</a></li>
<li class="chapter" data-level="3.5.2" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#experiment-2"><i class="fa fa-check"></i><b>3.5.2</b> Experiment 2</a></li>
<li class="chapter" data-level="3.5.3" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#general-discussion"><i class="fa fa-check"></i><b>3.5.3</b> General discussion</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#acknowledgements"><i class="fa fa-check"></i><b>3.6</b> Acknowledgements</a></li>
<li class="chapter" data-level="3.7" data-path="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html"><a href="orofacial-electromyographic-correlates-of-induced-verbal-rumination.html#suppCH3"><i class="fa fa-check"></i><b>3.7</b> Supplementary data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dissociating-facial-electromyographic-correlates-of-visual-and-verbal-induced-rumination.html"><a href="dissociating-facial-electromyographic-correlates-of-visual-and-verbal-induced-rumination.html"><i class="fa fa-check"></i><b>4</b> Dissociating facial electromyographic correlates of visual and verbal induced rumination</a></li>
<li class="chapter" data-level="5" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>5</b> Introduction</a><ul>
<li class="chapter" data-level="5.1" data-path="introduction-1.html"><a href="introduction-1.html#rumination-its-definition-functions-and-consequences"><i class="fa fa-check"></i><b>5.1</b> Rumination: its definition, functions and consequences</a></li>
<li class="chapter" data-level="5.2" data-path="introduction-1.html"><a href="introduction-1.html#the-nature-of-ruminative-thoughts"><i class="fa fa-check"></i><b>5.2</b> The nature of ruminative thoughts</a></li>
<li class="chapter" data-level="5.3" data-path="introduction-1.html"><a href="introduction-1.html#inducing-rumination-in-a-controlled-environment"><i class="fa fa-check"></i><b>5.3</b> Inducing rumination in a controlled environment</a></li>
<li class="chapter" data-level="5.4" data-path="introduction-1.html"><a href="introduction-1.html#the-present-study"><i class="fa fa-check"></i><b>5.4</b> The present study</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="methods-1.html"><a href="methods-1.html"><i class="fa fa-check"></i><b>6</b> Methods</a><ul>
<li class="chapter" data-level="6.1" data-path="methods-1.html"><a href="methods-1.html#participants-1"><i class="fa fa-check"></i><b>6.1</b> Participants</a></li>
<li class="chapter" data-level="6.2" data-path="methods-1.html"><a href="methods-1.html#material-1"><i class="fa fa-check"></i><b>6.2</b> Material</a></li>
<li class="chapter" data-level="6.3" data-path="methods-1.html"><a href="methods-1.html#procedure-1"><i class="fa fa-check"></i><b>6.3</b> Procedure</a><ul>
<li class="chapter" data-level="6.3.1" data-path="methods-1.html"><a href="methods-1.html#trait-questionaires"><i class="fa fa-check"></i><b>6.3.1</b> Trait questionaires</a></li>
<li class="chapter" data-level="6.3.2" data-path="methods-1.html"><a href="methods-1.html#state-questionaires"><i class="fa fa-check"></i><b>6.3.2</b> State questionaires</a></li>
<li class="chapter" data-level="6.3.3" data-path="methods-1.html"><a href="methods-1.html#baseline-measurements"><i class="fa fa-check"></i><b>6.3.3</b> Baseline measurements</a></li>
<li class="chapter" data-level="6.3.4" data-path="methods-1.html"><a href="methods-1.html#imagery-training"><i class="fa fa-check"></i><b>6.3.4</b> Imagery training</a></li>
<li class="chapter" data-level="6.3.5" data-path="methods-1.html"><a href="methods-1.html#stress-induction"><i class="fa fa-check"></i><b>6.3.5</b> Stress induction</a></li>
<li class="chapter" data-level="6.3.6" data-path="methods-1.html"><a href="methods-1.html#rumination-induction"><i class="fa fa-check"></i><b>6.3.6</b> Rumination induction</a></li>
<li class="chapter" data-level="6.3.7" data-path="methods-1.html"><a href="methods-1.html#muscle-specific-relaxation"><i class="fa fa-check"></i><b>6.3.7</b> Muscle-specific relaxation</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="methods-1.html"><a href="methods-1.html#emg-signal-processing-1"><i class="fa fa-check"></i><b>6.4</b> EMG signal processing</a></li>
<li class="chapter" data-level="6.5" data-path="methods-1.html"><a href="methods-1.html#data-analysis"><i class="fa fa-check"></i><b>6.5</b> Data analysis</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="results-1.html"><a href="results-1.html"><i class="fa fa-check"></i><b>7</b> Results</a><ul>
<li class="chapter" data-level="7.1" data-path="results-1.html"><a href="results-1.html#effects-of-the-rumination-induction-and-rumination-modality"><i class="fa fa-check"></i><b>7.1</b> Effects of the rumination induction and rumination modality</a><ul>
<li class="chapter" data-level="7.1.1" data-path="results-1.html"><a href="results-1.html#descriptive-statistics-and-figures"><i class="fa fa-check"></i><b>7.1.1</b> Descriptive statistics and figures</a></li>
<li class="chapter" data-level="7.1.2" data-path="results-1.html"><a href="results-1.html#confirmatory-preregistered-analyses"><i class="fa fa-check"></i><b>7.1.2</b> Confirmatory (preregistered) analyses</a></li>
<li class="chapter" data-level="7.1.3" data-path="results-1.html"><a href="results-1.html#exploratory-analyses"><i class="fa fa-check"></i><b>7.1.3</b> Exploratory analyses</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="results-1.html"><a href="results-1.html#effects-of-the-relaxation"><i class="fa fa-check"></i><b>7.2</b> Effects of the relaxation</a><ul>
<li class="chapter" data-level="7.2.1" data-path="results-1.html"><a href="results-1.html#planned-preregistered-analyses"><i class="fa fa-check"></i><b>7.2.1</b> Planned (preregistered) analyses</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="discussion-1.html"><a href="discussion-1.html"><i class="fa fa-check"></i><b>8</b> Discussion</a><ul>
<li class="chapter" data-level="8.1" data-path="discussion-1.html"><a href="discussion-1.html#inducing-rumination-in-different-modalities"><i class="fa fa-check"></i><b>8.1</b> Inducing rumination in different modalities</a></li>
<li class="chapter" data-level="8.2" data-path="discussion-1.html"><a href="discussion-1.html#modality-specific-and-effector-specific-relaxation-effects"><i class="fa fa-check"></i><b>8.2</b> Modality-specific and effector-specific relaxation effects</a></li>
<li class="chapter" data-level="8.3" data-path="discussion-1.html"><a href="discussion-1.html#conclusions"><i class="fa fa-check"></i><b>8.3</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="supp.html"><a href="supp.html"><i class="fa fa-check"></i><b>9</b> Supplementary materials</a></li>
<li class="chapter" data-level="" data-path="acknowledgements-1.html"><a href="acknowledgements-1.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="10" data-path="muscle-specific-electromyographic-correlates-of-inner-speech-production.html"><a href="muscle-specific-electromyographic-correlates-of-inner-speech-production.html"><i class="fa fa-check"></i><b>10</b> Muscle-specific electromyographic correlates of inner speech production</a></li>
<li class="chapter" data-level="11" data-path="articulatory-suppression-effects-on-induced-rumination.html"><a href="articulatory-suppression-effects-on-induced-rumination.html"><i class="fa fa-check"></i><b>11</b> Articulatory suppression effects on induced rumination</a></li>
<li class="chapter" data-level="12" data-path="refining-the-involvement-of-the-speech-motor-system-during-rumination-a-dual-task-investigation.html"><a href="refining-the-involvement-of-the-speech-motor-system-during-rumination-a-dual-task-investigation.html"><i class="fa fa-check"></i><b>12</b> Refining the involvement of the speech motor system during rumination: a dual-task investigation</a></li>
<li class="part"><span><b>III Discussion and conclusions</b></span></li>
<li class="chapter" data-level="13" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html"><i class="fa fa-check"></i><b>13</b> Discussion and perspectives</a><ul>
<li class="chapter" data-level="13.1" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html#summary-of-the-results"><i class="fa fa-check"></i><b>13.1</b> Summary of the results</a></li>
<li class="chapter" data-level="13.2" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html#benchmarks-for-theories-of-inner-speech"><i class="fa fa-check"></i><b>13.2</b> Benchmarks for theories of inner speech</a></li>
<li class="chapter" data-level="13.3" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html#limitations-and-ways-forward"><i class="fa fa-check"></i><b>13.3</b> Limitations and ways forward</a></li>
<li class="chapter" data-level="13.4" data-path="discussion-and-perspectives.html"><a href="discussion-and-perspectives.html#conclusions-1"><i class="fa fa-check"></i><b>13.4</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank"> Powered by bookdown </a></li>
<li><a href="http://www.barelysignificant.com" target="blank"> Ladislas Nalborczyk </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Understanding rumination as a form of inner speech</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methods-1" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Methods</h1>
<p>In the <em>Methods</em> and <em>Data analysis</em> sections, we report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study <span class="citation">(Simmons, Nelson, &amp; Simonsohn, <a href="references.html#ref-simmons_21_2012" role="doc-biblioref">2012</a>)</span>. A pre-registered version of our protocol can be found online: <a href="https://osf.io/c9pag/">https://osf.io/c9pag/</a>.</p>
<div id="participants-1" class="section level2">
<h2><span class="header-section-number">6.1</span> Participants</h2>
<p>Our sample included 85 female participants, ranging in age from 18 to 31 years (M = 19.8823529, SD = 2.0207621). We chose to include only female participants in the present study, for the following three reasons. First, women have been found to engage in rumination more than men <span class="citation">(Johnson &amp; Whisman, <a href="references.html#ref-Johnson2013" role="doc-biblioref">2013</a>)</span>. Second, in comparison with men, women have greater visual imagery abilities and report more vivid mental visual images <span class="citation">(as reviewed in Lawrence et al., <a href="references.html#ref-lawrence_visual_2018" role="doc-biblioref">2018</a>)</span>. Third, the distribution of gender is very unbalanced in Psychology courses. Therefore, it would be practically impossible to have a well-balanced sample with respect to gender. All participants attended undergraduate Psychology programs at Univ. Grenoble Alpes. They were all native speakers of French, had no history of psychiatric or neurological disorders, speech disorders or hearing deficits. Another inclusion criterion was that participants had no depressive symptoms. This was tested at the beginning of the experiment using the Center for Epidemiologic Studies – Depression scale <span class="citation">(CES-D, Radloff, <a href="references.html#ref-radloff_ces-d_1977" role="doc-biblioref">1977</a>)</span>. Those participants whose scores overstepped the threshold did not proceed to the main part of the experiment (N = 16). Instead, they were debriefed and received information about places they could turn to for counselling.</p>
<p>Participants were recruited through the university website. They were told that the goal of the study was to test a French adaptation of a novel intelligence test and were, therefore, blind to the actual goal of the study. Participants received course credits for their participation and were fully debriefed at the end of the experiment. Written consent was obtained from each participant and the study received an approval from the local ethical committee (CERNI, Amendement-2018-02-06-23, Avis-2015-03-03-61).</p>
<p>As described in the preregistration form, we used sequential testing to determine the appropriate sample size. More precisely, we recruited participants until reaching either a predetermined level of precision <span class="citation">(this procedure is described in Kruschke, <a href="references.html#ref-kruschke_doing_2015" role="doc-biblioref">2015</a>)</span> or the end of the period of time allocated to this experiment (fixed to eight weeks). We first determined a region of practical equivalence (ROPE) and a target precision level on the main effect of interest (i.e., the interaction between the effect of time (baseline versus post-induction, within-subject) and group (verbal rumination versus visual rumination induction, between-subject design), on the EMG amplitude of the OOI muscle). We recruited participants until the 95% credible interval (the Bayesian analogue of a confidence interval) around the parameter of interest was at least 0.8 times narrower than the ROPE. The ROPE can be defined as the region comprising the effect sizes that we consider as “null effects” (alternatively, it defines the minimum effect size of interest). We defined the ROPE as [-0.1, 0.1] on the scale of the normalised and baseline-standardised EMG amplitude. This ROPE has been defined to correspond to a “null effect” based on previous EMG data we have collected on control muscles (forearm). Then, we defined the target precision as 0.8 times the width of the ROPE, that is: <span class="math inline">\(0.8 \times 0.2 = 0.16\)</span>. We did not reach this threshold within the allocated time. Thus, we ran the study for the full eight weeks (details on the evolution of the estimation precision can be found in the <a href="supp.html#supp">supplementary materials</a>).</p>
</div>
<div id="material-1" class="section level2">
<h2><span class="header-section-number">6.2</span> Material</h2>
<p>The experimental procedure was developed using the OpenSesame software <span class="citation">(Mathôt, Schreij, &amp; Theeuwes, <a href="references.html#ref-mathot_opensesame:_2012" role="doc-biblioref">2012</a>)</span> and stimuli were displayed on a DELL computer screen of size 1280px*720px. TrignoTM Mini wireless sensors (Delsys Inc.) were used for the detection of the surface EMG signals. These sensors consist of a bigger and a smaller box. The smaller box contains two 5x1mm parallel electrode bars with 10mm between them that record bipolar muscle activation. For facial EMG, the small box with electrodes was attached to the face and the bigger box was usually placed on the side of the neck. Concerning the forearm EMG, both boxes were placed on the forearm. Both boxes were attached by double-sided adhesive tape. Before setting the sensors, the skin was cleaned by Nuprep scrubbing gel and by alcohol wipes. Signal acquisition and synchronisation was done using the PowerLab 16/35 (ADInstrument, PL3516) device with a sampling rate of 1926 Hz. In addition to EMG measurements, the audio signal was simultaneously recorded using a C1000S AKG microphone which was placed 20-30 cm away from participant, while the video was recorded using Sony HDR-CX240E camera. These recordings were taken in order to track any vocal or behavioural artefacts during periods of interest (i.e., baseline, rumination and relaxation). Labchart 8 software (ADInstrument, MLU60/8) was used for EMG and audio data collecting and processing.</p>
<p>Our exploration focused on the muscles that have already been found to be activated during covert or overt speech <span class="citation">(e.g., Laurent et al., <a href="references.html#ref-Laurent2016" role="doc-biblioref">2016</a>; Maier-Hein, Metze, Schultz, &amp; Waibel, <a href="references.html#ref-maier-hein_session_2005" role="doc-biblioref">2005</a>; Schultz &amp; Wand, <a href="references.html#ref-schultz_modeling_2010" role="doc-biblioref">2010</a>)</span>. With surface EMG, it is difficult to precisely relate a given skin position to a specific muscle. However, as authors often refer to the facial positions as muscle positions, we will follow this tradition for clarity. Because of their involvement in speech production, bipolar surface EMG electrodes were positioned on the <em>orbicularis oris inferior</em> (OOI), the <em>zygomaticus major</em> (ZYG) and the neck muscles (NCK). In addition, electrodes were also placed on the <em>frontalis</em> (FRO) as an non-speech but emotion-related muscle. Finally, we positioned a sensor on the <em>flexor carpi radialis</em> (FCR) to control for general (whole body) muscle contraction.</p>
<p>Speech-related sensors were positioned on the right side of the face whereas the emotion-related (forehead) sensor was positioned on the left side of participants’ faces, following studies that found larger movements of the right side of the mouth during speech production <span class="citation">(Nicholls &amp; Searle, <a href="references.html#ref-nicholls_asymmetries_2006" role="doc-biblioref">2006</a>)</span>, and more emotional expression on the left side of the face <span class="citation">(Nicholls, Ellis, Clement, &amp; Yoshino, <a href="references.html#ref-nicholls_detecting_2004" role="doc-biblioref">2004</a>)</span>. Since participants were asked to use a mouse to provide answers, the forearm sensor was positioned on the non-dominant forearm (that participants did not use to provide the answer).</p>
</div>
<div id="procedure-1" class="section level2">
<h2><span class="header-section-number">6.3</span> Procedure</h2>
<p>We formed two groups based on the modality participants were asked to ruminate in. Hereafter these groups will be referred to as <em>verbal</em> and <em>visual</em>. Participants were also divided based on the type of relaxation they were listening to, that is, an <em>orofacial</em> relaxation, or an <em>arm</em> relaxation. As a result, there were four groups in the experiment: <em>verbal – orofacial</em>, <em>verbal – arm</em>, <em>visual – orofacial</em>, and <em>visual – arm</em>.</p>
<div id="trait-questionaires" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Trait questionaires</h3>
<p>After filling the consent form, participants were asked to complete the CES-D <span class="citation">(Radloff, <a href="references.html#ref-radloff_ces-d_1977" role="doc-biblioref">1977</a>)</span>. Participants also filled out the short version of the Ruminative Response Scale <span class="citation">(RRS, Treynor et al., <a href="references.html#ref-treynor_rumination_2003" role="doc-biblioref">2003</a>)</span>, adapted and validated in French (Douilliez, Guimpel, Baeyens, &amp; Philippot, in preparation). These questionnaires were filled in paper format. Once it was determined that they could participate in the study (i.e., that they did not exceed the threshold for depressive symptoms on the CES-D), participants were equipped with the EMG sensors.</p>
</div>
<div id="state-questionaires" class="section level3">
<h3><span class="header-section-number">6.3.2</span> State questionaires</h3>
<p>Subsequently, a calibration was carried out, making sure that the sensors on each muscle were suitably detecting signals. Participants were then explained the Visual Analogue Scales (VASs) that were used to obtain various self reports throughout the experiment. Specifically, we explained what we meant by: <em>At this moment, my thoughts are presented in the form of words</em> (<em>VAS Verbal</em>), and <em>At this moment, my thoughts are presented in the form of visual mental images</em> (<em>VAS Visual</em>). To assess the level of state rumination, we used a French translation of the Brief State Rumination Inventory <span class="citation">(BSRI, Marchetti, Mor, Chiorri, &amp; Koster, <a href="references.html#ref-marchetti_brief_2018" role="doc-biblioref">2018</a>)</span>, composed of eight items also presented as VASs. From that point, the rest of the stimuli were presented on the computer screen and speakers, and the experimenter (blind to the condition) did not interact with the participants anymore.</p>
</div>
<div id="baseline-measurements" class="section level3">
<h3><span class="header-section-number">6.3.3</span> Baseline measurements</h3>
<p>Afterwards, participants listened to a guided relaxation (not focused on any specific muscle). The purpose of this relaxation was to minimise inter-individual variability of the initial mood states and to help participants to relax and get used to wearing the EMG sensors. The recording comprised of 240 seconds of guided relaxation, then a pause was made during which participants were told to continue relaxing and the baseline EMG measurements were recorded, after which the guided relaxation continued for another 30 seconds. Following this, participants baseline level of state rumination, verbal and visual level of thoughts were measured using the VASs.</p>
</div>
<div id="imagery-training" class="section level3">
<h3><span class="header-section-number">6.3.4</span> Imagery training</h3>
<p>Next, participants went through a “lemon training” based on the task proposed by <span class="citation">Holmes et al. (<a href="references.html#ref-holmes_causal_2008" role="doc-biblioref">2008</a>)</span>. The objective of this training was to show the participants precisely what was meant by <em>thinking in words</em> or <em>thinking in pictures</em>. The participants in the <em>verbal</em> group were asked to combine an image and a word imagining a sentence in their head, whereas participants in the <em>visual</em> group were asked to do the same, but only imagining a picture. There were two trials. After doing this task, participants rated how clear (how vivid) their sentence or image was, following which they had to say or describe it out loud. This served as a verification that participants did the task and that they understood it.</p>
</div>
<div id="stress-induction" class="section level3">
<h3><span class="header-section-number">6.3.5</span> Stress induction</h3>
<p>Afterwards, participants took the intelligence test. The test comprised 18 verbal and 18 spatial intelligence questions. It was designed in a way that most (13/18) questions were very difficult while also containing certain (5/18) items that were relatively easy, in order to not demotivate the participants. Participants were instructed to provide their answer within 30 seconds. The number of questions was selected so that even if participants replied very fast, they still encountered around 15 minutes of this frustrating situation. This manipulation has already been shown successful in inducing a negative mood <span class="citation">(Nalborczyk et al., <a href="references.html#ref-nalborczyk_orofacial_2017" role="doc-biblioref">2017</a>)</span>.</p>
</div>
<div id="rumination-induction" class="section level3">
<h3><span class="header-section-number">6.3.6</span> Rumination induction</h3>
<p>When the test was done, participants were asked to think about the causes, signification and consequences of their performance during the test and of their current feelings, while their IQ score was being calculated. The participants in the <em>verbal</em> group were asked to do this <em>with their inner voice</em> and the participants in the <em>visual</em> group <em>using mental visual images</em>. Following <span class="citation">Holmes et al. (<a href="references.html#ref-holmes_causal_2008" role="doc-biblioref">2008</a>)</span>’s task, the instructions were presented in written format together with an image showing a person thinking in words (in the <em>verbal</em> group) or in pictures (in the <em>visual</em> group). When ready, participants pressed the key and a loading sign showed on their screen which lasted for 5 minutes during which participants were expected to ruminate either using inner speech or mental images. When this period was done, participants were again presented with the VASs.</p>
</div>
<div id="muscle-specific-relaxation" class="section level3">
<h3><span class="header-section-number">6.3.7</span> Muscle-specific relaxation</h3>
<p>Finally, participants listened again to a guided relaxation, only this time there were two types of relaxation. One half of verbal and one half of visual group were assigned to an <em>orofacial relaxation</em> group and they listened to the relaxation that was focused on the mouth. The other two halves of both groups were randomly assigned to an <em>arm relaxation</em> group and they listened to the relaxation concentrated on the arm. Both relaxations had a similar structure with around 270 seconds of guidance, 60 seconds of pause during which the EMG measurements were performed and 25 seconds of relaxation closure. At the very end, participants were asked to write down what they thought was the goal of the experiment and what they were thinking during the score calculation (i.e., the rumination period). The first question served to assess a potential compliance bias insofar as due to the goal of the experiment (i.e., manipulation of the rumination modality), we could not make participants completely blind to the task. The second question served again to check how much participants followed the instruction. At the end of the experiment, participants were given an exhaustive debriefing explaining the goals of the research.</p>
</div>
</div>
<div id="emg-signal-processing-1" class="section level2">
<h2><span class="header-section-number">6.4</span> EMG signal processing</h2>
<p>Data were collected using Labchart8 and were subsequently exported to Matlab for signal processing (www.mathworks.fr, Matlab r2015a, version 8.5.0.197613). First, a 50Hz frequency comb filter was applied to eliminate excessive power noise. Then, in keeping with the recommendation for facial EMG studies <span class="citation">(De Luca et al., <a href="references.html#ref-de_luca_filtering_2010" role="doc-biblioref">2010</a>)</span>, a 20 Hz – 450 Hz bandpass filter was applied, in order to focus on the facial EMG frequency band. The EMG signal was centered to its mean and cut with respect to the three periods of interest (i.e., baseline, rumination and relaxation period), all of which were divided into 5s blocks. These data were then exported to <code>R</code> version 3.5.0 <span class="citation">(R Core Team, <a href="references.html#ref-R-base" role="doc-biblioref">2018</a>)</span>, where the mean of the absolute signal was calculated for each 5s block. Thus, a score for each muscle, in each period, for each participant was calculated. Absolute EMG values are not meaningful as muscle activation is never null, even in resting conditions, due in part to physiological noise. In addition, there are inter-individual variations in the amount of EMG amplitude in the baseline. To normalise for baseline amplitude across participants, we thus subtracted the EMG amplitude of the baseline to the two periods if interest (i.e., after rumination and after relaxation) and divided it by the variability of the signal at baseline for each muscle and each participant.</p>
<p>Although participants were given the instruction to remain still and to avoid unnecessary movements, there were a lot of subtle movements (e.g., biting the lips). The blocks containing these <em>artifacts</em> were removed from the analysis. This was done by inspecting all recordings and manually removing blocks during which there were visually obvious bursts of the EMG amplitude.</p>
</div>
<div id="data-analysis" class="section level2">
<h2><span class="header-section-number">6.5</span> Data analysis</h2>
<p>Statistical analyses were conducted using <code>R</code> version 3.5.0 <span class="citation">(R Core Team, <a href="references.html#ref-R-base" role="doc-biblioref">2018</a>)</span>, and are reported with the <code>papaja</code> <span class="citation">(Aust &amp; Barth, <a href="references.html#ref-R-papaja" role="doc-biblioref">2018</a>)</span> and <code>knitr</code> <span class="citation">(Xie, <a href="references.html#ref-R-knitr" role="doc-biblioref">2018</a>)</span> packages.</p>
<p>To model EMG amplitude variations in response to the rumination induction, we fitted a Bayesian multivariate regression model with the standardised EMG amplitude as an outcome and <em>Group</em> as a categorical predictor (contrast-coded). We used the same strategy for modelling the interaction effect between the type of induction and the type of rumination induction<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>. These analyses were conducted using the <code>brms</code> package <span class="citation">(<span class="citeproc-not-found" data-reference-id="R-brms_a"><strong>???</strong></span>)</span>, an <code>R</code> implementation of Bayesian multilevel models that employs the probabilistic programming language <code>Stan</code> <span class="citation">(Carpenter et al., <a href="references.html#ref-carpenter_stan:_2017" role="doc-biblioref">2017</a>)</span>.</p>
<p><code>Stan</code> implements gradient-based Markov Chain Monte Carlo (MCMC) algorithms, which allow yielding posterior distributions that are straightforward to use for interval estimation around all parameters. Four chains were run for each model, including each 10.000 iterations and a warmup of 2.000 iterations. Posterior convergence was assessed examining autocorrelation and trace plots, as well as the Gelman-Rubin statistic. Constant effects estimates were summarised via their posterior mean and 95% credible interval (CrI), where a credible interval interval can be considered as the Bayesian analogue of a classical confidence interval, except that it can be interpreted in a probabilistic way (contrary to confidence intervals). When applicable, we also report Bayes factors (BFs) computed using the Savage-Dickey method<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a>. These BFs can be interpreted as updating factors, from prior knowledge (what we knew before seeing the data) to posterior knowledge (what we know after seeing the data).</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="19">
<li id="fn19"><p>An introduction to Bayesian statistical modelling is outside the scope of the current paper but the interested reader is referred to <span class="citation">Nalborczyk et al. (<a href="references.html#ref-nalborczyk_introduction_2019" role="doc-biblioref">2019</a><a href="references.html#ref-nalborczyk_introduction_2019" role="doc-biblioref">a</a>)</span>, for an introduction to Bayesian multilevel modelling using the <code>brms</code> package.<a href="methods-1.html#fnref19" class="footnote-back">↩</a></p></li>
<li id="fn20"><p>This method simply consists in taking the ratio of the posterior density at the point of interest divided by the prior density at that point <span class="citation">(Wagenmakers, Lodewyckx, Kuriyal, &amp; Grasman, <a href="references.html#ref-wagenmakers_bayesian_2010" role="doc-biblioref">2010</a>)</span>.<a href="methods-1.html#fnref20" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="results-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lnalborczyk/phd_thesis/edit/master/04-chap4.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["thesis.pdf"],
"toc": {
"collapse": "none / section / subsection",
"scroll_highlight": true
},
"search": true,
"highlight": "pygments"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
