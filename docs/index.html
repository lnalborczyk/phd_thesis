<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Psychophysiological characteristics of verbal rumination</title>
  <meta name="description" content="Psychophysiological characteristics of verbal rumination">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Psychophysiological characteristics of verbal rumination" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Psychophysiological characteristics of verbal rumination" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path=""><a href="#welcome"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Theoretical chapters</b></span></li>
<li class="chapter" data-level="1" data-path=""><a href="#intro"><i class="fa fa-check"></i><b>1</b> Theoretical framework</a><ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#rumination-as-a-form-of-repetitive-negative-thinking"><i class="fa fa-check"></i><b>1.1</b> Rumination as a form of repetitive negative thinking</a></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#what-is-motor-imagery"><i class="fa fa-check"></i><b>1.2</b> What is motor imagery ?</a><ul>
<li class="chapter" data-level="1.2.1" data-path=""><a href="#the-motor-simulation-theory"><i class="fa fa-check"></i><b>1.2.1</b> The motor simulation theory</a></li>
<li class="chapter" data-level="1.2.2" data-path=""><a href="#emulation-and-internal-models"><i class="fa fa-check"></i><b>1.2.2</b> Emulation and internal models</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#emg"><i class="fa fa-check"></i><b>1.3</b> Electromyography of covert actions</a><ul>
<li class="chapter" data-level="1.3.1" data-path=""><a href="#explanations-for-the-presence-of-muscular-activity-during-motor-imagery"><i class="fa fa-check"></i><b>1.3.1</b> Explanations for the presence of muscular activity during motor imagery</a></li>
<li class="chapter" data-level="1.3.2" data-path=""><a href="#controversial-findings"><i class="fa fa-check"></i><b>1.3.2</b> Controversial findings</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path=""><a href="#what-is-that-little-voice-inside-my-head"><i class="fa fa-check"></i><b>1.4</b> What is that little voice inside my head ?</a><ul>
<li class="chapter" data-level="1.4.1" data-path=""><a href="#inner-speech-as-multimodal-verbal-imagery"><i class="fa fa-check"></i><b>1.4.1</b> Inner speech as multimodal verbal imagery</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path=""><a href="#overt-and-imagined-actions"><i class="fa fa-check"></i><b>1.5</b> Overt and imagined actions</a><ul>
<li class="chapter" data-level="1.5.1" data-path=""><a href="#motor-imagery"><i class="fa fa-check"></i><b>1.5.1</b> Motor imagery</a></li>
<li class="chapter" data-level="1.5.2" data-path=""><a href="#inner-speech---what-is-this-little-voice-in-my-head"><i class="fa fa-check"></i><b>1.5.2</b> Inner speech - what is this little voice in my head ?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path=""><a href="#methodological-framework"><i class="fa fa-check"></i><b>2</b> Methodological framework</a><ul>
<li class="chapter" data-level="2.1" data-path=""><a href="#electromyographic-correlates-of-speech-production"><i class="fa fa-check"></i><b>2.1</b> Electromyographic correlates of speech production</a><ul>
<li class="chapter" data-level="2.1.1" data-path=""><a href="#speech-production-mechanisms"><i class="fa fa-check"></i><b>2.1.1</b> Speech production mechanisms</a></li>
<li class="chapter" data-level="2.1.2" data-path=""><a href="#speech-production-muscles"><i class="fa fa-check"></i><b>2.1.2</b> Speech production muscles</a></li>
<li class="chapter" data-level="2.1.3" data-path=""><a href="#muscular-physiology"><i class="fa fa-check"></i><b>2.1.3</b> Muscular physiology</a></li>
<li class="chapter" data-level="2.1.4" data-path=""><a href="#emg-signal"><i class="fa fa-check"></i><b>2.1.4</b> EMG signal</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path=""><a href="#emg-signal-measures"><i class="fa fa-check"></i><b>2.2</b> EMG signal measures</a><ul>
<li class="chapter" data-level="2.2.1" data-path=""><a href="#motor-unit-action-potential"><i class="fa fa-check"></i><b>2.2.1</b> Motor unit action potential</a></li>
<li class="chapter" data-level="2.2.2" data-path=""><a href="#surface-emg"><i class="fa fa-check"></i><b>2.2.2</b> Surface EMG</a></li>
<li class="chapter" data-level="2.2.3" data-path=""><a href="#basic-signal-processing"><i class="fa fa-check"></i><b>2.2.3</b> Basic signal processing</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path=""><a href="#statistical-modelling-approach"><i class="fa fa-check"></i><b>2.3</b> Statistical modelling approach</a></li>
<li class="chapter" data-level="2.4" data-path=""><a href="#overview-of-the-experimental-chapters"><i class="fa fa-check"></i><b>2.4</b> Overview of the experimental chapters</a></li>
</ul></li>
<li class="part"><span><b>II Experimental chapters</b></span></li>
<li class="chapter" data-level="3" data-path=""><a href="#orofacial-electromyographic-correlates-of-induced-verbal-rumination"><i class="fa fa-check"></i><b>3</b> Orofacial electromyographic correlates of induced verbal rumination</a><ul>
<li class="chapter" data-level="3.1" data-path=""><a href="#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path=""><a href="#methods"><i class="fa fa-check"></i><b>3.2</b> Methods</a><ul>
<li class="chapter" data-level="3.2.1" data-path=""><a href="#participants"><i class="fa fa-check"></i><b>3.2.1</b> Participants</a></li>
<li class="chapter" data-level="3.2.2" data-path=""><a href="#material"><i class="fa fa-check"></i><b>3.2.2</b> Material</a></li>
<li class="chapter" data-level="3.2.3" data-path=""><a href="#procedure"><i class="fa fa-check"></i><b>3.2.3</b> Procedure</a></li>
<li class="chapter" data-level="3.2.4" data-path=""><a href="#data-processing-and-analysis"><i class="fa fa-check"></i><b>3.2.4</b> Data processing and analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path=""><a href="#results"><i class="fa fa-check"></i><b>3.3</b> Results</a><ul>
<li class="chapter" data-level="3.3.1" data-path=""><a href="#experiment-1-rumination-induction-1"><i class="fa fa-check"></i><b>3.3.1</b> Experiment 1: rumination induction</a></li>
<li class="chapter" data-level="3.3.2" data-path=""><a href="#experiment-2-rumination-reduction-by-relaxation-1"><i class="fa fa-check"></i><b>3.3.2</b> Experiment 2: rumination reduction by relaxation</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path=""><a href="#discussion"><i class="fa fa-check"></i><b>3.4</b> Discussion</a><ul>
<li class="chapter" data-level="3.4.1" data-path=""><a href="#experiment-1"><i class="fa fa-check"></i><b>3.4.1</b> Experiment 1</a></li>
<li class="chapter" data-level="3.4.2" data-path=""><a href="#experiment-2"><i class="fa fa-check"></i><b>3.4.2</b> Experiment 2</a></li>
<li class="chapter" data-level="3.4.3" data-path=""><a href="#general-discussion"><i class="fa fa-check"></i><b>3.4.3</b> General discussion</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path=""><a href="#acknowledgements-1"><i class="fa fa-check"></i><b>3.5</b> Acknowledgements</a></li>
<li class="chapter" data-level="3.6" data-path=""><a href="#supplementary-data"><i class="fa fa-check"></i><b>3.6</b> Supplementary data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path=""><a href="#dissociating-facial-electromyographic-correlates-of-visual-and-verbal-induced-rumination"><i class="fa fa-check"></i><b>4</b> Dissociating facial electromyographic correlates of visual and verbal induced rumination</a></li>
<li class="chapter" data-level="5" data-path=""><a href="#muscle-specific-electromyographic-correlates-of-inner-speech-production"><i class="fa fa-check"></i><b>5</b> Muscle-specific electromyographic correlates of inner speech production</a></li>
<li class="chapter" data-level="6" data-path=""><a href="#articulatory-suppression-effects-on-induced-rumination"><i class="fa fa-check"></i><b>6</b> Articulatory suppression effects on induced rumination</a></li>
<li class="chapter" data-level="7" data-path=""><a href="#refining-the-involvement-of-the-speech-motor-system-during-rumination-a-dual-task-investigation"><i class="fa fa-check"></i><b>7</b> Refining the involvement of the speech motor system during rumination: a dual-task investigation</a></li>
<li class="part"><span><b>III Discussion</b></span></li>
<li class="chapter" data-level="8" data-path=""><a href="#discussion-and-perspectives"><i class="fa fa-check"></i><b>8</b> Discussion and perspectives</a><ul>
<li class="chapter" data-level="8.1" data-path=""><a href="#summary-of-the-results"><i class="fa fa-check"></i><b>8.1</b> Summary of the results</a></li>
<li class="chapter" data-level="8.2" data-path=""><a href="#limitations-and-ways-forward"><i class="fa fa-check"></i><b>8.2</b> Limitations and ways forward</a></li>
<li class="chapter" data-level="8.3" data-path=""><a href="#conclusions"><i class="fa fa-check"></i><b>8.3</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#references"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank"> Powered by bookdown </a></li>
<li><a href="http://www.barelysignificant.com" target="blank"> Ladislas Nalborczyk </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Psychophysiological characteristics of verbal rumination</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Psychophysiological characteristics of verbal rumination</h1>
</div>
<div id="welcome" class="section level1 unnumbered">
<h1>Welcome</h1>
<p>This book, when finished, will contain my doctoral thesis (last compiled on 2019-03-23).</p>


<p>lah blah…</p>



<p>lah blah…</p>



<p>lah blah…</p>



<p>cknowledgements will be included in the final version of this thesis.</p>



<p>lah blah…</p>



<!-- Inserting TOC, LOT and LOF -->
<p>   </p>
<p> </p>
<p> </p>


</div>



<div id="intro" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Theoretical framework</h1>
<p>s you read these words, you might notice the presence of a familiar companion. A voice-like phenomenon that remains unnoticed until we pay attention to it. However, if I ask you to focus on that little voice while you are reading these lines, you would probably be able to provide a relatively fine-graind description of this thing that we call inner speech. Whose voice is it ? Is it yours ? Is it gendered ? It is usually possible to examine these aspects as well as more low-level features like the tone of this soundy companion, its pitch, its tempo, or virtually any sensory aspect of it. This first set of very basic observations already provide us some very important insights. First, if we can think about inner speech, then it should be something different from thinking itself (réf ?). Rather, inner speech (or <em>covert speech</em>), can be construed as <em>a</em> vehicle for conscious thought (instead of <em>verbal thinking</em>, for instance)<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. Second, the set of observations we can make about our inner voice also tautologically reveals that inner speech is accompanied by sensory percepts (sounds, kinaesthesic feelings, etc.). It thus raises an interesting question: where do these percepts come from ? Why do they look like the one we experience when we <em>actually</em> (overtly) speak ?</p>
<p>This first set of questions refer to the <em>nature</em> of inner speech, that is, <em>what</em> is it ? In the current work, we are mostly concerned with this first question. Another related set of interesting questions revolve around the <em>function</em> question, that is, <em>what for</em> is it ? The influential Vygotskian theory of inner speech development suggests that inner speech evolves from <em>private speech</em> (i.e., self-adressed overt speech) during childhood. As such, we (as others have argued elsewhere) postulate that the functions of inner speech are inherited from the functions of private speech, via a mechanism of internalisation. The specific features of this internalisation processs are worthy of investigation on their own (and we briefly discuss them later on) but we are mostly interesred in the <em>what is</em> (the nature) question here. Thus, we will only sparsely address the <em>functions</em> question in the following text.</p>
<p>That being said, it is interesting to look at situations in which these functions do not work as intended. These <em>dysfunctions</em> <span class="citation">(that can also be considered as <em>mis-exadaptation</em>, Agnati et al. <a href="#ref-agnati_possible_2012">2012</a>)</span> are as spread as… They can generally be understood as transdiagnostic processes (i.e., a process that is not specific to a single pathology), and cover various…</p>
<p>…</p>
<p>Learning how to internalise speech might be similar to learning how to internalise playing an instrument… Let’s consider the analogy between speaking and playing an instrument (e.g., the piano). Playing piano results from the learning of an infinitely complex coordination of fine motor sequences, that in turn produce sensory (kinestheatic, auditory, visual, etc) feedback to the producer of the action (the agent). It seems that (from a certain level of analysis), the act of speech can be paralleled with the act of playing an instrument in that its consists in the coordination of infinitely complex movements that result in some modifications in the environment that in turn generate sensory feedbacks for the agent. Thus, pursuing the analogy, we argue that imagining playing pian and imagining speaking (i.e., producing inner speech) might rest on similar mechanisms… see O’Shea &amp; Moran (2018) on expert pianists…</p>
<div id="rumination-as-a-form-of-repetitive-negative-thinking" class="section level2">
<h2><span class="header-section-number">1.1</span> Rumination as a form of repetitive negative thinking</h2>
<p>Blah blah <span class="citation">(<span class="citeproc-not-found" data-reference-id="koster_rumination_2013"><strong>???</strong></span>)</span>…</p>
<p>As suggested by <span class="citation">(<span class="citeproc-not-found" data-reference-id="Christoff2016"><strong>???</strong></span>)</span>, rumination and other forms of spontaneous thoughts can be considered in a common conceptual space (see Figure 1). This space is built upon two dimensions: <em>deliberate constraints</em> and <em>automatic constraints</em>. These dimensions represent two general mechanisms that allow to constrain the contents of these related mental states and the transitions between them. The first contrain correspond to a deliberate processus and is implemented through <strong>cognitive control</strong> <span class="citation">(<span class="citeproc-not-found" data-reference-id="Miller2000"><strong>???</strong></span>)</span>. The second constrain is referring to more automatic constrains like sensory afferences. In this framework, rumination is characterizsd by the highest level of automatic constraints and spread all along the <em>deliberate constraints</em> dimension.</p>
<div class="figure" style="text-align: center"><span id="fig:conceptual"></span>
<img src="assets/conceptual_space.png" alt="Conceptual space of different types of thought (Christoff et al., 2016)" width="75%" />
<p class="caption">
Figure 1.1: Conceptual space of different types of thought (Christoff et al., 2016)
</p>
</div>
<p><strong>Copy-pasted from zygoto old intro…</strong></p>
<p>Speech production might be one of the most complex motor action ever studied. Involving the fine-grained coordination of more than 100 muscles in the upper part of the body <span class="citation">(Simonyan and Horwitz <a href="#ref-simonyan_laryngeal_2011">2011</a>)</span>, its expression is shaped by a subtle combination of physiological, cultural and evolutionary determinants. In adult humans, its covert counterpart (i.e., <em>inner speech</em> or <em>verbal imagery</em>) has developed to allow the full reconstruction of usual overt speech situations. In the same way as visual imagery allows to mentally examine visual scenes, <em>verbal imagery</em> can be used as an internal tool, allowing –amongst other things– to rehearse or to prepare past and future speech situations <span class="citation">(for a review, see <span class="citeproc-not-found" data-reference-id="perrone-bertolotti_what_2014"><strong>???</strong></span>)</span>. In consideration of its self-evident motoric nature, a parallel can be drawn between verbal imagery and other forms of motor imagery (e.g., imagined walking or imagined writing). As such, inner speech studies might benefit from insights gained from the study of motor imagery and the field of motor cognition <span class="citation">(e.g., Haggard <a href="#ref-haggard_conscious_2005">2005</a>; Jeannerod <a href="#ref-jeannerod_motor_2006">2006</a>)</span>. Whereas previous research have demonstrated that it is possible to record muscle-specific electromyographic correlates of inner speech production using invasive intramuscular needle electrodes, more recent research using surface electromyography lead to mixed results. Building upon previous work, we describe an experimental set-up using surface electromyography with the aim of refining the description of the involvement of the speech motor system during inner speech production.</p>
</div>
<div id="what-is-motor-imagery" class="section level2">
<h2><span class="header-section-number">1.2</span> What is motor imagery ?</h2>
<div id="the-motor-simulation-theory" class="section level3">
<h3><span class="header-section-number">1.2.1</span> The motor simulation theory</h3>
<p>Motor imagery can be defined as the mental process by which one rehearses a given action, without engaging in the physical movements involved in this particular action. One of the most influential theoretical explanation of this broad phenomenon, the <em>motor simulation theory</em> <span class="citation">(MST; Jeannerod <a href="#ref-jeannerod_representing_1994">1994</a>; Jeannerod <a href="#ref-jeannerod_neural_2001">2001</a>; Jeannerod <a href="#ref-jeannerod_motor_2006">2006</a>)</span>, contains the three following postulates at its core: i) there exists a continuum between the covert (the mental representation) and the overt execution of an action, ii) action representations can operate off-line, via a <em>simulation</em> mechanism, and iii) covert actions rely on the same set of mechanisms as the overt actions they simulate, except that execution is inhibited <span class="citation">(O’Shea and Moran <a href="#ref-oshea_does_2017">2017</a>)</span>.</p>
<p>In this framework, the concept of simulation refers to the “offline rehearsal of neural networks” <span class="citation">(Jeannerod <a href="#ref-jeannerod_motor_2006">2006</a>)</span>, and motor imagery is conceptualised as a simulation of the covert stage of the same executed action <span class="citation">(O’Shea and Moran <a href="#ref-oshea_does_2017">2017</a>)</span>. The MST shares some similarities with the theories of embodied and grounded cognition <span class="citation">(<span class="citeproc-not-found" data-reference-id="barsalou_grounded_2008"><strong>???</strong></span>)</span> in that both allow to account for the phenomenon of motor imagery by appealing to a simulation mechanism. However, the concept of simulation in grounded theories is assumed to be multi-modal (not just motoric) and to operate in order to achieve a particular abstract knowledge <span class="citation">(O’Shea and Moran <a href="#ref-oshea_does_2017">2017</a>)</span>, which is not the concern of the MST<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>.</p>
<p>The MST is supported by a wealth a findings, going from mental chronometry studies showing that the time taken to perform an action is often found to be similar to the time needed to imagine the corresponding action <span class="citation">(though not always, see Glover and Baran <a href="#ref-glover_motor-cognitive_2017">2017</a>, for a review of controversial findings and for an alternative conceptualisation of motor imagery)</span>, to neuroimaging and neurostimulation studies showing that both motor imagery and overt actions tend to recruit similar frontal, parietal and sub-cortical regions <span class="citation">(e.g., Hétu et al. <a href="#ref-hetu_neural_2013">2013</a>; Jeannerod <a href="#ref-jeannerod_neural_2001">2001</a>)</span>. The involvement of the motor system during motor imagery is also supported by repeated observations of autonomic responses and peripheral muscular activity during motor imagery (we discuss these observations in section <a href="#emg">1.3</a>).</p>
</div>
<div id="emulation-and-internal-models" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Emulation and internal models</h3>
<p>A second class of explanatory models of motor imagery are concerned with the phenomenon of <em>emulation</em> and with <em>internal models</em> <span class="citation">(see Gentsch et al. <a href="#ref-gentsch_towards_2016">2016</a>, for a review of the similarities and dissimilarities of simulation and emulation models)</span>.</p>
<p>Internal model theories share the postulate that the motor system is represented by <em>internal models</em>, whose function is to estimate and anticipate the outcome of a motor command. One of its variant, the <em>motor control theory</em> <span class="citation">(e.g., Kawato <a href="#ref-kawato_internal_1999">1999</a>; Wolpert, Ghahramani, and Jordan <a href="#ref-wolpert_internal_1995">1995</a>)</span>, assumes two kind of models: a forward model that predicts the sensory consequences of motor commands from efference copies, and an inverse model that calculates the feed-forward motor commands from the desired movement <span class="citation">(Gentsch et al. <a href="#ref-gentsch_towards_2016">2016</a>)</span>.</p>
<p>Emulation theories <span class="citation">(e.g., Grush <a href="#ref-grush_emulation_2004">2004</a>; Moulton and Kosslyn <a href="#ref-moulton_imagining_2009">2009</a>)</span> borrow from both previously discussed framework (i.e., simulation theories and internal model theories) to posit a specific kind of simulation. While the MST postulates that during simulation the motor system is guided exclusively by internal motor representations, the emulation theories suggest that both motor and sensory systems are emulated in parallel <span class="citation">(Grush <a href="#ref-grush_emulation_2004">2004</a>; O’Shea and Moran <a href="#ref-oshea_does_2017">2017</a>)</span>.</p>
<p>In the emulation model proposed by <span class="citation">Grush (<a href="#ref-grush_emulation_2004">2004</a>)</span>, the <em>emulator</em> is a device that implements the same input-output function as the body (i.e., the musculoskeletal system and relevant proprioceptive/kinaesthetic systems). When the emulator receives a copy of the control signal (which is also sent to the body), it produces an output signal (the emulator feedback), identical or similar to the feedback signal produced by the body<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. This feedback would be responsible for the presence of sensory percepts (e.g., visual, auditory, kinaesthetic) during motor imagery.</p>
<p>One important difference between the emulation theory of motor imagery and the MST though, is that the latter takes the mere activation of efferent motor centres as being sufficient for explaining motor imagery, while the emulation theory postulates that an emulator of the musculoskeletal system is needed <span class="citation">(Grush <a href="#ref-grush_emulation_2004">2004</a>, 384–85)</span>. <span class="citation">Grush (<a href="#ref-grush_emulation_2004">2004</a>)</span> suggested an analogy to illustrate this difference: “The emulation theory claims that motor imagery is like a pilot sitting in a flight simulator, and the pilot’s efferent commands (hand and foot movements, etc.) are translated into faux “sensory” information (instrument readings, mock visual display) by the flight simulator which is essentially an emulator of an aircraft. The simulation theory claims that just a pilot, moving her hands and feet around but driving neither a real aircraft nor a flight simulation, is sufficient for mock sensory information”. Alternatively, in the words of <span class="citation">Moulton and Kosslyn (<a href="#ref-moulton_imagining_2009">2009</a>)</span>, instrumental simulations (à la Jeannerod) can be thought of as <em>first-order</em> simulations that imitate the content of the simulated action, while emulative simulations can be thought of as <em>second-order</em> simulations that imitate both the content and the processes that change the content.</p>
</div>
</div>
<div id="emg" class="section level2">
<h2><span class="header-section-number">1.3</span> Electromyography of covert actions</h2>
<div id="explanations-for-the-presence-of-muscular-activity-during-motor-imagery" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Explanations for the presence of muscular activity during motor imagery</h3>
<p>Motor imagery has consistently been defined as the mental rehearsal of a motor action without any overt movement. One consequence of this claim is that, in order to prevent execution, the neural commands for muscular contractions should be blocked at some level of the motor system by active inhibitory mechanisms <span class="citation">(for a review, see Guillot et al. <a href="#ref-guillot_imagining_2012">2012</a>)</span>. Despite these inhibitory mechanisms, there is now abundant evidence for peripheral muscular activation during motor imagery <span class="citation">(for a review, see Guillot and Collet <a href="#ref-guillot_contribution_2005">2005</a>; Guillot et al. <a href="#ref-guillot_imagining_2012">2012</a>)</span>. As suggested by <span class="citation">Jeannerod (<a href="#ref-jeannerod_representing_1994">1994</a>)</span>, the incomplete inhibition of the motor commands would provide a valid explanation to account for the peripheral muscular activity observed during motor imagery. This idea has been corroborated by studies of changes in the excitability of the motor pathways during motor imagery tasks. <span class="citation">Bonnet et al. (<a href="#ref-bonnet_mental_1997">1997</a>)</span> measured spinal reflexes while participants were instructed to either press a pedal with the foot or to simulate the same action mentally. They observed that both H-reflexes and T-reflexes increased during motor imagery, and that these increases correlated with the force of the simulated pressure. Using transcranial magnetic stimulation and motor evoked potentials (MEPs), several investigators observed muscle-specific increases of MEPs during various motor imagery tasks, while no such increase could be observed in antagonist muscles <span class="citation">(e.g., Fadiga et al. <a href="#ref-fadiga_corticospinal_1999">1999</a>; Rossini <a href="#ref-rossini_corticospinal_1999">1999</a>)</span><a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>.</p>
<p>Interestingly, the dominant interpretation of the muscular correlates of motor imagery at the beginning of the last century was that the peripheral muscular activity observed during imagined actions was the <em>source</em> of the mental content. However, as explained by <span class="citation">Jeannerod (<a href="#ref-jeannerod_motor_2006">2006</a>)</span>, this interpretation of mental processes as a consequence of peripheral feedback is now disproved, for instance by the simple fact that many people can experiment motor imagery, without any observable muscular activity<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>. In the most recent theoretical explanations of motor imagery (e.g., MST, emulation or internal models theories), the peripheral activity is rather assumed to be a consequence of an incomplete inhibition of motor output during the mental states involving motor simulation/emulation (i.e., these views adhere to a <em>centralist</em> interpretation of the physiological correlates of inner speech).</p>
</div>
<div id="controversial-findings" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Controversial findings</h3>
<p>As reviewed in <span class="citation">Guillot, Lebon, and Collet (<a href="#ref-guillot_electromyographic_2010">2010</a>)</span>, although there are many observations showing a peripheral muscular activity during motor imagery, there are also many studies failing to do so, or reporting surprisingly high levels of inter-subject variability, with some participants showing no muscular activity at all. Putting aside the discussion on the exact nature and location of the inhibitory mechanisms during motor imagery <span class="citation">(see Guillot et al. <a href="#ref-guillot_imagining_2012">2012</a>)</span>, two main explanations have been advanced to resolve these discrepancies. First, the electromyographic activity recorded during motor imagery could be moderated by the perspective taken in motor imagery. We usually make a distinction between a first-person perspective or <em>internal imagery</em> (i.e., imagining an action as we would execute it) and a third-person perspective or <em>external imagery</em> (i.e., imagining an action as an observer of this action), that seem to involve different neural and cognitive processes. It has been shown that a first-person perspective generally results in greater EMG activity than motor imagery in a third-person perspective <span class="citation">(Hale <a href="#ref-hale_effects_1982">1982</a>; Harris and Robinson <a href="#ref-harris_effects_1986">1986</a>)</span>. Second, some authors postulated that the intensity of the EMG activity recorded during motor imagery might be related to the individual ability to form an accurate mental representation of the motor skill (i.e., the vividness of the mental image). However, after reviewing the available evidence, <span class="citation">Guillot et al. (<a href="#ref-guillot_brain_2009">2009</a>)</span> concluded that this is unlikely to be the case. Alternatively, discrepancies in experimental design and methodological choices (e.g., use of intramuscular versus surface electromyography) could also explain these different results <span class="citation">(Guillot, Lebon, and Collet <a href="#ref-guillot_electromyographic_2010">2010</a>)</span>.</p>
<p>In the next section, we turn to a discussion of inner speech conceptualised as a kind of motor (and sensory) imagery of speech, and discuss the theoretical underpinnings of this proposition as well as the available empirical evidence in its support.</p>
</div>
</div>
<div id="what-is-that-little-voice-inside-my-head" class="section level2">
<h2><span class="header-section-number">1.4</span> What is that little voice inside my head ?</h2>
<div id="inner-speech-as-multimodal-verbal-imagery" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Inner speech as multimodal verbal imagery</h3>
<p>While grasping the concept of a visual image appears as relatively straightforward, it seems more difficult at first to grasp the concept of a motor image, especially when it comes to verbal imagery. The subjective experience of the tension that results from a given position of the articulators and the covert production of an incompatible speech sound permits to substantiate what a motor image is. For instance, it is generally impossible to generate the image of the pronunciation of the sound “b” while keeping the mouth wide opened <span class="citation">(e.g., Binet <a href="#ref-binet_psychologie_1886">1886</a>; Stricker <a href="#ref-stricker_studien_1880">1880</a>)</span>. This simple experiment allows defining imagined speech as the simulation of the corresponding overt verbal content, where <em>simulation</em> is meant to be understood either as the off-line rehearsal of neural motor networks involved in the overt action <span class="citation">(Jeannerod <a href="#ref-jeannerod_motor_2006">2006</a>)</span>, or in the terms of the emulation theories discussed previously<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>.</p>
<p>The model of wilful (voluntary) inner speech production introduced in <span class="citation">Lœvenbruck et al. (<a href="#ref-loevenbruck_cognitive_2018">2018</a>)</span> goes one step further and, by building on the models of speech motor control <span class="citation">(e.g., Houde and Nagarajan <a href="#ref-houde_speech_2011">2011</a>; Wolpert, Ghahramani, and Jordan <a href="#ref-wolpert_internal_1995">1995</a>)</span>, describes inner speech as “multi-modal acts with multi-sensory percepts stemming from coarse multi-sensory goals”. In other words, the auditory and kinaesthetic sensations perceived during inner speech prediction are assumed to be the predicted sensory consequences of speech motor acts, emulated by internal forward models, that use the efference copies issued from an inverse model <span class="citation">(this proposal shares similarities with the emulation model of motor imagery discussed earlier, Grush <a href="#ref-grush_emulation_2004">2004</a>)</span>.</p>
<p><strong>Fin de l’intro old de zygoto…</strong></p>
</div>
</div>
<div id="overt-and-imagined-actions" class="section level2">
<h2><span class="header-section-number">1.5</span> Overt and imagined actions</h2>
<p>Wittgenstein’s (1953) famous query: “When I raise my arm, what is left after subtracting the fact that my arm raised?”. We posit that what is left is an internal model (a representation) of what should happen if and when my arm goes up (Jeannerod, 1999)…</p>
<div id="motor-imagery" class="section level3">
<h3><span class="header-section-number">1.5.1</span> Motor imagery</h3>
<p>Considerable experimental evidence has accumulated to suggest that movement execution and MI share substantial overlap of active brain regions (for review, see Guillot et al., 2012). Such apparent functional equivalence supports the hypothesis that MI draws on the similar neural networks that are used in actual perception and motor control (Jeannerod, 1994; Grezes and Decety, 2001; Holmes and Collins, 2001)…</p>
<p>See introduction of O’Shea (2017) phd thesis introduction…</p>
<p>See Stinear’s chapter in Guillot’s book for intracortical and spinal mechanisms involved during motor imagery (p.55-57).</p>
<div id="simulation-theories" class="section level4">
<h4><span class="header-section-number">1.5.1.1</span> Simulation theories</h4>
<p>For Jeannerod (1995), motor imagery is necessarily first-perspective. Third perspective imagery is imagery, but not MOTOR imagery… Motor representations are conceived here as ‘internal models’ of the goal of an action.</p>
</div>
<div id="emulation-theories" class="section level4">
<h4><span class="header-section-number">1.5.1.2</span> Emulation theories</h4>
<p>…</p>
</div>
<div id="action-representation-and-internal-models" class="section level4">
<h4><span class="header-section-number">1.5.1.3</span> Action representation and internal models</h4>
<p>Voir Jeannerod (2004), Wolpert el al. (1995), Wolpert &amp; Gharamani (2000)…</p>
</div>
</div>
<div id="inner-speech---what-is-this-little-voice-in-my-head" class="section level3">
<h3><span class="header-section-number">1.5.2</span> Inner speech - what is this little voice in my head ?</h3>
<p>…</p>
<p>The inner voice as the sensory consequence (prediction, see Loevenbruck et al., 2018) of imagined speech. Analogy with raising the arm: what we perceive when we imagine raising our arm are the sensory consequences (e.g., visual) of what would happen if we actually raised our arm, these are then kind of predictions. The same thing happens during inner speech production: the inner voice is the predicted auditory consequence of actual speech, except that it’s predicted. The two actions might seem very different, partly because of differences in the degree of automaticity. Imagining raising our arm might need a voluntary/deliberate/conscious (choose a word) intention (i.e., I want to raise my arm &gt; I raise my arm) while speech imagery (i.e., inner speech) seems more automatic: we do not expression consciously the intention to speak, we just speak…</p>
<div id="mvtv-cohen-1986" class="section level4">
<h4><span class="header-section-number">1.5.2.1</span> MVTV Cohen (1986)</h4>
<p>…</p>
</div>
<div id="predictive-models" class="section level4">
<h4><span class="header-section-number">1.5.2.2</span> Predictive models</h4>
<p>Learning how to internalise speech might be similar to learning how to internalise playing an instrument… Let’s consider the analogy between speaking and playing an instrument (e.g., the piano). Playing piano results from the learning of an infinitely complex coordination of fine motor sequences, that in turn produce sensory (kinestheatic, auditory, visual, etc) feedback to the producer of the action (the agent). It seems that (from a certain level of analysis), the act of speech can be paralleled with the act of playing an instrument in that its consists in the coordination of infinitely complex movements that result in some modifications in the environment that in turn generate sensory feedbacks for the agent. Thus, pursuing the analogy, we argue that imagining playing pian and imagining speaking (i.e., producing inner speech) might rest on similar mechanisms… see O’Shea &amp; Moran (2018) on expert pianists…</p>
</div>
<div id="loevenbruck-et-al.-hmosaic" class="section level4">
<h4><span class="header-section-number">1.5.2.3</span> Loevenbruck et al., HMOSAIC</h4>
<p>…</p>

</div>
</div>
</div>
</div>
<div id="methodological-framework" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Methodological framework</h1>
<div id="electromyographic-correlates-of-speech-production" class="section level2">
<h2><span class="header-section-number">2.1</span> Electromyographic correlates of speech production</h2>
<p>…</p>
<div id="speech-production-mechanisms" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Speech production mechanisms</h3>
<p>…</p>
</div>
<div id="speech-production-muscles" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Speech production muscles</h3>
<p>…</p>
</div>
<div id="muscular-physiology" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Muscular physiology</h3>
<p>…</p>
</div>
<div id="emg-signal" class="section level3">
<h3><span class="header-section-number">2.1.4</span> EMG signal</h3>
</div>
</div>
<div id="emg-signal-measures" class="section level2">
<h2><span class="header-section-number">2.2</span> EMG signal measures</h2>
<p>Muscular activity can be studied at different levels. At the cellular level, using electrophysiological measures like micro-electrods implanted in the cell, that allow direct measures of <strong>action potential</strong>. At the segmental level, biomechanis study muscular activity using surface sensors, positionned on the skin…intermediate levels…</p>
<div id="motor-unit-action-potential" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Motor unit action potential</h3>
<p>The <strong>motor unit action potential</strong> (MUAP) is the electric field resulting from the sum of the electric fiels emitted by each fiber of the motor unit. This train of action potentials will generate a <em>train</em> of MUAP, call <strong>motor unit action potential trains</strong> (MUAPT). The electric potential generated by this field is highly dependent of parameters such as the number of fibers, their length, speed of conduction and position of the neuromuscular junction…</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-1"></span>
<img src="assets/muap.jpg" alt="Motor unit action potential representation." width="100%" />
<p class="caption">
Figure 2.1: Motor unit action potential representation.
</p>
</div>
<p>To sum up, the EMG signal results from a mixture of recruited motor units…</p>
</div>
<div id="surface-emg" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Surface EMG</h3>
<p>…<em>crosstalk</em> phenomenon <span class="citation">(De Luca <a href="#ref-de_luca_use_1997">1997</a>)</span>. In reason of the important… of facial muscles, the EMG activity of one recorded muscle generally does not represent the activity of a single muscle but rather a mixture of… <span class="citation">L. Rapin (<a href="#ref-Rapin2011">2011</a>)</span>…</p>
</div>
<div id="basic-signal-processing" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Basic signal processing</h3>
<p>…the EMG signal is a stochastic signal… In order to illustrate what EMG signal looks like, we simulated EMG signal based on a standard algorithm implemented in the <code>biosignalEMG</code> package <span class="citation">(Guerrero and Macias-Diaz <a href="#ref-R-biosignalEMG">2018</a>)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(biosignalEMG)
<span class="kw">library</span>(tidyverse)

emg &lt;-<span class="st"> </span><span class="kw">syntheticemg</span>(
  <span class="dt">off.sd =</span> <span class="dv">1</span>, <span class="dt">on.sd =</span> <span class="dv">2</span>, <span class="dt">on.mode.pos =</span> <span class="fl">0.1</span>, <span class="dt">samplingrate =</span> <span class="fl">1e3</span>, <span class="dt">units =</span> <span class="st">&quot;mV&quot;</span>
  )<span class="op">$</span>values

<span class="kw">ts.plot</span>(
  emg, <span class="dt">xlab =</span> <span class="st">&quot;Time (samples)&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Raw EMG signal (mV)&quot;</span>,
  <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>
  )</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="02-chap2_files/figure-html/unnamed-chunk-2-1.png" alt="Simulated EMG signal." width="100%" />
<p class="caption">
Figure 2.2: Simulated EMG signal.
</p>
</div>
<p>We usually rectify the EMG signal by taking its absolute value and substracting the mean in order to correct for any offset (bias) present in the raw data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">&gt;</span><span class="st"> </span>emg &lt;-<span class="st"> </span><span class="kw">abs</span>(emg <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(emg) )
<span class="op">&gt;</span><span class="st"> </span>
<span class="er">&gt;</span><span class="st"> </span><span class="kw">ts.plot</span>(
<span class="op">+</span><span class="st">   </span>emg, <span class="dt">xlab =</span> <span class="st">&quot;Time (samples)&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Rectified EMG signal&quot;</span>,
<span class="op">+</span><span class="st">   </span><span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>
<span class="op">+</span><span class="st">   </span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-3"></span>
<img src="02-chap2_files/figure-html/unnamed-chunk-3-1.png" alt="Rectified EMG signal." width="100%" />
<p class="caption">
Figure 2.3: Rectified EMG signal.
</p>
</div>
<p>From there, two main measures can be used to represent the magnitude of muscle activity<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>. The first one is the <strong>mean absolute value</strong> (MAV):</p>
<p><span class="math display">\[MAV = \frac{1}{N} \sum_{n=1}^{N} | x_{n} |\]</span></p>
<p>which is computed over a specific interval and where <span class="math inline">\(|x_{n}|\)</span> is the absolute value of a datum of EMG in the data window. The unit of measurement is <span class="math inline">\(mV\)</span> or <span class="math inline">\(\mu V\)</span>, and the MAV calculation is generally similar to the numerical formula for integration <span class="citation">(Kamen and Gabriel <a href="#ref-kamen_essentials_2010">2010</a>)</span>. The second one is the <strong>root-mean-square</strong> (RMS) amplitude:</p>
<p><span class="math display">\[RMS = \sqrt \frac{1}{N} \sum_{n=1}^{N} | x^{2}_{n} |\]</span></p>
<p>where <span class="math inline">\(| x^{2}_{n} |\)</span> is the squared value of each EMG datum and has both physical and physiological meanings…</p>
</div>
</div>
<div id="statistical-modelling-approach" class="section level2">
<h2><span class="header-section-number">2.3</span> Statistical modelling approach</h2>
<p>Describe the way we approach data analysis here…</p>
</div>
<div id="overview-of-the-experimental-chapters" class="section level2">
<h2><span class="header-section-number">2.4</span> Overview of the experimental chapters</h2>
<p>…</p>

</div>
</div>



<div id="orofacial-electromyographic-correlates-of-induced-verbal-rumination" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Orofacial electromyographic correlates of induced verbal rumination</h1>
<p>Summary of the research…<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>As humans, we spend a considerable amount of time reflecting upon ourselves, thinking about our own feelings, thoughts and behaviors. Self-reflection enables us to create and clarify the meaning of past and present experiences (Boyd &amp; Fales, 1983; Nolen-Hoeksema, Wisco, &amp; Lyubomirsky, 2008). However, this process can lead to unconstructive consequences when self-referent thoughts become repetitive, abstract, evaluative, and self-critical <span class="citation">(Watkins <a href="#ref-Watkins2008">2008</a>)</span>.</p>
<p>Indeed, rumination is most often defined as a repetitive and recursive mode of responding to negative affect <span class="citation">(Rippere <a href="#ref-Rippere1977">1977</a>)</span> or life situations <span class="citation">(M. S. Robinson and Alloy <a href="#ref-Robinson2003">2003</a>)</span>. Although rumination is a common process that can be observed in the general population <span class="citation">(Watkins <a href="#ref-Watkins2008">2008</a>)</span>, it has been most extensively studied in depression and anxiety. Depressive rumination has been thoroughly studied by Susan Nolen-Hoeksema, who developed the Response Style Theory <span class="citation">(RST, Nolen-Hoeksema <a href="#ref-nolen-hoeksema_responses_1991">1991</a>)</span>. According to the RST, depressive rumination is characterized by an evaluative style of processing that involves recurrent thinking about the causes, meanings, and implications of depressive symptoms. Even though rumination can involve several modalities (i.e., visual, sensory), it is a predominantly verbal process <span class="citation">(Goldwin and Behar <a href="#ref-goldwin_concreteness_2012">2012</a>; McLaughlin, Borkovec, and Sibrava <a href="#ref-mclaughlin_effects_2007">2007</a>)</span>. In this study, we focus on verbal rumination, which can be conceived of as a particularly significant form of inner speech.</p>
<p>Inner speech or covert speech can be defined as silent verbal production in one’s mind or the activity of silently talking to oneself (Zivin, 1979). The nature of inner speech is still a matter of theoretical debate <span class="citation">(see Perrone-Bertolotti et al. <a href="#ref-Perrone-Bertolotti2014">2014</a> for a review)</span>. Two opposing views have been proposed in the literature: the Abstraction view and the Motor Simulation view. The Abstraction view describes inner speech as unconcerned with articulatory or auditory simulations and as operating on an amodal level. It has been described as “condensed, abbreviated, disconnected, fragmented, and incomprehensible to others” (Vygotsky, 1987). It has been argued that important words or grammatical affixes may be dropped in inner speech (Vygotsky, 1987) or even that the phonological form or representation of inner words may be incomplete (Sokolov, 1972; Dell &amp; Repka, 1992). MacKay (1992) stated that inner speech is nonarticulatory and nonauditory and that “Even the lowest level units for inner speech are highly abstract” (p.122).</p>
<p>In contrast with this Abstraction view, the physicalist or embodied view considers inner speech production as mental simulation of overt speech production. As such, it can be viewed as similar to overt speech production, except that the motor execution process is blocked and no sound is produced (Grèzes &amp; Decety, 2001; Postma &amp; Noordanus, 1996). Under this Motor Simulation view, a continuum exists between overt and covert speech, in line with the continuum drawn by Decety and Jeannerod (1996) between imagined and actual actions. This hypoth- esis has led certain authors to claim that inner speech by essence should share features with speech motor actions (Feinberg, 1978; Jones &amp; Fernyhough, 2007). The Motor Simulation view is supported by several findings. Firstly, covert and overt speech have comparable physiological correlates: for instance, measurements of speaking rate (Landauer, 1962; Netsell, Ashley, &amp; Bakker, 2010) and respiratory rate (Conrad &amp; Schönle, 1979) are similar in both. A prediction of the Motor Simulation view is that the speech motor system should be recruited during inner speech. Subtle muscle activity has been detected in the speech musculature using electromyography (EMG) during verbal mental imagery, silent reading, silent recitation (Jacobson, 1931; Sokolov, 1972; Livesay, Liebke, Samaras, &amp; Stanley, 1996; McGuigan &amp; Dollins, 1989), and during auditory verbal hallucination in patients with schizophrenia (Rapin, Dohen, Polosan, Perrier, &amp; L &amp; venbruck, 2013). Secondly, it has been shown that covert speech production involves a similar cerebral network as that of overt speech production. Covert and overt speech both recruit essential language areas in the left hemisphere (for a review, see Perrone- Bertolotti et al., 2014). However, there are differences. Consistent with the Motor Simulation view and the notion of a continuum between covert and overt speech, overt speech is associated with more activity in motor and premotor areas than inner speech (e.g., Palmer et al., 2001). This can be related to the absence of articulatory movements during inner verbal production. In a reciprocal way, inner speech involves cerebral areas that are not activated during overt speech (Basho, Palmer, Rubio, Wulfeck, &amp; Müller, 2007). Some of these activations (cingulate gyrus and superior rostral frontal cortex) can be attributed to the inhibition of overt responses.</p>
<p>These findings suggest that the processes involved in overt speech include those required for inner speech (except for inhibition). Several studies in patients with aphasia support this view: overt speech loss can either be associated with an impairment in inner speech (e.g., Levine, Calvanio, &amp; Popovics, 1982; Martin &amp; Caramazza, 1982) or with intact inner speech: only the later phases of speech production (execution) being affected by the lesion (Baddeley &amp; Wilson, 1985; Marshall et al., 1985; Vallar &amp; Cappa, 1987). Geva, Bennett, Warburton, and Patterson (2011) have reported a dissociation that goes against this view, however. In three patients with chronic post-stroke aphasia (out of 27 patients), poorer homophone and rhyme judgement performance was in fact observed in covert mode compared with overt mode. A limitation of this study, though, was that the task was to detect rhymes in written words, which could have been too difficult for the patients. To over- come this limitation, Langland-Hassan, Faries, Richardson, and Dietz (2015) have tested aphasia patients with a similar task, using images rather than written words. They also found that most patients performed better in the overt than in the covert mode. They inferred from these results that inner speech might be more demanding in terms of cognitive and linguistic load, and that inner speech may be a distinct ability, with its own neural substrates. We suggest an alternative interpretation to this dissociation. According to our view, rhyme and homophone judgements rely on auditory representations of the stimuli (see e.g., Paulesu, Frith, &amp; Frackowiak, 1993). Overt speech provides a strong acoustic output that is fed back to the auditory cortex and can create an auditory trace, which can be used to monitor speech. In the covert mode, the auditory output is only mentally simulated, and its saliency in the auditory system is lesser than in the overt mode. This is in accordance with the finding that inner speech is associated with reduced sensory cortex activation compared with overt speech (Shuster &amp; Lemieux, 2005). In patients with aphasia, the weakened saliency of covert auditory signals may be accentuated for two reasons: first, because of impairment in the motor-to-auditory transformation that produces the auditory simulation, and second, because of asso- ciated auditory deficits. Therefore, according to our view, the reduced performance observed in rhyme and homophone judgement tasks in the covert compared with the overt mode in brain-injured patients, simply indicates a lower saliency of the auditory sensations evoked during inner speech compared with the actual auditory sensations fed back during overt speech production. In summary, these findings suggest that overt and covert speech share common subjective, physiological and neural correlates, supporting the claim that inner speech is a motor simulation of overt speech.</p>
<p>However, the Motor Simulation view has been challenged by several experimental results. Examining the properties of errors during the production of tongue twisters, Oppenheim and Dell (2010) showed that speech errors display a lexical bias in both overt and inner speech. According to these researchers, errors also display a phonemic similar- ity effect (or articulatory bias), a tendency to exchange phonemes with common articulatory features, but this second effect is only observed with overt speech or with inner speech accompanied with mouthing. This has led Oppenheim and Dell (2010) to claim that inner speech is fully specified at the lexical level, but that it is impoverished at lower featural (articulatory) levels. This claim, related to the Abstraction view, is still debated however, as a phonemic similarity effect has been found by Corley, Brocklehurst and Moat (2011). Their findings suggest that inner speech is in fact specified at the articulatory level, even when there is no intention to articulate words overtly. Other findings however, may still challenge the Motor Simulation view. Netsell et al. (2010) have examined covert and overt speech in persons who stutter (PWS) and typical speakers. They have found that PWS were faster in covert than in overt speech while typical speakers presented similar overt and covert speech rates. This can be interpreted in favour of the Abstraction view, in which inner representations are not fully specified at the articulatory level, which would explain why they are not disrupted in PWS speech. Altogether, these results suggest that full articulatory specification may not always be necessary for inner speech to be produced.</p>
<p>The aim of this study is to examine the physiological correlates of verbal rumination in an attempt to provide new data in the debate between motor simulation and abstraction. A prediction of the Motor Simulation view is that verbal rumination, as a kind of inner speech, should be accompanied with activity in speech-related facial muscles, as well as in negative emotion or anxiety-related facial muscles, but should not involve non-facial muscles (such as arm muscles). Alternatively, the Abstraction view predicts that verbal rumination should be associated with an increase in emotion-related facial activity, without activity in speech-related muscles and non-facial muscles.</p>
<p>There is strong interest in the examination of physiological correlates of rumination as traditional assessment of rumination essentially consists of self-reported measures. The measurement of rumination as conceptualized by Nolen-Hoeksema (1991) was operationalized by the development of the Ruminative Response Scale (RRS), which is a subscale of the response style questionnaire (Nolen-Hoeksema &amp; Morrow, 1991). The RRS consists of 22 items that describe responses to dysphoric mood that are self-focused, symptom-focused, and focused on the causes and consequences of one’s mood. Based on this scale, Treynor, Gonzalez and Nolen-Hoeksema (2003) have offered a detailed description of rumina- tion styles and more recently, Watkins (2004, 2008) has further characterized different modes of rumination. The validity of these descriptions is nevertheless based on the hypothesis that individuals have direct and reliable access to their internal states. However, self- reports increase reconstruction biases (e.g., Brewer, 1986; Conway, 1990) and it is well known that participants have a very low level of awareness of the cognitive processes that underlie and modulate complex behaviors (Nisbett &amp; Wilson, 1977).</p>
<p>In order to overcome these difficulties, some authors have at- tempted to quantify state rumination and trait rumination more objectively, by recording physiological or neuroanatomical correlates of rumination (for a review, see Siegle &amp; Thayer, 2003). Peripheral physiological manifestations (e.g., pupil dilation, blood pressure, cardiac rhythm, cardiac variability) have been examined during induced or chronic rumination. Vickers and Vogeltanz-Holm (2003) have observed an increase in systolic blood pressure after rumination induction, suggesting the involvement of the autonomic nervous system in rumination. Moreover, galvanic skin response has shown to be increased after a rumination induction, in highly anxious women (Sigmon, Dorhofer, Rohan, &amp; Boulard, 2000). According to Siegle and Thayer (2003), disrupted autonomic activity could provide a reliable physiological correlate of rumination. In this line, Key, Campbell, Bacon, and Gerin (2008) have observed a diminution of the high- frequency component of heart rate variability (HF-HRV) after rumina- tion induction in people with a low tendency to ruminate (see also Woody, McGeary, &amp; Gibb, 2014). A consistent link between persevera- tive cognition and decreased HRV was also found in a meta-analysis conducted by Ottaviani et al. (2015). Based on these positive results and on suggestions that labial EMG activity may accompany inner speech and therefore rumination, our aim was to examine facial EMG as a potential correlate of rumination and HRV as an index to examine concurrent validity.</p>
<p>In addition to labial muscular activity, we also recorded forehead muscular activity (i.e., frontalis muscle) because of its implication in prototypical expression of sadness (e.g., Ekman, 2003; Kohler et al., 2004), reactions to unpleasant stimuli (Jäncke, Vogt, Musial, Lutz, &amp; Kalveram, 1996), and anxiety or negative emotional state (Conrad &amp; Roth, 2007)<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a>. Our hypothesis was that frontalis activity could be an accurate electromyographic correlate of induced rumination, as a negatively valenced mental process.</p>
<p>In this study, we were also interested in the effects of relaxation on induced rumination. Using a relaxation procedure targeted on muscles involved in speech production is a further way to test the reciprocity of the link between inner speech (verbal rumination) and orofacial muscle activity. If verbal rumination is a kind of action, then its production should be modulated in return by the effects of relaxation on speech effectors. This idea is supported by the results of (among others) Cefidekhanie, Savariaux, Sato and Schwartz (2014), who have observed substantial perturbations of inner speech production while participants had to realize forced movements of the articulators.</p>
<p>In summary, the current study aimed at evaluating the Motor Simulation view and the Abstraction view by using objective and subjective measures of verbal rumination. To test the involvement of the orofacial motor system in verbal rumination, we used two basic approaches. In the first approach, we induced verbal rumination and examined concurrent changes in facial muscle activity (Experiment 1). In the second approach, we examined whether orofacial relaxation would reduce verbal rumination levels (Experiment 2). More specifi- cally, in Experiment 1, we aimed to provide an objective assessment of verbal rumination using quantitative physiological measures. Thus, we used EMG recordings of muscle activity during rumination, focusing on the comparison of speech-related (i.e., two lip muscles − orbicularis oris superior and orbicularis oris inferior) and speech-unrelated (i.e., forehead −frontalis- and forearm − flexor carpi radialis) muscles. Under the Motor Simulation view, an increase in lip and forehead EMG activity should be observed after rumination induction, with no change in forearm EMG activity, associated with an increase in self-reported rumination. Alternatively, under the Abstraction view, an increase in forehead activity should be observed, associated with an increase in self-reported rumination, and no changes in either lip or forearm activity should be noted.</p>
<p>In Experiment 2, in order to assess the reciprocity of the rumination and orofacial motor activity relationship, we evaluated the effects of orofacial relaxation on rumination. More specifically, we compared three kinds of relaxation: i) Orofacial Relaxation (i.e., lip muscles), ii) Arm Relaxation (i.e., to differentiate effects specific to speech-related muscle relaxation) and iii) Story Relaxation (i.e., to differentiate effects specific to attentional distraction). If the Motor simulation view is correct, we predicted a larger decrease of lip and forehead muscle activity after an Orofacial Relaxation than after an Arm Relaxation (associated with a larger decrease in self-reported rumination), which should also be larger than after listening to a story. We also predicted that forearm activity should remain stable across the three conditions (i.e., should not decrease after relaxation). Alternatively, if the Abstraction view is correct, we predicted that none of the relaxation conditions should have an effect on lip or arm activity, because none of these should have increased after induction. However, we expected to observe a decrease in forehead activity and self-reported rumination after Orofacial or Arm relaxation, this decrease being larger than after listening to a Story. Importantly, we predicted that, under the Abstraction View no superiority of the Orofacial relaxation should be observed over the Arm relaxation.</p>
</div>
<div id="methods" class="section level2">
<h2><span class="header-section-number">3.2</span> Methods</h2>
<div id="participants" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Participants</h3>
<p>Because of the higher prevalence of rumination in women than in men (see Johnson &amp; Whisman, 2013; for a recent meta-analysis), we chose to include female participants only. Seventy-two female under- graduate students from Université Grenoble Alpes, native French speaking, participated in our study. One participant presenting aberrant data (probably due to inadequate sensor sticking) was removed from analyses. Final sample consisted of seventy-one undergraduate female students (Mage = 20.58, SDage = 4.99). They were recruited by e-mail diffusion lists and participated in the experiment for course credits. They did not know the goals of the study. The cover story presented the research as aiming at validating a new I.Q. test, more sensitive to personality profiles. Participants reported having no neurologic or psychiatric medical history, no language disorder, no hearing deficit, and taking no medication. Each participant gave written consent and this study has been approved by the local ethical committee (CERNI, N° 2015-03-03-61).</p>
</div>
<div id="material" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Material</h3>
<p>…</p>
<p>EMG signals were detected with TrignoTM Mini sensors (Delsys Inc.) at a sampling rate of 1926 samples/s with a band pass of 20 Hz (12 dB/ oct) to 450 Hz (24 dB/oct) and were amplified by a TrignoTM 16-channel wireless EMG system (Delsys Inc.). The sensors consisted of two 5 mm long, 1 mm wide parallel bars, spaced by 10 mm, which were attached to the skin using double-sided adhesive interfaces. The skin was cleaned by gently scrubbing it with 70% isopropynol alcohol. EMG signals were then synchronized using the PowerLab 16/35 (ADInstrument, PL3516). Raw data from the EMG sensors were then resampled at a rate of 1 kHz and stored in digital format using Labchart 8 software (ADInstrument, MLU60/8). As shown in Fig. 1, bipolar surface EMG recordings were obtained from two speech-related labial muscles: orbicularis oris superior (OOS) and orbicularis oris inferior (OOI), as well as from one non speech- related but negative-affect-related facial muscle: frontalis (FRO) and from one non-facial and non speech-related muscle: flexor carpi radialis (FCR) on the non-dominant forearm. The latter pair of electrodes was used to check whether the rumination induction would cause any muscle contraction, outside of the facial muscles. The same sensor layout was used for all participants. Asymmetrical movements of the face have been shown in speech and emotional expression. As reviewed in Everdell, Marsh, Yurick, Munhall, and Paré (2007), the dominant side of the face displays larger movements than the left during speech production, whereas the non-dominant side is more emotionally expressive. To optimise the capture of speech-related activity, the OOS and OOI sensors were therefore positioned on the dominant side of the body (i.e. the right side for right-handed participants). To optimise the capture of emotion-related activity, the FRO sensor was positioned on the non-dominant side. To minimise the presence of involuntary manual gestures during the recording, the FCR sensor was positioned on the non-dominant side. Each pair of electrodes was placed parallel with the direction of the muscle fibers, at a position distant from the innervation zones and the muscle tendon interface, following the recommendations of DeLuca (1997). The experiment was video-monitored using a Sony HDR-CX240E video camera to track any visible facial movements. A microphone was placed 20–30 cm away from the participant’s lips to record any faint vocal production during rumination. Stimuli were displayed with E-prime 2.0 (<a href="http://www" class="uri">http://www</a>. pstnet.com) on a 19-inch color monitor.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-1"></span>
<img src="assets/face_emg.jpg" alt="Facial muscles of interest. Two speech-related labial muscles: orbicularis oris superior (OOS) and orbicularis oris inferior (OOI); as well as one non speech-related but sadness-related facial muscle: frontalis (Front)." width="100%" />
<p class="caption">
Figure 2.1: Facial muscles of interest. Two speech-related labial muscles: orbicularis oris superior (OOS) and orbicularis oris inferior (OOI); as well as one non speech-related but sadness-related facial muscle: frontalis (Front).
</p>
</div>
</div>
<div id="procedure" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Procedure</h3>
<p>This study consisted of two parts. The first part was carried out a week before the EMG experiment and consisted in checking the inclusion criteria. We checked that participants did not exceed a threshold on a depressive symptoms scale. This was assessed using the French version of the Center for Epidemiologic Studies Depression scale (CES-D; Fuhrer &amp; Rouillon, 1989), which evaluates the level of depres- sive symptom in subclinical population. We also collected information about any potential speech, neurologic, neuromuscular or cardiac disorders and about academic curriculum. Finally, the tendency to ruminate (i.e., trait rumination) in daily life was evaluated using the French version of the Mini-CERTS (Cambridge-Exeter Repetitive Thought Scale; Douilliez, Philippot, Heeren, Watkins, &amp; Barnard, 2014). The second part included two EMG interdependent experiments related to Rumination Induction and Rumination Reduction by Muscle Relaxation. Specifically, Experiment 1 consisted of acquiring physiolo- gical EMG data during rest and induced rumination and Experiment 2 consisted of acquiring physiological EMG data after different kinds of relaxation (see below).</p>
<p>During both Experiment 1 and Experiment 2, momentary rumination was assessed using four different Visual Analogue Scales (VAS, the first two being adapted and translated to French from Huffziger, Ebner- Priemer, Koudela, Reinhard, &amp; Kuehner, 2012) rated from 0 to 100: i) “At this moment, I am thinking about my feelings” (referred to as VAS “Feelings”), ii) “At this moment, I am thinking about my problems” (referred to as VAS “Problems”), iii) “At this moment, I am brooding about negative things” (referred to as VAS “Brooding”) and iv) “At this moment, I am focused on myself” (referred to as VAS “Focused”).</p>
<div id="experiment-1-rumination-induction" class="section level4">
<h4><span class="header-section-number">3.2.3.1</span> Experiment 1: rumination induction</h4>
<p>Participants were seated in front of a computer screen in a comfortable and quiet room. EMG sensors were positioned as explained above (see Fig. 1). Before the rumination induction, each participant underwent a non-specific relaxation session (i.e., without targeting specific muscles) in order to minimize inter-individual initial thymic variability (approximate duration ∼330 s). Immediately after, partici- pants were instructed to remain silent and not to move for one minute to carry out EMG “baseline” measurements. Then, participants’ initial level of rumination was assessed using the four VASs.</p>
<p>Subsequently, participants were invited to perform a 15-min I.Q. test, which was presented on the computer screen facing them. They were instructed to correctly respond to three types of I.Q. questions (logical, mathematical and spatial-reasoning questions) in a very short time (30 s). Most of the questions were very difficult, if not impossible, to correctly answer in 30 s. We included ten different questions for each of the three types of IQ question: ten logical questions (e.g., finding the next number of a Fibonacci sequence), ten mathematical questions (e.g., “What is the result of the following calculus: (30/165) − (70/ 66)”) and ten spatial-reasoning questions (e.g., finding the next figure of a series). Forced-failure tasks have extensively been employed in the literature to induce a slightly negative mood, ideal for subsequent rumination induction (e.g., LeMoult &amp; Joormann, 2014; Van Randenborgh, Hüffmeier, LeMoult, &amp; Joormann, 2010).</p>
<p>After the I.Q. test, participants were invited to reflect upon the causes and consequences of their feelings, during five minutes (rumina- tion induction). This method is based on the induction paradigm developed by Nolen-Hoeksema and Morrow (1993). The classical paradigm uses a series of prompts. In order to avoid the potential confound in muscle activity induced by silent reading, we did not use the full paradigm. We simply summarised the series of prompts by one typical induction sentence. During this period, participants were asked to remain silent and not to move, while EMG recordings were carried out (i.e., EMG Post-induction measures). EMG signals of rumination were collected during the last minute of this period. Finally, partici- pants were instructed to self-report momentary rumination on the four VASs.</p>
</div>
<div id="experiment-2-rumination-reduction-by-relaxation" class="section level4">
<h4><span class="header-section-number">3.2.3.2</span> Experiment 2: rumination reduction by relaxation</h4>
<p>After Experiment 1, participants were randomly allocated to one of three groups. In the first group, participants listened to a pre-recorded relaxation session that was focused on orofacial speech-related muscles (“Orofacial Relaxation” condition). In the second group, relaxation was focused on the arm muscles (“Arm Relaxation” condition). In the third group, participants simply listened to a story, read by the same person, for an equivalent duration (“Story” condition, detailed content of the story can be found in the Supplementary Materials, in French). In summary, the first condition allowed us to evaluate the effects of targeted speech muscle relaxation on rumination. The second condition allowed evaluating the effects of a non-orofacial relaxation (i.e., speech- unrelated muscles) while the third condition allowed controlling for effects of attentional distraction during relaxation listening.</p>
<p>The speeches associated with the three conditions, relaxation sessions and story listening session, were delivered to the participants through loudspeakers. They were recorded by a professional sophrology therapist in an anechoic room at GIPSA-lab (Grenoble, France) and were approximately of the same duration (around 330 s).</p>
<p>After the relaxation/distraction session, participants were asked to remain silent and not to move during one minute, during which EMG measurements were collected (EMG Post-relaxation measures). Finally, participants were instructed to self-report rumination on the four VASs.</p>
</div>
</div>
<div id="data-processing-and-analysis" class="section level3">
<h3><span class="header-section-number">3.2.4</span> Data processing and analysis</h3>
<div id="emg-data-processing" class="section level4">
<h4><span class="header-section-number">3.2.4.1</span> EMG data processing</h4>
<p>EMG signal pre-processing was carried out using Labchart 8. The EMG data were high-pass filtered using a Finite Impulse Response (FIR) filter at a cut-off of 20 Hz, using the Kaiser window method with β = 6. Then, output of this first filter was to a low-pass filtered at a cut-off of 450 Hz (with the same parameters), in order to focus on the 20–450 Hz frequency band, following current recommendations for facial EMG studies (DeLuca, 1997; DeLuca, Gilmore, Kuznetsov, &amp; Roy, 2010; Van Boxtel, 2001).</p>
<p>Although we specifically asked participants to remain silent and not to move during EMG data collection, tiny facial movements (such as biting one’s lips) or vocal productions sometimes occurred. Periods with such facial movement or vocal production were excluded from the analysis. To do this, visual inspection of audio, video, and EMG signal was performed. Specifically, for the EMG signals, we compared two methods of signal selection. The first one consisted of setting a threshold on the absolute value of the EMG signal and portions of signals above this threshold were removed. This threshold was empiri- cally chosen using visual inspection of a few samples and set to the mean EMG value plus 6 SDs. The second method consisted of manually removing periods of time that included visually obvious bursts of EMG activity, corresponding to overt contraction (as in Rapin et al., 2013). Based on samples from a few participants, the comparisons between these two methods showed that the automatic threshold method was somewhat less sensitive to overt movements. Therefore, the second method was used, as it was more conservative and less prone to leave data related to irrelevant overt movements.</p>
<p>After pre-processing, EMG data were exported from Labchart soft- ware to Matlab r2014a (Version 8.3.0.532, www.mathworks.fr). For each EMG signal, mean values were computed under Matlab, using 200 ms sliding windows. The average of these mean values were calculated for each recording session (baseline, after induction and after relaxation/induction). This provided a score for each muscle of interest (OOS, OOI, FCR, FRO) in each Session (Baseline, Post- Induction, Post-Relaxation) for each participant<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a>.</p>
</div>
<div id="statistical-analyses" class="section level4">
<h4><span class="header-section-number">3.2.4.2</span> Statistical analyses</h4>
<p>Absolute EMG values are not meaningful as muscle activation is never null, even in resting conditions, due in part to physiological noise (Tassinary, Cacioppo, &amp; Vanman, 2007). In addition, there are inter- individual variations in the amount of EMG activity in the baseline. To normalise for baseline activity across participants, we used a differential measure and expressed EMG amplitude as a percentage of baseline level (Experiment 1) or of post-induction level (Experiment 2).</p>
<p>To model EMG amplitude variations in response to the rumination induction (Experiment 1) and relaxation (Experiment 2), we used a bayesian multivariate regression model with the natural logarithm of the EMG amplitude (expressed in% of baseline level) as an outcome, in an intercept-only model (in Experiment 1), and using Condition (Orofacial, Arm or Story) as a categorical predictor in Experiment 2. We used the same strategy (two multivariate models) to analyse VAS scores (expressed in relative changes) along the two experiments.</p>
<p>These analyses were conducted using RStudio (RStudio Team, 2015) and the brms package (Bürkner, in press), an R implementation of Bayesian multilevel models that employs the probabilistic program- ming language, Stan (Carpenter et al., 2016). Stan implements gradient- based Markov Chain Monte Carlo (MCMC) algorithms (e.g., Hamilto- nian Monte-Carlo), which allow yielding posterior distributions that are straightforward to use for interval estimation around all parameters. Two MCMC simulations (or “chains”) were run for each model, including 100,000 iterations, a warmup of 10,000 iterations, and a thinning interval of 10. Posterior convergence was assessed examining autocorrelation and trace plots, as well as the Gelman-Rubin statistic. Fixed effects were estimated via the posterior mean and 95% highest density intervals (HDIs), where an HDI interval is the Bayesian analogue of a classical confidence interval<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a>.</p>
<p>This strategy allowed us to examine posterior probability distribution on each parameter of interest (i.e., effects of session and condition on each response variable). When applicable, we also report evidence ratios (ERs), computed using the hypothesis function of the brms package (Bürkner, in press). These evidence ratios are simply the posterior probability under a hypothesis against its alternative (Bürkner, in press). We also report summary statistics (mean and HDI) of Cohen’s d effect sizes, computed from the posterior samples.</p>
</div>
</div>
</div>
<div id="results" class="section level2">
<h2><span class="header-section-number">3.3</span> Results</h2>
<div id="experiment-1-rumination-induction-1" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Experiment 1: rumination induction</h3>
<p>The evolution of VAS scores (for the four assessed scales: Feelings, Problems, Brooding, and Focused) and EMG (for the four muscles: OOS, OOI, FCR and FRO) activity from baseline to post-induction were examined.</p>
<div id="self-reported-rumination-measures-vas-scores" class="section level4">
<h4><span class="header-section-number">3.3.1.1</span> Self-reported rumination measures: VAS scores</h4>
<p>Results for VAS relative changes based on the multivariate models described earlier are shown in the right panel of Fig. 2. Thereafter, <span class="math inline">\(\alpha\)</span> represents the mean of the posterior distribution of the intercept. Raw pre- and post-induction scores are provided in Supplementary Materials.</p>
<p>Mean VAS score on the Feelings scale was slightly lower after induction (<span class="math inline">\(\alpha\)</span> = −5.55, 95% HDI [-10.89, −0.24], d = −0.23, 95% HDI [-0.46, −0.01]), while Problems score was slightly higher (<span class="math inline">\(\alpha\)</span> = 3.99, 95% HDI [-2.04, 9.83], d = 0.15, 95% HDI [-0.08, 0.37]). We observed a strong increase of the score on the Brooding scale (<span class="math inline">\(\alpha\)</span> = 14.45, 95% HDI [8.07, 20.72], d = 0.50, 95% HDI [0.26, 0.74]), and a strong decrease on the Focused scale (<span class="math inline">\(\alpha\)</span> = −11.63, 95% HDI [-17, −6.07], d = −0.48, 95% HDI [-0.72, −0.24]). As we examined the fit of the intercept-only model, these estimates represent the posterior mean for each muscle.</p>
<p>In the following, we report the mean (indicated by the Greek symbol ρ) and the 95% HDI of the posterior distribution on the correlation coefficient (<span class="math inline">\(\rho\)</span>). Examination of the correlation matrix estimated by the multivariate model revealed no apparent correlation neither between Feelings and Problems scales (<span class="math inline">\(\rho\)</span> = −0.01, 95% HDI [-0.23, 0.22]), nor between Feelings and Brooding (<span class="math inline">\(\rho\)</span> = 0.08, 95% HDI [-0.15, 0.30]). However, we observed a strong positive correlation between Problems and Brooding VASs (<span class="math inline">\(\rho\)</span> = 0.64, 95% HDI [.49, 0.76]), a positive correlation between Feelings and Focused (<span class="math inline">\(\rho\)</span> = 0.30, 95% HDI [.08, 0.50]), and a negative correlation between Problems and Focused (<span class="math inline">\(\rho\)</span> = −0.30, 95% HDI [-0.49, −0.08]), as well as between Brooding and Focused (<span class="math inline">\(\rho\)</span> = −0.18, 95% HDI [-0.39, 0.05]).</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="assets/emg_fig1.png" alt="Posterior mean (white dots) and 95\% credible intervals for the EMG amplitude (expressed in percentage of baseline level, left panel), and the VAS score (expressed in relative change from baseline, right panel). N = 71 (for each muscle and each VAS). Dashed line represents the null value (i.e., 100)." width="100%" />
<p class="caption">
Figure 2.2: Posterior mean (white dots) and 95% credible intervals for the EMG amplitude (expressed in percentage of baseline level, left panel), and the VAS score (expressed in relative change from baseline, right panel). N = 71 (for each muscle and each VAS). Dashed line represents the null value (i.e., 100).
</p>
</div>
</div>
<div id="emg" class="section level4">
<h4><span class="header-section-number">3.3.1.2</span> EMG</h4>
<p>Results for EMG data based on the multivariate model described earlier are shown in the left panel of Figure 2. Summary statistics were computed on posterior samples transformed back from log scale.</p>
<p>Mean EMG amplitude for OOS was higher after induction (<span class="math inline">\(\alpha\)</span> = 138.57, 95% HDI [124.43, 151.71], d = 0.66, 95% HDI [0.49, 0.84]) as well as for OOI (<span class="math inline">\(\alpha\)</span> = 163.89, 95% HDI [145.24, 184.14], d = 0.77, 95% HDI [0.61, 0.94]), and FRO (<span class="math inline">\(\alpha\)</span> = 197.55, 95% HDI [166.59, 228.42], d = 0.74, 95% HDI [0.59, 0.89]). Effects on the FCR were approximately null (<span class="math inline">\(\alpha\)</span> = 100.10, 95% HDI [97.48, 102.76], d = 0.01, 95% HDI [-0.24, 0.23]).</p>
<p>Examination of the correlation matrix estimated by the bayesian multivariate model revealed a positive correlation between OOS and OOI EMG amplitudes (<span class="math inline">\(\rho\)</span> = 0.44, 95% HDI [.24, 0.61]), while no apparent correlations neither between OOS and FCR (<span class="math inline">\(\rho\)</span> = 0.09, 95% HDI [-0.14, 0.31]), OOS and FRO (<span class="math inline">\(\rho\)</span> = 0.12, 95% HDI [-0.11, 0.35]), OOI and FCR (<span class="math inline">\(\rho\)</span> = 0.02, 95% HDI [-0.21, 0.25]), FRO and FCR (<span class="math inline">\(\rho\)</span> = −0.06, 95% HDI [-0.28, 0.17]), nor OOI and FRO (<span class="math inline">\(\rho\)</span> = 0.07, 95% HDI [-0.16, 0.29]). Scatterplots, marginal posterior distributions and posterior distributions on correlation coefficients are available in Supplementary Materials (Supplementary materials, data, reproducible code and figures are available at: <a href="https://osf.io/882te/" class="uri">https://osf.io/882te/</a>).</p>
<p>In order to check whether the propensity to ruminate could predict the effects of the rumination induction on EMG amplitude, we compared the multivariate model described above, with a similar model but with the score on the abstract dimension of the Mini- CERTS as an additional predictor. We compared these models using the widely applicable information criterion (WAIC; Watanabe, 2010), via the WAIC function of the brms package (Bürkner, in press). Results showed that the intercept-only model had a lower WAIC (WAIC = 177.39) than the more complex model (WAIC = 182.01), indicating that there is no predictive benefit in adding the Mini-CERTS score as a predictor.</p>
</div>
<div id="correlations-between-emg-amplitudes-and-vas-scores" class="section level4">
<h4><span class="header-section-number">3.3.1.3</span> Correlations between EMG amplitudes and VAS scores</h4>
<p>Correlations between EMG amplitudes and VAS scores were exam- ined using the BayesianFirstAid package (Bååth, 2013), using 15,000 iterations for each correlation coefficient. Both estimated correlation coefficients (<span class="math inline">\(\rho\)</span>s) and 95% HDIs are reported in Table 1.</p>
<!-- insert table 1 here -->
</div>
</div>
<div id="experiment-2-rumination-reduction-by-relaxation-1" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Experiment 2: rumination reduction by relaxation</h3>
<p>In the second experiment, we aimed at comparing the evolution in EMG activity and VAS scores from post-induction to post-relaxation in three different conditions: Orofacial relaxation, Arm relaxation, and listening to a Story.</p>
<div id="self-reported-rumination-measures-vas-scores-1" class="section level4">
<h4><span class="header-section-number">3.3.2.1</span> Self-reported rumination measures: VAS scores</h4>
<p>Posterior means and 95% HDIs of the VAS scores in each condition of experiment 2 are represented in Fig. 3 and Table 1 (Table 2).</p>
<p>In order to compare the effects of the two kind of relaxation on the VAS scores, we then used the hypothesis function of the brms package that allows deriving evidence ratios (ER). These evidence ratios are simply the posterior probability under a hypothesis (e.g., the hypothesis that the Orofacial relaxation session would be more effective in reducing self-reported rumination than the Arm relaxation session) against its alternative (Bürkner, in press).</p>
<p>Since the Problems and the Brooding scales seemed to be sensitive markers of rumination (as their scores increased after induction in Experiment 1), our analyses were focused on these two scales.</p>
<p>Concerning the Problems VAS, the decrease observed in the Orofacial condition was more pronounced than in the Arm condition (Est = −11.06, SE = 6.35, ER10 = 22.65), and slightly more pro- nounced compared to the Story condition (Est = −6.05, SE = 6.31, ER10 = 4.98). The observed on the Brooding VAS score in the Orofacial condition was larger than in the Arm condition (Est = −9.98, SE = 6.07, ER10 = 18.85), and slightly more important compared to the Story condition (Est = −5.23, SE = 6.01, ER10 = 4.27).</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-3"></span>
<img src="assets/emg_fig2.png" alt="Posterior mean and 95\% credible intervals for the VAS score (expressed in relative change from post-induction level)." width="100%" />
<p class="caption">
Figure 2.3: Posterior mean and 95% credible intervals for the VAS score (expressed in relative change from post-induction level).
</p>
</div>
<!-- insert table 2 here -->
</div>
<div id="emg-1" class="section level4">
<h4><span class="header-section-number">3.3.2.2</span> EMG</h4>
<p>Posterior means and 95% HDIs of the EMG amplitude in each condition of experiment 2 are represented in Figure XX and reported in Table XX.</p>
<p>We used the same strategy as before to compare the effects of the two kinds of relaxation on the EMG amplitudes.</p>
<p>Concerning the OOS, the observed decrease in the Orofacial condition was more pronounced than in the Arm condition (Est = −0.34, SE = 0.14, ER10 = 140.73), as well as concerning the OOI (Est = −0.35, SE = 0.19, ER10 = 29.46), while we observed no noticeable differences between the two kinds of relaxation concerning the EMG amplitude of the FRO (Est = -0.04, SE = 0.14, ER10 = 1.53).</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-4"></span>
<img src="assets/emg_fig3.png" alt="Posterior mean and 95\% credible intervals for the VAS score (expressed in relative change from post-induction level)." width="100%" />
<p class="caption">
Figure 3.1: Posterior mean and 95% credible intervals for the VAS score (expressed in relative change from post-induction level).
</p>
</div>
<!-- insert table 2 here -->
</div>
</div>
</div>
<div id="discussion" class="section level2">
<h2><span class="header-section-number">3.4</span> Discussion</h2>
<div id="experiment-1" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Experiment 1</h3>
<p>In the first experiment, we examined electromyographic correlates of induced rumination in healthy individuals. According to the Motor Simulation view, we predicted an increase in the activity of all facial muscles after the rumination induction, associated with an increase in self-reported rumination. Alternatively, the Abstraction view predicted an increase in self-reported rumination associated with an increase in forehead activity with no changes in either lip or forearm activity.</p>
<p>To test the predictions of these two theoretical views, we compared EMG measures and VAS scores after induction to their values before induction. EMG activity was examined in four muscles: OOS and OOI, two muscles involved in speech production, FRO, a facial negative- affect-related but not speech-related muscle, and FCR, a non-facial control muscle on the non-dominant forearm.</p>
<p>As predicted by the Motor Simulation view, we observed an increase in the activity of the two speech-related muscles (OOS &amp; OOI) as well as in the negative-affect-related muscle (FRO) and no change in FCR activity. The increase in facial EMG together with the increase in the subjective reports of rumination suggests that facial EMG increase is a correlate of verbal rumination. As supported by several studies results, the forehead muscle activity has been associated with unpleasant emotions (Jäncke et al., 1996) or anxiety (Conrad &amp; Roth, 2007). The increase in FRO activity observed here is consistent with the increase in negative emotions induced by our negatively valenced induction procedure. Orbicularis oris lip muscles are associated with speech production. The increase in lip activity observed here suggests that the speech motor system was involved during the ruminative phase. The fact that the FCR remained stable after rumination induction suggests that the observed facial activity increase was not due to general body tension induced by a negative mental state. These facial EMG results therefore support the hypothesis that rumination is an instance of articulatory-specified inner speech.</p>
<p>After the rumination induction, a larger increase in OOI activity was observed compared to the increase in OOS activity. This finding is consistent with previous findings of higher EMG amplitude in the lower lip during speech and inner speech (e.g., Barlow &amp; Netsell, 1986; Regalo et al., 2005; Sokolov, 1972) or auditory verbal hallucinations (Rapin et al., 2013). Rapin et al. (2013) have explained the difference between the activities of the two lip muscles by muscle anatomy. The proximity of the OOI muscle with other speech muscles (such as the depressor angular muscle or the mentalis) could increase the surface EMG signal captured on the lower lip (OOI), as compared to the upper lip (OOS) during speech. An even larger increase in FRO activity was observed compared to the increase in lip muscle activity. As EMG amplitude is known to vary with muscle length (Babault, Pousson, Michaut, &amp; Van Hoecke, 2003), the greater increase in frontalis activity could be explained by its anatomical properties.</p>
<p>However, although a functional distinction can be drawn between the forehead and the lip muscles, one should acknowledge the fact that these two sets of muscles can be commonly activated during some behaviours. For instance, Van Boxtel &amp; Jessurun (1993) have shown that orbicularis oris inferior and frontalis were both activated during a two-choice serial reaction task in which nonverbal auditory or visual signals were presented. Moreover, there was a gradual increase in EMG activity in these muscles during the task, either when the task was prolonged or when the task was made more difficult. They interpreted this increase in EMG activity as associated with a growing compensa- tory effort to keep performance at an adequate level. An alternative interpretation is that the increase in task difficulty was dealt with by inner verbalization. Covertly rehearsing the instructions or covertly qualifying the stimuli might have helped the participants to perform adequately. Therefore, the increase in orbicularis oris activity might have been related to an increase in covert verbalization, whereas the increase in frontalis activity might have been related to increased anxiety or tension. The fact that the EMG increase was muscle specific, and that some facial muscles (orbicularis oculi, zygomaticus major, temporalis) did not show an increase in activity unless the task became too difficult, supports this interpretation. It cannot be ruled out, however, that orbicularis oris activity may in some cases be related to mental effort without mental verbalisation. Nevertheless, although the IQ test itself was designed to induce mental effort, no cognitively demanding task was asked to the participant during the period of EMG recording (i.e., approximately four minutes after the end of the test). Although we cannot absolutely exclude that rumination in itself could require cognitive effort, it seems unlikely that mental effort was the main factor of variation.</p>
<p>Scores on the VAS need to be discussed in further detail. We examined which VAS scales were most suitable to capture changes in state rumination to allow focused analyses. Due to the “pre-baseline” relaxation session, during which participants were asked to concentrate on their body and breathing cycles, participants reported a high level of attentional self-focus at baseline (“Feelings” and “Focused” VAS). Because of the high level of self-focused attention at baseline, it is likely that the scores on the “Feelings” and “Focused” VAS did not show the expected increase after rumination induction (ceiling effect). The scores on the scales “Problems” and “Brooding”, which are more representative of maladaptive rumination, did increase after our rumination induction paradigm, however. Interestingly, the “Brooding” VAS corresponded to a larger increase and seemed to be more sensitive to rumination induction than the “Problems” VAS. Given this greater sensibility and the strong positive correlation between the “Brooding” and the “Problems” VAS, it thus make sense to consider the “Brooding” VAS as a better estimate of ruminative state, at least within our paradigm. We will therefore only use this scale to assess rumination in the following.</p>
<p>The fact that we did not observe any association between the propensity to ruminate (as measured by the Mini-CERTS questionnaire) and the effects of the induction is consistent with the results of Rood, Roelofs, Bögels, and Arntz (2012) who found that the level of trait rumination did not moderate the effects of a rumination induction.</p>
</div>
<div id="experiment-2" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Experiment 2</h3>
<p>In the second experiment, we studied the effects of two muscle- specific relaxation sessions: Orofacial relaxation and Arm relaxation. We compared their effects to a third control condition (Story), which did not involve the deliberate relaxation of any specific muscle. Our predictions were that a decrease in facial EMG activity should be observed in each condition. If the Motor Simulation view is correct, we expected a larger decrease in the activity of all facial muscles in the “Orofacial relaxation” condition than in the “Arm relaxation” condition, associated with a larger decrease in self-reported rumination. Additionally, we expected a more pronounced decrease in the two relaxation conditions (orofacial and arm relaxation conditions) than in the control (“Story”) condition. We also expected no difference between relaxation conditions regarding the change in the forearm muscle activity.</p>
<p>The data indicated a decrease in self-reported rumination (“Brooding” VAS) in each condition. The “Orofacial” relaxation condi- tion elicited a slightly larger decrease than the “Arm relaxation” or the “Story” condition. However, there was extensive individual variation in response to these conditions. As concerns EMG results, we observed a decrease in OOS and OOI activities in all three conditions but this decrease was more pronounced in the orofacial condition than in the other two conditions. The frontalis activity did not show the same pattern. A similar FRO activity decrease was observed in both the orofacial and the non-orofacial relaxation conditions. Therefore, in Experiment 2, the lip muscles and the forehead muscle follow differ- ential evolutions. A dissociation was observed: whereas both orofacial and arm relaxations resulted in a decrease in forehead activity, only orofacial relaxation was successful at reducing lip activity.</p>
<p>Considering both VAS results and the dissociation in EMG patterns, several interpretations are possible. The first interpretation is that verbal production associated with rumination was more reduced by orofacial muscular relaxation than by non-orofacial relaxation. This interpretation is consistent with the fact that the “Brooding” VAS was slightly more decreased in this condition compared to the other two. The larger decrease in OOS and OOI amplitude after orofacial relaxa- tion would thus reflect this reduction in verbal production, as hypothesised by the Motor Simulation view. The fact that FRO activity displayed a similar decrease in both orofacial and non-orofacial relaxation conditions could suggest that any means of body relaxation (be it orofacial or not) is appropriate to reduce negative affect and can therefore reduce forehead contraction. This suggests that the FRO activity increase presumably reflected negative affect and tension (such as observed in EMG studies on generalised anxiety disorder patients, see Conrad &amp; Roth, 2007 for a review).</p>
<p>Alternatively, one could also argue that the larger decrease in lip muscle activity after orofacial relaxation finds a more trivial explana- tion in that it seems obvious to expect that orofacial relaxation will be more efficient to reduce lip muscle contraction than non-orofacial relaxation. Thus, the different impacts of the two relaxation sessions on the lip muscles would not be related to reduced rumination per se but simply to a more anatomically targeted relaxation. However, several observations argue against such an interpretation. The larger decrease in the “Brooding” VAS in the orofacial relaxation condition compared with the other conditions suggests that the reduction in lip muscle activity is indeed related to the reduction in rumination. Moreover, an interpretation solely based on anatomical links does not explain why FRO activity displayed the same amount of reduction in both relaxation sessions. If reduction in muscle activity was merely related to the effect of facial muscle relaxation, then the decrease in FRO activity should have also been higher in the orofacial relaxation condition than in the other relaxation condition, which was not the case. Therefore the dissociation between forehead and lip patterns of activity, together with the differential effects of the two types of relaxation on subjective rumination reports strongly suggest that different processes underlie the activity of these two sets of muscles. We therefore consider that the first interpretation is more plausible: frontalis activity seems related to overall facial tension due to negative affect whereas lip activity seems to be related to the specific involvement of the speech musculature in rumination. These results thus seem to confirm the interpretation of decreased OOS and OOI activities in the orofacial relaxation condition as markers of rumination reduction.</p>
<p>Interestingly, we observed no changes of forearm EMG activity in any of the three conditions of experiment 2. The fact that the relaxation session focused on the forearm was not associated with a decrease in FCR activity has a simple explanation: FCR activity had not increased after rumination induction and had remained at floor level. The forearm was thus already relaxed and the Arm relaxation session did not modify FCR activity. Another interesting conclusion related to this absence of modification of forearm activity is that relaxation does not spuriously decrease muscle activity below its resting level. One possible interpretation of the increase in lip EMG after rumination induction could have been that baseline relaxation artificially decreased baseline activity under its resting level. The facts that forearm activity did not decrease after arm-focused relaxation contradicts this interpretation.</p>
<p>Finally, the “Story” condition was also associated with a decrease in OOI and FRO activities. This could mean that listening to a story reduced rumination to the same extent as relaxation did. However, the discrepancy observed in “Focused” VAS between the two relaxation conditions on the one hand and the control condition on the other hand, suggests that the EMG decrease observed in the “Story” condition might be attributable to a different cause than that observed in the two relaxation conditions. Listening to a story could help reducing rumina- tion by shifting attention away from ruminative thoughts. Relaxation sessions could help reducing rumination by shifting attention to the body in a beneficial way.</p>
</div>
<div id="general-discussion" class="section level3">
<h3><span class="header-section-number">3.4.3</span> General discussion</h3>
<p>We set out two experiments to examine whether rumination involves motor simulation or is better described as linguistically abstract and articulatory impoverished. We used labial, facial, and arm EMG measures to assess potential articulatory correlates of rumination. The patterns of results of our study seem to be in favour of the motor nature of verbal rumination. In Experiment 1, rumination induction was associated with a higher score on the scale “I am brooding about negative things” which is representative of abstract- analytical rumination, considered as verbal rumination. This maladap- tive rumination state was associated with an increase in the activity of two speech-related muscles, without modification of the arm muscle activity, which indicates that rumination involves activity in speech articulatory muscles, specifically. The concurrent increase in forehead muscle activity could be explained by an increase in negative emotions induced by our negatively valenced induction procedure. The results of Experiment 1 therefore show the involvement of the speech muscula- ture during rumination. This is in line with the Motor simulation view, according to which inner speech is fully specified at the articulatory level, not just the lexical level.</p>
<p>In Experiment 2, guided relaxation resulted in a decrease in speech muscle activity. In the lip muscles, the activity decrease was stronger after orofacial relaxation than after arm-focused relaxation. In the forehead muscle, however the effect was the same for both types of relaxation. This decrease in speech muscle activity was associated with a decrease in self-reports of rumination and was most pronounced after orofacial relaxation. These findings suggest that a reduction in speech muscle activity could hinder articulatory simulation and thus limit inner speech production and therefore reduce rumination. This inter- pretation is consistent with the Motor Simulation view of inner speech. Brooding-type rumination was also diminished after the arm-focused relaxation as well as after listening to a story, although less than in the orofacial relaxation. This suggests that general relaxation or distraction are also likely to reduce negative rumination. To summarize, experi- ments 1 and 2 are consistent with the Motor Simulation view of inner speech, according to which speech muscle activity is inherent to inner speech production. Experiment 1 shows the involvement of the lip musculature during brooding-type rumination. Experiment 2 suggests that brooding-type rumination could be reduced by blocking or relaxing speech muscles.</p>
<p>These data support the utility of labial EMG as a tool to objectively assess inner speech in a variety of normal and pathological forms. We suggest that this method could be used as a complement to self-report measures, in order to overcome limitation of these measures.</p>
<p>Our results should be interpreted with some limitations in mind. Firstly, our sample consisted exclusively of women. Although this methodological choice makes sense considering the more frequent occurrence of rumination in women, further studies should be con- ducted to ascertain that our results may generalize to men. Secondly, in Experiment 1, no between-subject control condition was used to compare with the group of participants who underwent rumination induction. Thus, we cannot rule out that other processes occurred between baseline and rumination induction, influencing responding. Thirdly, substantial inter-individual differences were observed concern- ing the size of the effect of rumination induction on facial EMG activity. The results of Jäncke (Jäncke, 1996; Jäncke et al., 1996) can shed light on this last result. Jäncke used a similar procedure (i.e., negative mood induction using a false I.Q. test and facial EMG measurements to assess emotions), except that the experimenter was not in the room while participants performed the test and acknowledged their results. The experimenter then came back to the room and analysed participants’ behaviours. Jäncke observed an increase in facial muscular activity (assessed when participants were reading their results) only in partici- pants who were prone to express their distress when the experimenter came back, while more introverted participants did not show any increased facial activity when reading their results. Jäncke interpreted these results in the framework of an ecological theory of facial expression, suggesting that facial expressions would not only be guided by underlying emotions, but also by their communicative properties. Considering these results, it seems likely that the proneness of participants to communicate their emotions could have mediated effects of the induction on their facial EMG activity. This could partially explain the observed inter-individual variability in facial EMG activity associated with rumination. Moreover, even though rumination is a predominantly verbal process, one cannot exclude that some of our participants experienced rumination in another modality (e.g., ima- gery-based rumination), which would explain their lower than average lip activity.</p>
<p>Thus, a logical next step is to examine qualitative factors that mediate the link between rumination and facial muscular activity. These factors (among others) could be proneness to communicate emotion or proneness to verbalize affects. Additionally, recent studies suggest a link between verbal aptitudes and propensity to ruminate. Uttl, Morin and Hamper (2011) have observed a weak but consistent correlation between the tendency to ruminate and scores on a verbal intelligence test. Penney, Miedema and Mazmanian (2015) have observed that verbal intelligence constitutes a unique predictor of rumination severity in chronic anxious patients. To our knowledge, the link between verbal intelligence and induced rumination has never been studied. It would be interesting to examine whether the effects of a rumination induction could be mediated by verbal intelligence, and to what extent this could influence related facial EMG activity.</p>
<p>In conclusion, this study provides new evidence for the facial embodiment of rumination, considered as a particular instance of inner speech. Even if more data are needed to confirm these preliminary conclusions, our results seem to support the Motor Simulation view of inner speech production, manifested as verbal rumination. In addition, facial EMG activity provides a useful means to objectively quantify the presence of verbal rumination.</p>
</div>
</div>
<div id="acknowledgements-1" class="section level2">
<h2><span class="header-section-number">3.5</span> Acknowledgements</h2>
<p>This project was funded by the ANR project INNERSPEECH [grant number ANR-13-BSH2-0003-01]. The first author of the manuscript is funded by a fellowship from Université Grenoble Alpes and a grant from the Pôle Grenoble Cognition. We thank Nathalie Vallet for recording the relaxation and distraction sessions. We thank our colleagues from GIPSA-lab: Marion Dohen for her help in the recording of the audio stimuli in the anechoic room at GIPSA-lab, as well as Christophe Savariaux and Coriandre Vilain for their advice in the audio setup associated with the EMG measures. We are also grateful to Rafael Laboissière and Adeline Leclercq Samson for their advice concerning data analysis. We sincerely thank two anonymous reviewers for their critical reading of our manuscript and their many insightful comments and suggestions. Access to the facility of the MSH-Alpes SCREEN platform for conducting research is gratefully acknowledged.</p>
</div>
<div id="supplementary-data" class="section level2">
<h2><span class="header-section-number">3.6</span> Supplementary data</h2>
<p>Supplementary data associated with this article can be found, in the online version, at <a href="http://dx.doi.org/10.1016/j.biopsycho.2017.04.013" class="uri">http://dx.doi.org/10.1016/j.biopsycho.2017.04.013</a>.</p>


</div>
</div>
<div id="dissociating-facial-electromyographic-correlates-of-visual-and-verbal-induced-rumination" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Dissociating facial electromyographic correlates of visual and verbal induced rumination</h1>
<p>Summary of the research…<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a></p>


</div>
<div id="muscle-specific-electromyographic-correlates-of-inner-speech-production" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Muscle-specific electromyographic correlates of inner speech production</h1>
<p>Summary of the research…<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a></p>


</div>
<div id="articulatory-suppression-effects-on-induced-rumination" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Articulatory suppression effects on induced rumination</h1>
<p>Summary of the research…<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a></p>


</div>
<div id="refining-the-involvement-of-the-speech-motor-system-during-rumination-a-dual-task-investigation" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Refining the involvement of the speech motor system during rumination: a dual-task investigation</h1>
<p>Summary of the research…<a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a></p>


</div>



<div id="discussion-and-perspectives" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Discussion and perspectives</h1>
<div id="summary-of-the-results" class="section level2">
<h2><span class="header-section-number">8.1</span> Summary of the results</h2>
<p>…</p>
</div>
<div id="limitations-and-ways-forward" class="section level2">
<h2><span class="header-section-number">8.2</span> Limitations and ways forward</h2>
<p>…</p>
</div>
<div id="conclusions" class="section level2">
<h2><span class="header-section-number">8.3</span> Conclusions</h2>
<p>…</p>

</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<!-- This manually sets the header for this unnumbered chapter.
\markboth{References}{References}

\singlespacing
\sloppy
-->
<p>  </p>

<div id="refs" class="references">
<div id="ref-agnati_possible_2012">
<p>Agnati, Luigi F., Peter Barlow, Roberta Ghidoni, Dasiel O. Borroto-Escuela, Diego Guidolin, and Kjell Fuxe. 2012. “Possible Genetic and Epigenetic Links Between Human Inner Speech, Schizophrenia and Altruism.” <em>Brain Research</em> 1476 (October): 38–57. doi:<a href="https://doi.org/10.1016/j.brainres.2012.02.074">10.1016/j.brainres.2012.02.074</a>.</p>
</div>
<div id="ref-binet_psychologie_1886">
<p>Binet, Alfred. 1886. <em>La Psychologie Du Raisonnement. Recherches Expérimentales Par L’hypnotisme</em>. Alcan, Paris.</p>
</div>
<div id="ref-bonnet_mental_1997">
<p>Bonnet, M, J Decety, Marc Jeannerod, and J Requin. 1997. “Mental Simulation of an Action Modulates the Excitability of Spinal Reflex Pathways in Man.” <em>Cognitive Brain Research</em> 5 (3): 221–28. doi:<a href="https://doi.org/10.1016/S0926-6410(96)00072-9">10.1016/S0926-6410(96)00072-9</a>.</p>
</div>
<div id="ref-cohen_motor_1986">
<p>Cohen, B. H. 1986. “The Motor Theory of Voluntary Thinking.” In <em>Consciousness and Self-Regulation</em>, edited by R. J. Davidson, G. E. Schartz, and D. Shapiro. Springer, Boston, MA.</p>
</div>
<div id="ref-de_luca_use_1997">
<p>De Luca, Carlo J. 1997. “The Use of Surface Electromyography in Biomechanics.” <em>Journal of Applied Biomechanics</em> 13 (2): 135–63. doi:<a href="https://doi.org/10.1123/jab.13.2.135">10.1123/jab.13.2.135</a>.</p>
</div>
<div id="ref-fadiga_corticospinal_1999">
<p>Fadiga, Luciano, Giovanni Buccino, Laila Craighero, Leonardo Fogassi, Vittorio Gallese, and Giovanni Pavesi. 1999. “Corticospinal Excitability Is Specifically Modulated by Motor Imagery a Magnetic Stimulation Study.” <em>Neuropsychologia</em> 37 (2): 147–58. doi:<a href="https://doi.org/10.1016/s0028-3932(98)00089-x">10.1016/s0028-3932(98)00089-x</a>.</p>
</div>
<div id="ref-gentsch_towards_2016">
<p>Gentsch, Antje, Arne Weber, Matthis Synofzik, Gottfried Vosgerau, and Simone Schütz-Bosbach. 2016. “Towards a Common Framework of Grounded Action Cognition: Relating Motor Control, Perception and Cognition.” <em>Cognition</em> 146 (January): 81–89. doi:<a href="https://doi.org/10.1016/j.cognition.2015.09.010">10.1016/j.cognition.2015.09.010</a>.</p>
</div>
<div id="ref-glover_motor-cognitive_2017">
<p>Glover, Scott, and Marek Baran. 2017. “The Motor-Cognitive Model of Motor Imagery: Evidence from Timing Errors in Simulated Reaching and Grasping.” <em>Journal of Experimental Psychology: Human Perception and Performance</em> 43 (7): 1359–75. doi:<a href="https://doi.org/10.1037/xhp0000389">10.1037/xhp0000389</a>.</p>
</div>
<div id="ref-goldwin_concreteness_2012">
<p>Goldwin, Michelle, and Evelyn Behar. 2012. “Concreteness of Idiographic Periods of Worry and Depressive Rumination.” <em>Cognitive Therapy and Research</em> 36 (6): 840–46. doi:<a href="https://doi.org/10.1007/s10608-011-9428-1">10.1007/s10608-011-9428-1</a>.</p>
</div>
<div id="ref-grush_emulation_2004">
<p>Grush, Rick. 2004. “The Emulation Theory of Representation: Motor Control, Imagery, and Perception.” <em>Behavioral and Brain Sciences</em> 27 (03). doi:<a href="https://doi.org/10.1017/S0140525X04000093">10.1017/S0140525X04000093</a>.</p>
</div>
<div id="ref-R-biosignalEMG">
<p>Guerrero, J.A., and J.E. Macias-Diaz. 2018. <em>BiosignalEMG: Tools for Electromyogram Signals (Emg) Analysis</em>. <a href="https://CRAN.R-project.org/package=biosignalEMG" class="uri">https://CRAN.R-project.org/package=biosignalEMG</a>.</p>
</div>
<div id="ref-guillot_contribution_2005">
<p>Guillot, Aymeric, and Christian Collet. 2005. “Contribution from Neurophysiological and Psychological Methods to the Study of Motor Imagery.” <em>Brain Research Reviews</em> 50 (2): 387–97. doi:<a href="https://doi.org/10.1016/j.brainresrev.2005.09.004">10.1016/j.brainresrev.2005.09.004</a>.</p>
</div>
<div id="ref-guillot_brain_2009">
<p>Guillot, Aymeric, Christian Collet, Vo An Nguyen, Francine Malouin, Carol Richards, and Julien Doyon. 2009. “Brain Activity During Visual Versus Kinesthetic Imagery: An fMRI Study.” <em>Human Brain Mapping</em> 30 (7): 2157–72. doi:<a href="https://doi.org/10.1002/hbm.20658">10.1002/hbm.20658</a>.</p>
</div>
<div id="ref-guillot_imagining_2012">
<p>Guillot, Aymeric, Franck Di Rienzo, Tadhg MacIntyre, Aidan Moran, and Christian Collet. 2012. “Imagining Is Not Doing but Involves Specific Motor Commands: A Review of Experimental Data Related to Motor Inhibition.” <em>Frontiers in Human Neuroscience</em> 6. doi:<a href="https://doi.org/10.3389/fnhum.2012.00247">10.3389/fnhum.2012.00247</a>.</p>
</div>
<div id="ref-guillot_electromyographic_2010">
<p>Guillot, Aymeric, Florent Lebon, and Christian Collet. 2010. “Electromyographic Activity During Motor Imagery.” In <em>The Neurophysiological Foundations of Mental and Motor Imagery</em>, edited by Aymeric Guillot and Christian Collet, 83–94. Oxford University Press. doi:<a href="https://doi.org/10.1093/acprof:oso/9780199546251.003.0006">10.1093/acprof:oso/9780199546251.003.0006</a>.</p>
</div>
<div id="ref-haggard_conscious_2005">
<p>Haggard, Patrick. 2005. “Conscious Intention and Motor Cognition.” <em>Trends in Cognitive Sciences</em> 9 (6): 290–95. doi:<a href="https://doi.org/10.1016/j.tics.2005.04.012">10.1016/j.tics.2005.04.012</a>.</p>
</div>
<div id="ref-hale_effects_1982">
<p>Hale, Bruce D. 1982. “The Effects of Internal and External Imagery on Muscular and Ocular Concomitants.” <em>Journal of Sport Psychology</em> 4 (4): 379–87. doi:<a href="https://doi.org/10.1123/jsp.4.4.379">10.1123/jsp.4.4.379</a>.</p>
</div>
<div id="ref-harris_effects_1986">
<p>Harris, Dorothy V., and William J. Robinson. 1986. “The Effects of Skill Level on EMG Activity During Internal and External Imagery.” <em>Journal of Sport Psychology</em> 8 (2): 105–11. doi:<a href="https://doi.org/10.1123/jsp.8.2.105">10.1123/jsp.8.2.105</a>.</p>
</div>
<div id="ref-hetu_neural_2013">
<p>Hétu, Sébastien, Mathieu Grégoire, Arnaud Saimpont, Michel-Pierre Coll, Fanny Eugène, Pierre-Emmanuel Michon, and Philip L. Jackson. 2013. “The Neural Network of Motor Imagery: An ALE Meta-Analysis.” <em>Neuroscience &amp; Biobehavioral Reviews</em> 37 (5): 930–49. doi:<a href="https://doi.org/10.1016/j.neubiorev.2013.03.017">10.1016/j.neubiorev.2013.03.017</a>.</p>
</div>
<div id="ref-houde_speech_2011">
<p>Houde, John F., and Srikantan S. Nagarajan. 2011. “Speech Production as State Feedback Control.” <em>Frontiers in Human Neuroscience</em> 5. doi:<a href="https://doi.org/10.3389/fnhum.2011.00082">10.3389/fnhum.2011.00082</a>.</p>
</div>
<div id="ref-jeannerod_representing_1994">
<p>Jeannerod, Marc. 1994. “The Representing Brain: Neural Correlates of Motor Intention and Imagery.” <em>Behavioral and Brain Sciences</em> 17 (02): 187. doi:<a href="https://doi.org/10.1017/S0140525X00034026">10.1017/S0140525X00034026</a>.</p>
</div>
<div id="ref-jeannerod_neural_2001">
<p>———. 2001. “Neural Simulation of Action: A Unifying Mechanism for Motor Cognition.” <em>NeuroImage</em> 14 (1): S103–S109. doi:<a href="https://doi.org/10.1006/nimg.2001.0832">10.1006/nimg.2001.0832</a>.</p>
</div>
<div id="ref-jeannerod_motor_2006">
<p>———. 2006. <em>Motor Cognition: What Actions Tell the Self</em>. Oxford Psychology Series, no. 42. Oxford ; New York: Oxford University Press.</p>
</div>
<div id="ref-kamen_essentials_2010">
<p>Kamen, Gary, and David A. Gabriel. 2010. <em>Essentials of Electromyography</em>. Champaign, IL: Human Kinetics.</p>
</div>
<div id="ref-kawato_internal_1999">
<p>Kawato, Mitsuo. 1999. “Internal Models for Motor Control and Trajectory Planning.” <em>Current Opinion in Neurobiology</em> 9 (6): 718–27. doi:<a href="https://doi.org/10.1016/S0959-4388(99)00028-8">10.1016/S0959-4388(99)00028-8</a>.</p>
</div>
<div id="ref-loevenbruck_cognitive_2018">
<p>Lœvenbruck, Hélène, R Grandchamp, Lucile Rapin, Ladislas Nalborczyk, M Dohen, P Perrier, M Baciu, and M Perrone-Bertolotti. 2018. “A Cognitive Neuroscience View of Inner Language: To Predict and to Hear, See, Feel.” In <em>Inner Speech: New Voices</em>, edited by Peter Langland-Hassan and Agustín Vicente, 37. Oxford University Press.</p>
</div>
<div id="ref-mackay_problem_1981">
<p>Mackay, Donald G. 1981. “The Problem of Rehearsal or Mental Practice.” <em>Journal of Motor Behavior</em> 13 (4): 274–85. doi:<a href="https://doi.org/10.1080/00222895.1981.10735253">10.1080/00222895.1981.10735253</a>.</p>
</div>
<div id="ref-mclaughlin_effects_2007">
<p>McLaughlin, Katie A, Thomas D Borkovec, and Nicholas J Sibrava. 2007. “The Effects of Worry and Rumination on Affect States and Cognitive Activity.” <em>Behavior Therapy</em> 38 (1): 23–38. doi:<a href="https://doi.org/10.1016/j.beth.2006.03.003">10.1016/j.beth.2006.03.003</a>.</p>
</div>
<div id="ref-moulton_imagining_2009">
<p>Moulton, S. T., and S. M. Kosslyn. 2009. “Imagining Predictions: Mental Imagery as Mental Emulation.” <em>Philosophical Transactions of the Royal Society B: Biological Sciences</em> 364 (1521): 1273–80. doi:<a href="https://doi.org/10.1098/rstb.2008.0314">10.1098/rstb.2008.0314</a>.</p>
</div>
<div id="ref-nolen-hoeksema_responses_1991">
<p>Nolen-Hoeksema, Susan. 1991. “Responses to Depression and Their Effects on the Duration of Depressive Episodes.” <em>Journal of Abnormal Psychology</em> 100 (4): 569–82. doi:<a href="https://doi.org/10.1037//0021-843X.100.4.569">10.1037//0021-843X.100.4.569</a>.</p>
</div>
<div id="ref-oshea_does_2017">
<p>O’Shea, Helen, and Aidan Moran. 2017. “Does Motor Simulation Theory Explain the Cognitive Mechanisms Underlying Motor Imagery? A Critical Review.” <em>Frontiers in Human Neuroscience</em> 11 (February). doi:<a href="https://doi.org/10.3389/fnhum.2017.00072">10.3389/fnhum.2017.00072</a>.</p>
</div>
<div id="ref-Perrone-Bertolotti2014">
<p>Perrone-Bertolotti, M, Lucile Rapin, J P Lachaux, M Baciu, and Hélène Lœvenbruck. 2014. “What Is That Little Voice Inside My Head? Inner Speech Phenomenology, Its Role in Cognitive Performance, and Its Relation to Self-Monitoring.” <em>Behavioural Brain Research</em> 261: 220–39. doi:<a href="https://doi.org/10.1016/j.bbr.2013.12.034">10.1016/j.bbr.2013.12.034</a>.</p>
</div>
<div id="ref-phinyomark_feature_2012">
<p>Phinyomark, A., A. Nuidod, P. Phukpattaranont, and C. Limsakul. 2012. “Feature Extraction and Reduction of Wavelet Transform Coefficients for EMG Pattern Classification.” <em>Electronics and Electrical Engineering</em> 122 (6). doi:<a href="https://doi.org/10.5755/j01.eee.122.6.1816">10.5755/j01.eee.122.6.1816</a>.</p>
</div>
<div id="ref-pickering_integrated_2013">
<p>Pickering, Martin J., and Simon Garrod. 2013. “An Integrated Theory of Language Production and Comprehension.” <em>Behavioral and Brain Sciences</em> 36 (04): 329–47. doi:<a href="https://doi.org/10.1017/S0140525X12001495">10.1017/S0140525X12001495</a>.</p>
</div>
<div id="ref-Rapin2011">
<p>Rapin, L. 2011. “Hallucinations Auditives Verbales et Trouble Du Langage Intérieur Dans La Schizophrénie: Traces Physiologiques et Bases Cérébrales.” PhD thesis, University of Grenoble.</p>
</div>
<div id="ref-Rippere1977">
<p>Rippere, V. 1977. “What’s the Thing to Do When You’re Feeling Depressed? A Cross-Cultural Replication.” <em>Behaviour Research and Therapy</em> 15: 185–91. doi:<a href="https://doi.org/10.1016/0005-7967(83)90038-4">10.1016/0005-7967(83)90038-4</a>.</p>
</div>
<div id="ref-Robinson2003">
<p>Robinson, Matthew S, and Lauren B Alloy. 2003. “Negative Cognitive Styles and Stress-Reactive Rumination Interact to Predict Depression: A Prospective Study.” <em>Cognitive Therapy and Research</em> 27 (3): 275–92. doi:<a href="https://doi.org/10.1023/A:1023914416469">10.1023/A:1023914416469</a>.</p>
</div>
<div id="ref-rossini_corticospinal_1999">
<p>Rossini, P. M. 1999. “Corticospinal Excitability Modulation to Hand Muscles During Movement Imagery.” <em>Cerebral Cortex</em> 9 (2): 161–67. doi:<a href="https://doi.org/10.1093/cercor/9.2.161">10.1093/cercor/9.2.161</a>.</p>
</div>
<div id="ref-simonyan_laryngeal_2011">
<p>Simonyan, Kristina, and Barry Horwitz. 2011. “Laryngeal Motor Cortex and Control of Speech in Humans.” <em>The Neuroscientist</em> 17 (2): 197–208. doi:<a href="https://doi.org/10.1177/1073858410386727">10.1177/1073858410386727</a>.</p>
</div>
<div id="ref-smith_lack_1947">
<p>Smith, S. M., H. O. Brown, J. E. P. Toman, and L. S. Goodman. 1947. “The Lack of Cerebral Effects of d-Tubocurarine.” <em>Anesthesiology</em> 8 (1): 1–14.</p>
</div>
<div id="ref-stricker_studien_1880">
<p>Stricker, Salomon. 1880. <em>Studien über Die Sprachvorstellungen</em>. Wien: Braumüller.</p>
</div>
<div id="ref-Watkins2008">
<p>Watkins, Edward R. 2008. “Constructive and Unconstructive Repetitive Thought.” <em>Psychological Bulletin</em> 134 (2): 163–206. doi:<a href="https://doi.org/10.1037/0033-2909.134.2.163">10.1037/0033-2909.134.2.163</a>.</p>
</div>
<div id="ref-wolpert_internal_1995">
<p>Wolpert, D., Z Ghahramani, and Michael I. Jordan. 1995. “An Internal Model for Sensorimotor Integration.” <em>Science</em> 269 (5232): 1880–2. doi:<a href="https://doi.org/10.1126/science.7569931">10.1126/science.7569931</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>We will not dwell on the touchy question whether inner speech is a necessary condition for consciousness. For the current purpose, it is sufficient to say that thinking and inner speech are ontologically separable.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>We should also make a distinction between <em>embodiment of content</em>, which concerns the conceptual content of language, and <em>embodiment of form</em>, which concerns “the vehicle of thought”, that is, proper speech production <span class="citation">(Pickering and Garrod <a href="#ref-pickering_integrated_2013">2013</a>)</span>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>In Grush’s terminology, <em>emulator</em> is used as a synonym for <em>forward models</em> <span class="citation">(see Grush <a href="#ref-grush_emulation_2004">2004</a>, 378–79)</span>.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>As a side note, we should remark that these findings are consistent with both the simulation and the emulation views on motor imagery.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>The <em>peripheralist</em> interpretation has also been disproved by the heroic experiment carried out by <span class="citation">Smith et al. (<a href="#ref-smith_lack_1947">1947</a>)</span>. Smith used d-tubocurarine (curare) to paralyse his own facial muscles in order to test this interpretation. He later reported that, while being paralysed, he was still able to think in words and to solve mathematical problems.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Translated to speech, the MST is similar to previous proposals such as the <em>motor theory of voluntary thinking</em> <span class="citation">(Cohen <a href="#ref-cohen_motor_1986">1986</a>)</span> or the hierarchical model of mental practice <span class="citation">(Mackay <a href="#ref-mackay_problem_1981">1981</a>)</span>.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>But see <span class="citation">Phinyomark et al. (<a href="#ref-phinyomark_feature_2012">2012</a>)</span> for other features that can be extracted from the surface EMG signals.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>This experimental chapter is a published paper reformatted for the need of this thesis. Source: Nalborczyk, L., Perrone-Bertolotti, M., Baeyens, C., Grandchamp, R., Polosan, M., Spinelli, E., … Lvenbruck, H. (2017). Orofacial Electromyographic Correlates of Induced Verbal Rumination. <em>Biological Psychology, 127</em>, 53-63. <a href="http://dx.doi.org/10.1016/j.biopsycho.2017.04.013" class="uri">http://dx.doi.org/10.1016/j.biopsycho.2017.04.013</a>.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>The corrugator supercilii was another potential site, as it is sensitive to negative emotions. However, it has been claimed to be mostly activated for strong emotions such as fear/terror, anger/rage and sadness/grief (Ekman &amp; Friesen, 1978; Sumitsuji, Matsumoto, Tanaka, Kashiwagi, &amp; Kaneko, 1967). The rumination induction used in this study was designed to have participants self-reflect and brood over their failure at the IQ- test. It was not meant to induce such strong emotions. Several studies have reported increased activity in the frontalis muscle at rest in anxious or generalized anxiety disorder patients (for a review see Conrad &amp; Roth, 2007). We expected the type of emotional state induced by rumination to be closer to anxiety or worry than to strong emotions like fear, anger or grief. It was therefore more appropriate to record non-speech facial activity in the frontalis rather than in the corrugator.<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Because of constraints attributable to the design of our experiment, we were not able to perform conventional control measures (e.g., time of the day, food consumption, sport activity, smoking habits, etc.). Moreover, in our study, periods of signal recording had to be shorter than usual HRV analysis time periods (cf. methodology section). Although recent studies suggest that “ultrashort term” HRV analysis seems to correlate quite well with HRV analysis performed on longer periods of time (Brisinda et al., 2013; Salahuddin, Cho, Gi Jeong,&amp;Kim, 2007), we cannot exclude that our measurements might be unreliable. For these reasons, we chose not to present HRV results in this report and to focus on EMG results as well as subjective reports of rumination.<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>While not suffering from the misunderstandings associated with frequentist confidence intervals (for more details, see for instance Morey, Hoekstra, Rouder, Lee &amp; Wagenmakers, 2015).<a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>This experimental chapter is a manuscript reformatted for the need of this thesis. Source: The manuscript has been submitted to Psychological Research. Pre-registered protocol, preprint, data, as well as reproducible code and figures are available at: <a href="https://osf.io/c9pag/" class="uri">https://osf.io/c9pag/</a>.<a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>This experimental chapter is a manuscript reformatted for the need of this thesis. Source: The manuscript has been submitted to Psychological Research. Pre-registered protocol, preprint, data, as well as reproducible code and figures are available at: <a href="https://osf.io/czer4/" class="uri">https://osf.io/czer4/</a>.<a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>This experimental chapter is a manuscript reformatted for the need of this thesis. Source: The manuscript has been submitted to Psychological Research. Pre-registered protocol, preprint, data, as well as reproducible code and figures are available at: <a href="https://osf.io/3bh67/" class="uri">https://osf.io/3bh67/</a>.<a href="#fnref14">↩</a></p></li>
<li id="fn15"><p>This experimental chapter is a manuscript reformatted for the need of this thesis. Source: The manuscript has been submitted to Psychological Research. Pre-registered protocol, preprint, data, as well as reproducible code and figures are available at: <a href="https://osf.io/8ab2d/" class="uri">https://osf.io/8ab2d/</a>.<a href="#fnref15">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lnalborczyk/phd_thesis/edit/master/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["thesis.pdf"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"search": true,
"highlight": "pygments"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
