# Methodological framework



This chapter aims to introduce the main materials and methods we will discuss throughout the experimental chapters. It concerns either experimental tools (e.g., electromyography), statistical tools, and the flow of experiments...

## Speech production mechanisms

...

### Speech production muscles

In the current work, we were especially interested in the activity of the orofacial muscles, which can be dfined as the muscles situaated in the periphery of the mouth. More precisely, we were particulary interested in the *orbicularis oris inferior* and *orbicularis oris superior* muscles. As can be seen from Figure XX, these two muscles are actually parts of a broad sphyncter muscles that permis the contractio nand aperture of the mouth...

### Muscular physiology

...

## Brief introduction to surface electromyography concepts

The raw EMG signal is a stochastic train of motor unit action potentials (MUAP). When heard through a speaker, the raw EMG signal sounds like popcorn popping (Fridlund & Cacioppo, 1986)...

Factors that influence the EMG signal: causative (extrinsic, intrinsic), intermediate and deterministic (De Luca, 1997)...

See van Boxtel 2001...

### The electromyographic signal

Muscular activity can be studied at different levels. At the cellular level, using electrophysiological measures like micro-electrods implanted in the cell, that allow direct measures of **action potential**. At the segmental level, biomechanis study muscular activity using surface sensors, positionned on the skin...intermediate levels...
 
The **motor unit action potential** (MUAP) is the electric field resulting from the sum of the electric fiels emitted by each fiber of the motor unit. This train of action potentials will generate a *train* of MUAP, call **motor unit action potential trains** (MUAPT). The electric potential generated by this field is highly dependent of parameters such as the number of fibers, their length, speed of conduction and position of the neuromuscular junction...

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{assets/muap} 

}

\caption{Motor unit action potential representation.}(\#fig:muap)
\end{figure}

To sum up, the EMG signal results from a mixture of recruited motor units...

### Specificities and challenges of surface electromyography

...*crosstalk* phenomenon [@de_luca_use_1997]. In reason of the important... of facial muscles, the EMG activity of one recorded muscle generally does not represent the activity of a single muscle but rather a mixture of... @Rapin2011...

### Basic signal processing

...the EMG signal is a stochastic signal... In order to illustrate what EMG signal looks like, we simulated EMG signal based on a standard algorithm implemented in the `biosignalEMG` package [@R-biosignalEMG].

\begin{figure}[H]

{\centering \includegraphics[width=1\linewidth]{02-chap2_files/figure-latex/emgplot1-1} 

}

\caption{Simulated EMG signal.}(\#fig:emgplot1)
\end{figure}

We usually rectify the EMG signal by taking its absolute value and substracting the mean in order to correct for any offset (bias) present in the raw data. This operation is represented in Figure \@ref(fig:emgplot2).

\begin{figure}[H]

{\centering \includegraphics[width=1\linewidth]{02-chap2_files/figure-latex/emgplot2-1} 

}

\caption{Rectified EMG signal.}(\#fig:emgplot2)
\end{figure}

From there, two main measures can be used to represent the magnitude of muscle activity^[But see @phinyomark_feature_2012 for other features that can be extracted from the surface EMG signals.]. The first one is the *mean absolute value* (MAV), which is computed over a specific interval and where $|x_{n}|$ is the absolute value of a datum of EMG in the data window. 

$$MAV = \frac{1}{N} \sum_{n=1}^{N} | x_{n} |$$

The unit of measurement is $mV$ or $\mu V$, and the MAV calculation is generally similar to the numerical formula for integration [@kamen_essentials_2010]. The second one is the *root-mean-square* (RMS) amplitude:

$$RMS = \sqrt \frac{1}{N} \sum_{n=1}^{N} | x^{2}_{n} |$$

where $| x^{2}_{n} |$ is the squared value of each EMG datum and has both physical and physiological meanings. Put broadly, the RMS it taken to reflect the level of the physiological activities in the motor unit during contraction. Both the MAV and the RMS are illustrated in Figure XX...



Transition toward the statistical modelling approach...

## Statistical modelling and statistical inference

### Limitations of the standard statistical approach in Psychology

Numerous authors have highlighted the limitations inherent to the Null-Hypothesis Significance Testing (NHST) approach and the (exclusive) reliance on *p*-values and significance testing [e.g.,@bakan_test_1966;@Gigerenzer2004;@Kline2004;@Lambdin2012;@meehl_theory-testing_1967;@trafimow_manipulating_2018]. Considering these limitations, some authors have recommended to push away significance testing and to develop the use of effect size estimates and confidence intervals in order to favor accumulation of evidence [e.g.,@Cumming2012;@cumming_new_2014].

However, the apparent superiority of confidence intervals over *p*-values is an illusion. Indeed, as noted by many observers, confidence intervals are simply inverted significance tests. In other words, the confidence interval represents the range of values that are significant at some $\alpha$ level. Therefore, a confidence interval does not bring *any* new inferential value. Morevoer, its interpretation might be as hard as the interpretation of *p*-values. For instance, contrary to a widely shared belief, confidence intervals do not contain the $(1 - \alpha) \cdot 100$% most probable values of the parameter [e.g.,@morey_fallacy_2015;@nalborczyk_pragmatism_2019].

That being said, it is fair to acknowledge that using confidence intervals (instead of or in addition to single *p*-values) do shift the emphasis from a mechanical (mindless) point-hypothesis testing procedure to a more careful consideration of the range of values that are *compatible* with some hypothesis. More importantly, it emphasises the uncertainty that accompanies every statistical procedure. Indeed, we think that most of the caveats that are attributed to a specific statistical procedure (e.g., to NHST) are really caveats of the way it is used. Namely, the fact that is used in a categorical and absolute way. This tendency has been coined as *dichotomania* (i.e., the tendency to consider that results are either present --if significant-- or absent --if non-significant--), or *trichotomania* (e.g., when considering evidence ratios thresholds).

These biases and... have been highlighted by several ... [@wasserstein_asas_2016]. Very recently, *The American Statistician* published a special issue on *Moving to a Wold Beyond "p<.05"*, with the intention to provide new recommendations for the users of statistics (e.g., researchers, policy maker, journalists). This issue comprises 43 original papers aiming to provide new guidelines and practical alternatives to the mindless use of statistics.

In the accompanying editorial, Wassertine2019... Amongst others things, they recommend to follow the ATOM guidelines: "**A**ccept uncertainty. Be **t**houghtful, **o**pen, and **m**odest." In accordance with these guidelines...

* Accept uncertainty: we try to represent uncertainty in our analyses and conclusions. For instance, we do not conclude and/or infer that an effect is eithr "present" or "absent", but we report the *estimated* magnitude of the effect and the uncertainty that comes with this estimation. Additionally, when applicable, we report probabilistic statements based on the posterior distribution.

* Be thoughtful: while being broad... this incentivises statistical thinking...

* Be open: the soundness of a statistical procedure (and more generally, of an inferential procedure) can only be evaluated it its made transparent to peers and readers. Therefore, we take some space in the next section (but also in each experimental chapter) to motivate our statistical modelling decisions. We also make all the R scripts available to ensure the reproducibility of the analyses.

* Be modest: ...  Moreover, we discuss the limitations of our conclusions

To sum up....

### Current statistical approach

To briefly summarise the statistical approach that we have adopted during this work... for more information on Bayesian statistical modelling, see @nalborczyk_introduction_2019...

Explain the main tools and index we use and the difference between them (make a box for the bayes factor, for the ICs, etc)...

\begin{mybox}[label = BF]{What is a Bayes factor ?}

It is a rule in statistics that every statistics has already been suggested as the \textit{new statistics}. Confidence intervals have been suggested as a replacement to p-values, being purpotedly more informative and less difficult to interpret. Credible intervals have been suggested as a replacement to confidence intervals, for roughly the same reasons. Bayesian hypothesis testing through Bayes factors (BFs) has also been suggested as a replacement for frequentist hypothesis testing. It has been argued that they permit a richer inference and that they come with a more straightforward interpretation. Whereas this might be true, they nonetheless come with their lot of misinterpretations.\\

To highlight what BFs are and what they are not, it might be useful to write down the formula used to compute them. To this end, it is useful to write the Bayes rule in its \textit{odds form}, making the BF explicitly visible:

$$\underbrace{\dfrac{p(H_{0}|D)}{p(H_{1}|D)}}_{posterior\ odds} = \underbrace{\dfrac{p(D|H_{0})}{p(D|H_{1})}}_{Bayes\ factor} \times \underbrace{\dfrac{p(H_{0})}{p(H_{1})}}_{prior\ odds}$$

This equation reveals that the \textit{posterior odds}, the ratio of the posterior probability (i.e., how much more probable is hypothesis 1 ($H_{1}$) as compared to hypothesis 2 ($H_{2}$), after seeing the data $D$), is equal to the ratio of the probability of the data given the first hypothesis and the probability of the data given the second hypothesis, multiplied by the \textit{prior odds} (i.e., how much more probable was hypothesis 1 ($H_{1}$) as compared to hypothesis 2 ($H_{2}$), before seeing the data $D$).\\ 

Importantly, what we condider as \textit{evidence} in the Bayesian framework is also known as a \textit{marginal likelihood} and represents the information contained in the data, weighted by the prior information. It is a sum when parameters are discrete or an integral when paramaters are continuous.

$$\text{evidence}\ = p(D|H) = \int p(\theta|H) p(D|\theta,H) \text{d}\theta$$

Therefore, the BF does not indicate how much "probable" a hypothesis is, or how much more probable a hypothesis is, compared to another one (this would be to conflate the BF with the posterior odds). Instead, the BF can be (should be) interpreted either i) as a ratio of two \textit{marginal likelihoods} (i.e., a ratio of \textit{evidence}) or ii) as an updating factor, that indicates how we should reallocate credibility from prior knowledge (what we knew before seeing the data) to posterior knowledge (what we know after seeing the data).

\end{mybox}

Bayes factor are often said to have desirable asymptotic (when the number of observations is very large) properties. Indeed, they are *consistent* for model identification. It means that if a *true* statistical model is in the set of models that are compared, using a BF will usually permi to select this *true* model with a probability approaching 1 with increasing sample size. Whereas this seems an appealing property, it also poses a challenge to the underlying statistical philosophy. Indeed, one could question whether it is sensible to assume a true model (an oxymoron) in real life, especially in the social sciences [e.g.,@burnham_model_2002;@burnham_multimodel_2004]. As @findley_unbiasedness_1985 notes: *"[...] consistency can be an undesirable property in the context of selecting a model"*. A more realistic question is then not to look for the *true* model, but for the *best* model from some practical purpose.

Whereas BFs are said to be **consistent for model identification** (i.e., for identifying the true model). The AIC is not **consistent** for model identification, but it is an **efficient estimator** of the expected K-L information loss...

\begin{mybox}[label = IC]{Information criteria}

Hirotugu Akaike noticed that the negative log-likehood of a model + 2 times its number of parameters was approximately equal to the \textbf{out-of-sample deviance} of a model, which lead to what is nowadays known as the \textit{Akaike information criterion} (AIC):

$$\text{AIC} = \underbrace{-2\log(\mathcal{L}(\hat{\theta}|\text{data}))}_{deviance} + 2K$$

Where $K$ is the number of parameters of the model and the \textit{deviance} is a measure of discrepancy between the data and the model. Interestingly, we can mak a distinction between two types of deviances.\\

First, the \textbf{in-sample deviance} indicates how bad a model is to explain the current dataset (the dataset that we used to fit the model). Second, and more importantly, the \textbf{out-of-sample deviance} indicates how bad a model is to explain a \textbf{future} dataset issued from the same data generation process (the same population).\\

The usefulness of information criteria comes from their being approximations of the \textbf{out-of-sample deviance} of a model. In other words, they permit to approximate a quantity that we could otherwie obtain only by using cross-validation, that is, by acquiring much more data. In the current PhD work, we used generalisations of the AIC (especially the WAIC and LOOIC) that approximate the same quantity and as such give an indication of how good/bad a model is to predict future (i.e., non-observed) data.

\end{mybox}

In brief, in the present work, we used various methods but coherently with a few (nuanced) guiding principles. Namely:

* We favoured *model comparison* over single-model testing [e.g.,@burnham_model_2002;@burnham_multimodel_2004]
* We favoured model estimation over model testing
* We used several indicators when they provide complementary information (e.g., using both posterior probabilities, information criteria or Bayes factors)

...

## Overview of the following chapters

The experiment ran during this PhD will be presented as five empirical chapters that can be grouped under two main axes. In the first couple of experiment, we used surface electromyography and muscle-specific relaxation to investigate the involvement of the speech motor system during induced verbal and non-verbal rumination (Chapter 3 & 4). In Chapter 5, we used surface electromyography and machine learning algorithms to decode the musle-specific EMG correlates of inner speech production. In the last couple of experiments, we switched strategy from the "correlates strategy" to the "interference strategy", where the goal was to directly interfere with the activity of the speech motor system. More precisely, we used articulatory suppression to disrupt induced rumination in Chapter 6, and we used articulatory suppression to disrupt either induced rumination or problem-solving in Chapter 7, in order to compare their effects. Finally, in Chapter 8, we will summarise the main findings, discuss their implications and suggest ways forward from both a theoretical and an experimental perspective.
